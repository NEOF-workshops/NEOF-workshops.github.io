[["01-R_community_main_workflow.html", "R community analysis Chapter 1 Introduction", " R community analysis Matthew R. Gemmell 2023-04-24 Chapter 1 Introduction A lot of different analysis and visualisations can be carried out with community data. This includes taxonomy and functional abundance tables from 16S rRNA and Shotgun metagenomics analysis. This workshop will teach you how to use R with the phyloseq R object; a specialised object containing an abundance, taxonomy, and metadata table. The workshop will use a 16S dataset that has been pre-analysed with QIIME2 to create the ASV table, taxonomy table, and phylogenetic tree. Supplementary materials will show how to import Bracken shotgun metagenomic abundance data and generic abundance data frames into a phyloseq object. Sessions will start with a brief presentation followed by self-paced computer practicals guided by an online interactive book. The book will contain theory and practice code. This will be reinforced with multiple choice questions that will recap concepts and aid in interpretation of results. At the end of the course learners will be able to: Import QIIME2 artifacts into a phyloseq object. Summarise the abundance and taxonomy contents of a phyloseq object Preprocess the abundance and taxonomy tables. This will include transforming sample counts, and subsetting samples &amp; taxonomies. Understand the grammar of graphics (ggplot2) used by phyloseq and related packages. Carry out alpha &amp; beta diversity, and biomarker detection with the phyloseq object. Produce and customise publication quality plots. Run statistical analysis and incorporate these values into the plots. Convert static plots into interactive html plots with plotly within R. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Dataset_and_workflow.html", "Chapter 2 Dataset &amp; workflow 2.1 Dataset 2.2 Workflow", " Chapter 2 Dataset &amp; workflow 2.1 Dataset In this tutorial we will be using 16S metabarcdoing datasets derived from surface water from the Durance River in the south-east of France. Two major comparisons were carried out in combination with each other. 2.1.1 Sites Three different sites were chosen on the Durance River. These three sites were representative of an anthropisation (transformation of land by humans) gradient along a river stream. These sites were: Upper Durance sampling site (UD): Bottom part of the alpine part of the river with little/no anthropisation. Middle Durance sampling site (MD): Upper part of agricultural land dominated by apple and pear production. Lower Durance sampling site (LD): Lower part of agricultural land with intensive production of fruits, cereals, and vegetables. 2.1.2 Culture media Surface water was sampled and different culture media were used to produce bacterial lawns for each site. The media used were: Environmental sample (ENV): No media used, frozen at -20°C will DNA extraction. TSA 10% incubated at 28°C for 2 days. KBC incubated at 28°C for 2 days. CVP incubated at 28°C for 3 days. 2.1.3 Summary &amp; questions Each sample and media combination was produced in replicates of three giving a total of 27 samples (343 = 36). The three replicates were cultured on three different plates with the same media. An ASV table, taxonomy table, and phylogenetic tree were produced with QIIME2 and DADA2. With this data we can ask and investigate the following questions: How does the bacterial communities change across the anthropisation gradient? Is there a difference in the replicates of one site and media combination. I.e. do any of the media produce inconsistent profiles. Is there more difference between the sites or the media used? Do any of the media produce a similar taxonomic profile to the environmental sample? 2.2 Workflow "],["03-R_packages.html", "Chapter 3 R Packages 3.1 R packages/libraries 3.2 The grammar of graphics 3.3 phyloseq", " Chapter 3 R Packages During this workshop we will use various R packages with their own intricacies. Before going into analysis we'll introduce you to some of these important concepts. 3.1 R packages/libraries R packages/libraries contain additional functions, data and code for analysing, manipulating and plotting different types of data. Many common packages will be installed as default when you install R. Other more specialised packages, such as the ggplot2 package, must be installed by the user. Packages found on The Comprehensive R Archive Network (CRAN) which is R’s central software repository can be installed easily using the following command. install.packages(&quot;package_name&quot;) Every time you reload R you will need to load the packages you need if they are not one of the ones installed by default. To do this type: library(&quot;package_name&quot;) I generally have a list of library() functions at the top of my R scripts (.R files) for all the packages I use in the script. Throughout this course you will get a lot of practice installing and loading various packages. R package or R Library? R packages are a collection of R functions, data, and compiled code. You can install these into a directory on your computer. An R library is a directory containing a R package. Because of this, the terms R package and R library may be used synonymously. We will use the term package in this workshop. As we will be using a lot of packages we shall use a double colons to specify which package each function belongs to, unless the function is from base R. For example if we use the function summarize_phyloseq() from the package microbiome we would type the function like below: Note: Do not run the below command. microbiome::summarize_phyloseq() This convention has 2 benefits: We can easily tell which R package each function comes from. This is useful for your future coding where you may copy some, but not all, commands from one script to another. You will therefore know which packages you will need to load. If you need some more documentation about a function you will know what package to look up. Writing your methods will be a lot easier. Different packages may have functions with the same name. Specifying the package will ensure you are using the correct function. 3.2 The grammar of graphics During this course we will be using the grammar of graphics coding approach. This approach is implemented by the R package ggplot2 to create visualisations such as bar charts, box plots, ordination plots etc. In turn ggplot2 is used by a host of other packages, some of which we will be using. Although ggplot2 is R code its structure is very different and it takes effort to learn. Thankfully, ggplot2 is very powerful and flexible, and it produces very professional and clean plots. We will use the iris dataset (inbuilt into R) to show an example of ggplot2 code and its visualisation output is: Note: If you would like to see the contents of the iris dataset you can run the command View(iris) in your R instance. #Load library library(ggplot2) #Create new ggplot2 object using iris dataset ggplot2::ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + #Make the object a scatter plot ggplot2::geom_point() + #Add plot tile ggplot2::ggtitle(&quot;Iris Sepal length vs width&quot;) + #Set x and y axis label names ggplot2::labs(x = &quot;Sepal length&quot;, y = &quot;Sepal width&quot;) We will not learn ggplot2 specifically during this course. However, the structure of creating an object will be used. In the above case the initial object was built with ggplot. Subsequently additions and edits were carried out with + and various other functions. An important concept of the grammar of graphics is aesthetics. Aesthetics are the parts of a graphic/plot. In the above command we set the aesthetics with the function aes() within the ggplot() function. The X aesthetic (i.e. what values are assigned to the x axis) was set as the Sepal length values from the column Sepal.Length of the dataframe iris. In turn the Y axis values are set to the Sepal width and the colouring of the points are set to the Species. That was a quick introduction to the grammar of graphics. We will be using this to create visualisations with a phyloseq object using various R packages specifically designed for community abundance data within phyloseq objects. For more resources on ggplot2 please see the appendix of this book. 3.3 phyloseq In this book we will be working with phyloseq objects to preprocess our dataset, create visualisations, and carry out statistical analyses. This is a very popular object type for community abundance datasets as it contains the abundance table, metadata, and taxonomy table in one object, optionally containing the phylogenetic tree and reference sequences if wanted/required. "],["04-Setup.html", "Chapter 4 Set-up 4.1 Logon instructions 4.2 Mamba", " Chapter 4 Set-up Prior to any analysis we need to setup our environment in the webVNC. 4.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). Connect to the VNC with a browser by using the webVNC link you were sent. You will now be in a logged-in Linux VNC desktop with two terminals. You will see something as below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up too much/little space of your browser you can use the zoom of your browser to adjust the size. You will most likely need to use your browser's tool bar to accomplish this. Ensure you can see the grey borders. These instructions will not work outside of this workshop. If you would like to install your own Linux OS on your desktop or laptop we would recommend Mint Linux The following link is a guide to install Mint Linux: https://linuxmint-installation-guide.readthedocs.io/en/latest/ 4.2 Mamba This workshop requires a lot of packages. These all can be difficult to install with R. Instead we have used Mamba forge to install R, its packages, and Jupyter-notebook (more info below). To learn more about Mamba-forge and how to create your own environment please see the appendix. To set-up your environment for this workshop please run the following code (you must include the full stop and space at the front of the command). . usercommunity You will have successfully activated the environment if you now see (r_community) at the start of your command prompt. This indicates you are now in the mamba environment called r_community created by the instructor. If you are interested in the use script you can look at its contents. less /usr/local/bin/usercommunity Tip: press q to quit less. "],["05-Jupyter.html", "Chapter 5 Jupyter 5.1 Open Jupyter-notebook 5.2 Create R notebook 5.3 Cells and code 5.4 Create new cells 5.5 Running code 5.6 Saving the file 5.7 Title cells with markdown 5.8 Close the notebook 5.9 Video tutorial", " Chapter 5 Jupyter Jupyter-notebook is a nice browser based method to write, edit, and run code. It was initally created for Python coding, but has since branched out to many other languages, such as R. We are using it in this workshop for a variety of its properties: It is popular and well maintained. It is lightweight. Other heavier weight programs, such as RStudio, would struggle in our HPC due to the graphical and CPU load. It is interactive and displays code output. It allows for easier annotation, editing, and debugging than the command line. It provides a graphical interface for hanging directories and choosing files. Before carrying out any analysis we will go through a quick tutorial of jupyter-notebook. 5.1 Open Jupyter-notebook The first step is to open jupyter-notebook. Run the below command in your (r_community) environment. jupyter-notebook This will open jupyter-notebook in firefox. We won't need to access the linux terminal anymore. Leave it running jupyter-notebook and full screen your firefox so you should see something like below. 5.2 Create R notebook The next step is to create a R notebook. Click on the \"New\" button towards the top right, right of the \"Upload\" button. From the dropdown click \"R\" below \"Python 3 (ipykernel)\". This will open up a new R notebook like below. 5.3 Cells and code Jupyter-notebook uses cells (the gray boxes) to separate code. This is very useful to compartmentalise our code. There will already be one cell. Within the cell, type in the below commands. 1+1 2-3 When pressing enter in cells it will create a new line. To run all commands in a cell press CTRL + enter. Run your current cell and you should see something like below. 5.4 Create new cells You can create new cells by 2 different means. Press the + button on the tool bar (between the floppy disk and scissors ). This will add a cell below your currently selected option. Click on the Insert button and use the dropdown to add a cell above or below your currently selected cell. Tip: Hover over the toolbar icons to display a text based description of its function. With that knowledge add a second cell below the first cell. Add the following code to your second cell but do not run it. num_1 &lt;- 3 num_2 &lt;- 10 Tip: Notice there are green lines around your selected cell. Insert a third cell and add the following code to it. Do not run the code. num_1 * num_2 5.5 Running code Try to run the code in the third cell. There should be an error as we have not created the objects num_1 &amp; num_2. We have only written the code for these objects but not run them. We can run all the code in a notebook starting from the first cell to the last cell. Two methods to run all cells are: Click on the \"Cell\" button. Click \"Run All\" from the drop-down options. You should then see something like the below in your notebook. There is no output printed for cell 2 because we are assigning variables. However, now there is the correct output for Cell 3 as the variables were assigned before the command was run. 5.6 Saving the file As with RStudio and other good coding interfaces we can save our notebook. First we should rename the file. Rename the notebook to \"jupyter_tut\": Click on the name of the notebook, currently called \"Untitled\". This is at the very top of the notebook, right of the Jupyter logo. A pop-up called \"Rename Notebook\" will appear. Change the Name to \"jupyter_tut\". Click \"Rename\". Now we can save the file. Two methods to save are: Click the floppy disk on the toolbar. Click on the \"File\" button. Click \"Save and Checkpoint\" from the dropdown options. 5.7 Title cells with markdown We will be using multiple notebooks in this workshop. However, we will also have multiple sections per notebook. It will therefore be useful to create header cells with markdown to create visual separation of the different sections. To add a header cell to the top of our notebook: Create a new cell at the top of the notebook. Click on the \"Code\" drop down and select \"Markdown\". The \"Heading\" option no longer works. Add the following to the \"Markdown\" cell to create a first level header. Ensure you have a space between the # and header text (\"Tutorial\"). # Tutorial Great, we can now add nice headers in our notebooks. Save the notebook once more before carrying on to the next section. Markdown You won't need to know more about Markdown but if you are interested please see the Markdown guide. 5.8 Close the notebook To close the notebook: Click on \"File\". From the dropdown options click \"Close and Halt\". When you are back in the file explorer page you may not yet set the new file you saved. If so, you will need to refresh the page with the Refresh button towards the top right. With that quick tutorial of jupyter-notebook we can start our community analysis ion the next chapter. 5.9 Video tutorial "],["06-Preprocess_part.html", "Chapter 6 Data prep intro", " Chapter 6 Data prep intro In the next 3 chapters (7-9) we will learn how to: Import our data. Summarise our phyloseq object. Determine the minimum read depth for samples to be used. We will also use this as a chance to reinforce how to use jupyter-notebook with clear instructions. However, from chapters 10 onwards you will make more decisions on how many \"Coding\" and \"Markdown\" cells you want. "],["07-Import.html", "Chapter 7 Import 7.1 Import: notebook 7.2 qiime2R 7.3 Import: Summarise phyloseq 7.4 Save the phyloseq object 7.5 Import: recap", " Chapter 7 Import Before carrying out any analysis we first need to import our QIIME2 artifacts into a phyloseq object. Thankfully there is an R package called qiime2R 7.1 Import: notebook Prior to any coding, we will create a new directory, our analysis directory, for this workshop and create a new notebook called \"01-Import.ipynb\" in it. We will be creating a new notebook for each chapter and numbering them so we can easily see the order of scripts. First create a new directory. In the notebook file explorer, click the \"New\" button. Select \"Folder\" You will have an \"Untitled Folder\". To rename it: Click on the box left of the name. Press the \"Rename\" button that appeared. Change the name to \"R_community_workshop\". Click \"Rename\". Click on your \"R_community_workshop\" folder to move into it. Next step is to create a new R notebook, rename it to \"01-Import\", and save it. 7.2 qiime2R qiime2R is an R package for importing QIIME2 artifacts into a R phyloseq object. The package contains many different commands. Its function read_qza() can read a single artifact at a time. The best way to import all your QIIME2 artifacts is with the qza_to_phyloseq() function. In your \"01-Import.R\" script, add the following and run the commands. Tip: You can tab complete and/or copy and paste file paths within the webVNC. #Cell 1 #Load the package/library library(&quot;qiime2R&quot;) #Import data pseq &lt;- qiime2R::qza_to_phyloseq( features = &quot;/pub14/tea/nsc206/NEOF/R_community/data/table-dada2.qza&quot;, tree = &quot;/pub14/tea/nsc206/NEOF/R_community/data/rooted-tree.qza&quot;, taxonomy = &quot;/pub14/tea/nsc206/NEOF/R_community/data/taxonomy.sklearn.qza&quot;, metadata = &quot;/pub14/tea/nsc206/NEOF/R_community/data/media_metadata.txt&quot; ) This command creates a phyloseq object named pseq. It contains: The ASV abundance table (features = \"table-dada2.qza\"). The rooted phylogenetic tree (tree = \"rooted-tree.qza\"). The taxonomic classifications of the ASVs (taxonomy = \"taxonomy.sklearn.qza\"). The sample metadata (metadata = \"media_metadata.txt\") 7.3 Import: Summarise phyloseq Now that we have imported the data we can extract some summary information from it. First we will use the microbiome package with its summarize_phyloseq() function. Create a new cell and write and run the below in it. #Cell 2 #Load microbiome library library(&quot;microbiome&quot;) #Summary of phyloseq object microbiome::summarize_phyloseq(pseq) This gives us a plethora of information: The top line tells us if the data is compositional (relative abundance). We get the following list of values in a paragraph and via a list. Min. number of reads: Number of reads in the sample with the lowest number of reads. Max. number of reads: Number of reads in the sample with the largest number of reads. Total number of reads: Sum of all reads across all samples. Average number of reads: Sum of all reads / number of samples. Median number of reads: Midpoint read abundance across samples. Sparsity: See expandable box further down. Any OTU sum to 1 or less?: States if there are any ASVs with a summed abundance of 1 or less across all the samples. Number of singletons: Number of ASVs with a sum of 1 or less across all samples. Percent of OTUs that are singletons: Percentage of ASVs that only contain one read across all the samples. Number of sample variables are: Number of sample variables/groupings in our metadata. The last line shows the names of the sample variables/groupings in our metadata. Sparsity Sparsity is a measure of the number of 0s in a table. It can be represented by the following equation: \\[ sparsity = Z/C \\] Where: Z = The number of cells that equal zero. C = The total number of cells. Let's look at an example of an abundance table with a small amount of ASVs and Samples. Sample1 Sample2 Sample3 ASV1 0 10 24 ASV2 1 0 37 ASV3 6 25 0 ASV4 51 2 0 This abundance table has 12 cells, 3 samples * 4 ASVs. Of these cells, 4 have an abundance of zero. 4/12 = 0.3333, therefore its sparsity is 0.3333. Sparsity can be any value from 0-1. The higher the value the more sparse it is, with a value of 1 meaning all the cells have an abundance of zero. The lower the value the less sparse it is, with a value of 0 meaning all the cells have an abundance of 1 or more. 16S data is known to be sparse so high sparsity is not unexpected. Keep in mind that lower levels of taxa (ASVs, Species, &amp; Genera) will generally have more sparse tables that higher levels of taxa (Kingdom, Phylum, Class). If you would like to see how the function calculates its values you can view the source code online. 7.4 Save the phyloseq object When using multiple notebooks/scripts for analysis it is useful to save the R objects that will be used in different notebooks/scripts. This can be carried out with the function save(). Write and run the following code in a third cell. #Cell 3 #Save phyloseq as file save(pseq, file = &quot;phyloseq.RData&quot;) This saves our object pseq into the file phyloseq.RData. The suffix .RData is the normal convention. We have saved our final object of the notebook. Close and halt it. 7.5 Import: recap We have imported our QIIME2 artifacts into one phyloseq object so we can analyse the data in R. This object has been saved into a \".RData\" file which we will load in the next chapter. "],["08-Summarise_phyloseq.html", "Chapter 8 Summarise phyloseq 8.1 Summarise: setup 8.2 Summarise: recap", " Chapter 8 Summarise phyloseq For the next X chapters we will use one notebook. We will setup this notebook with libraries and phyloseq object we created in the last chapter. After this, we will summarise the phyloseq object. We will investigate the read depth of samples and the number of ASVs in our dataset. 8.1 Summarise: setup Before starting analysis create and save a new R notebook called \"02-Preprocess.ipynb\" in the analysis directory (when renaming you don't need to include the suffix). We will use this notebook for this and the next chapter. It is useful to add a title to the top of the notebook. Create a \"Markdown\" cell and add the following first level header: #Preprocessing data notebook The first section of our notebook will be used for setup. This will involve loading libraries and data we need. For good documentation add the below second level heading to the first \"Markdown\" cell. ## Setup To decrease the level of a heading add another #. #: 1st level header. ##: 2nd level header. ###: 3rd level header etc... I like to load all the libraries to be used in the notebook in this section. We will explain their uses later in this chapter. Add the below to a new \"Code\" cell in your notebook: #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;vegan&quot;) Our last bit of set-up is to load in our abundance phyloseq object we created in the previous chapter. #Load the phyloseq object load(&quot;phyloseq.RData&quot;) Ensure you have run the code in this cell. 8.1.1 Summarise header When you load in a dataset it is always useful to check it. We will therefore use a new section to inspect the data. In a new \"Markdown\" cell add the following 2nd level header. # Summarise the phyloseq object 8.1.2 Summarise phyloseq Create a second cell and add the following annotation and code. Then run the code. #Summary of phyloseq object microbiome::summarize_phyloseq(pseq) We ran this code in the \"01-Import.ipynb\". You can therefore check if our new output matched the output from that notebook. This should be the case since they are the same data. Due to the relative large amount of output to screen we'll put the next part into a new cell (third cell). 8.1.3 Reads per sample In our third cell we will use the command microbiome::readcount() to store and display the number of reads in each sample within our phyloseq object (pseq). We can even make a quick histogram of read numbers per sample with the base R function hist(). Write and run the below code in a third cell. #Number of reads per sample reads_sample &lt;- microbiome::readcount(pseq) reads_sample #Histogram hist(reads_samples, &quot;Histogram of read depths&quot;) This information is very useful. We will use it in the next chapter to determine what our minimum read depth should be. 8.1.4 ASVs per sample The last feature we will look at before some preprocessing is the ASVs (Amplicon Feature Variants). A useful phyloseq command is otu_table(). This allows us to extract the ASV/OTU/feature table. With this we can then carry out some other commands like looking at the total number of ASVs. For demonstrative purposes write and run the following code in its own cell to display the ASV table. #Can extract ASV table (known as otu table in phyloseq) phyloseq::otu_table(pseq) With this command we will extract the number of ASVs in the original abundance table. We will then save this in a vector. We will add to this vector as we create our relative abundance and rarefied abundance phyloseq objects. #Each row is an ASV and each column is the samples #Therefore we can get the number of ASVs in data #Let&#39;s make a new vector with this info so we can easily keep track num_asvs_vec &lt;- c(nrow(phyloseq::otu_table(pseq))) #Give the 1st element a relevant name names(num_asvs_vec)[1] &lt;- &quot;abundance&quot; #View current vector num_asvs_vec Save this vector as a .Rdata object in a new cell. This will allow us to load it in future notebooks. Additionally, we can remove the object so it doesn't use RAM. #Save object as file save(num_asvs_vec, file= &quot;num_asvs_vec.RData&quot;) #Remove object from environment rm(num_asvs_vec) 8.2 Summarise: recap We now have an idea of some of the attributes of our dataset. We can use this knowledge to carry out some preprocessing. "],["09-Minimum_read_depth.html", "Chapter 9 Minimum read depth 9.1 Considerations 9.2 Minimum read depth section title 9.3 Read depth vector and histogram 9.4 Sample depth boxplot 9.5 Rarefaction curve 9.6 Filtering by minimum read depth 9.7 Minmum read depth: Summary", " Chapter 9 Minimum read depth It is good to remove samples with a very low read depth (number of sequencing reads). However, it is not trivial to determine what an appropriate read depth is. This value will vary from study to study. Normally, for 16S data, a depth of at least 20K per sample is suggested. However, this is the general consensus for human microbiome data. In this chapter we will: Cover a brief intro to considertions of what is an acceptable minimum depth for your dataset. Reinvestigate our sample depths with a previously created histogram. View the depth ranges of different sample groups (site &amp; media) with box plots. Create a rarefaction curve to assess if the depth of our samples have captured a good amount of biodiversity. Demonstrate how to filter samples by depth. 9.1 Considerations There are 3 main considerations to take into account for what is an appropriate depth for your dataset. The biodiversity of your samples. If your sample is very biodiverse, such as the human gut microbiome, you will need a good depth (&gt;20K per sample). If your sample is less biodiverse, such as many geological environments or skin, then you will not need as much read depth. Rarefaction curves are a good method to determine if your samples have enough depth. We will look at this in this chapter. The biomass of your samples. Some environments are hard to extract DNA from. If this is the case for you, then people will hopefully accept that this is an unfortunate reality of life and you will use what you can. However, be careful of your conclusions, if you think your data doesn't have as much as it could do not make very definitive detailed claims. Read depth of sample groups. It may be possible that a few samples have a much lower depth than the rest and so you may think to remove them. However, these may all come from the same sample group and so you have lost all information of one group. For instance, you may be comparing different geological surfaces and your rock samples have much lower read depths than the various soil samples. For comparisons including the lower depth sample group (e.g. rock samples) you will need to retrain the lower depth sample. That is a brief overview of that topic. If you are interested in more I suggest you look at papers where they have studied an environment similar to yours. 9.2 Minimum read depth section title In the next section of our jupyter-notebook we will investigate what the minimum read depth should be and remove sample below this. Create a new \"Markdown\" cell and add the following 2nd level header. ## Minimum read depth 9.3 Read depth vector and histogram We have already created a vector and histogram of the read depths across our samples. Scroll up your notebook to view these and answer the following MCQ: What is the approximate read depth range of our dataset? 1-8 10,000-18,000 20,000+ This is a good first step but what if we want to know how the read depths vary between sample groups? 9.4 Sample depth boxplot We are going to use ggplot2 to create a couple boxplots to show the sequencing depth ranges of the different sample groups (Site &amp; Media). 9.4.1 Creating data frame for boxplots First, we need to create an object containing our sample names, Site &amp; Media information, and the depth. We will use this object to produce our boxplots. Thankfully the metadata in our phyloseq object contains all this information except the depth. In a new cell write and run the below code. This will extract the sample data (metadata) to a new object and display the top 6 rows fo this new object. #Extract sample data as a separate R object abundance_metadf &lt;- phyloseq::sample_data(pseq) #View top 6 rows of metadata data frame head(abundance_metadf) The 2 new functions above are: phyloseq::sample_data(): Extracts the sample data (metadata) data frame from a phyloseq object. head(): Returns the first 6 parts of an R object by default. It can be used for a vector, matrix, table, data frame, or function. In the case of a data frame it returns the first 6 rows. We need to add the depth information to our new data frame. We have extracted this previously into an object called sample_depths. However, before adding it we want to check it has the same order of samples as the rows in abundance_metadf. Write and run the below script in the same cell. The code uses head() to view the first 6 elements of sample_depths and the row names of abundance_metadf. Then the function idnetical() is used to see if they are identical (TRUE) or not (FALSE). #Check if our vector of sample_depths has the same order as our metadata rows head(names(sample_depths)) head(row.names(abundance_metadf)) identical(names(sample_depths),row.names(abundance_metadf)) The order of samples is identical so we can add the depth information to abundance_metadf. Carry this out in the same cell with the code below. #Add sample depths to metadata data frame abundance_metadf[,&quot;depth&quot;] &lt;- sample_depths #View top 6 rows of edited metadata dataframe head(abundance_metadf) Great! We will next use this data frame to create 2 boxplots. 9.4.2 Depth boxplots We are going to create 2 boxplots with ggplot2. We won't go into too much detail on how the code works here, instead learning more later in this book. The code below creates a ggplot2 boxplot. We carry this out with 2 functions: ggplot(): This creates a ggplot2 object, storing the information and aesthetics. The first option is the data we want to use for plotting (abundance_metadf). The second option is the aesthetics (aes()) to plot. In this case we want the depth column to be plotted on the y-axis (y=depth) and the site column to be plotted on the x-axis (x=site). +: We need to have a + at the end of the ggplot() function to add the next component of the plot. geom_boxplot(): This adds a layer to our ggplot2 object. In this case it converts the ggplot object, which is just information, into a boxplot. Write and run the following code in a new cell: #Create ggplot2 boxplot of depth by size ggplot2::ggplot(abundance_metadf, aes=(y=depth, x=site)) + ggplot2::geom_boxplot() Which site has the highest median depth (middle line of boxplot)? LD (Lower Durance) MD (Middle Durance) UD (Upper Durance We will use the same code to plot the depth by media. You can copy and paste the code changing the x aesthetic to media (x=media). Carry this out in the same cell and run the code. #Create ggplot2 boxplot of depth by size ggplot2::ggplot(abundance_metadf, aes=(y=depth, x=media)) + ggplot2::geom_boxplot() Which media has the lowest median depth (middle line of boxplot)? CVP ENV TSA From the boxplots we can see there is no drastic difference between the depths of the different sample groups. We will therefore continue and make some rarefaction curves to further assess the depth of our samples. For more resources on ggplot2 please see the appendix of this book. 9.5 Rarefaction curve Our read depths appear a bit low, each sample has &lt;20K reads. However, this might be fine for our dataset since we are using surface water samples rather than human gut microbiome samples. Let's see how our samples look with a rarefaction curve. Note: This is a quick example and we will go into more detail in the rarefaction chapter. Surprisingly, there is not a good method to produce a rarefaction curve with the phyloseq or microbiome packages. We will therefore use the vegan package. vegan is an R package for community ecologists. It has a variety of functions but it uses normal R data frames rather than phyloseq objects. We will therefore only use it for rarefaction purposes. 9.5.1 ASV abundance data frame Before creating our rarefaction curve we will extract the ASV abundance table from the phyloseq object with phyloseq's function otu_table(). We need to transpose (t()) the table so it is in the correct orientation for the rarefaction function. Additionally, we ensure it is a data frame with the function as.data.frame(). Carry this out in a new cell. #Rarefaction curve #Extract ASV table as data frame asv_abund_df &lt;- as.data.frame(t(phyloseq::otu_table(pseq))) 9.5.2 vegan's rarecurve With this data frame we can create a rarefaction curve with vegan's rarecurve() function. Add the following code to the same cell and run it. #Rarefaction curve vegan::rarecurve( x = asv_abund_df, step = 50, xlab = &quot;Read depth&quot;, ylab = &quot;ASVs&quot; ) Note: You will get a warning saying \"most observed count data have counts1, but smalled count is 2\". This can be ignored in this case. In essence, we are hoping that the majority of samples have plateau'd. If the curves have flattened in relation to the y axis this indicates that most of the ASVs present in the sample have been captured. In this case the samples have plateau'd or have gentle slopes towards the end. With this we can be happy to continue and not remove samples by a minimum read depth. If we saw some samples with steep curves which had low depths we could carry out some more analysis with rarefaction. However, more rarefaction functions, analysis, and theories will be covered in the rarefaction chapter. You could use some of these at this point to help you determine your minimum read depth for your own datasets. 9.6 Filtering by minimum read depth What if you want to filter samples by a minimum read depth? In that case you can use the subset_samples() function from phyloseq(). We will use our previously created vector containing read depths (sample_depths) to remove sample with less than 11k reads. We have chosen this depth as an example to remove some samples. Write and run the below code in a new cell. It will create a new subsetted phyloseq object. #Subset and keep samples with at least 11k reads pseq_min11K &lt;- phyloseq::subset_samples(pseq, reads_sample &gt; 11000) After removing samples it is also useful to remove ASVs with no abundance values. This can occur when ASVs are only present in the samples which have been removed. To remove these ASVs we can use two phyloseq functions: taxa_sums(): Returns a vector showing sum of all taxa in the abundance table. In our phyloseq object the ASVs are the taxa. ASVs have long human unfriendly names that are unique to every single ASV possible. prune_taxa(): This retains taxa/ASVs based on a provided vector. In this case we are creating a logical vector (TRUE/FALSE) where ASVs with 0 abundance are FALSE and ASVs with abundance &gt; 0 are TRUE. We'll first write and run some commands with taxa_sums() to get some practice with it. Carry this out int he same cell as the subset_samples() command. #Abundance sums of the 1st six ASVs head(phyloseq::taxa_sums(pseq_min11K)) #View number of ASVs in our data length(phyloseq::taxa_sums(pseq_min11K)) In the same cell add the following. This will filter out ASVs with no abundance. #Remove ASVs with no abundance pseq_min11k &lt;- phyloseq::prune_taxa( phyloseq_taxa_sums(pseq_min11k) &gt; 0, pseq_min11k ) Finally, summarise the contents of the phyloseq object. Add the following in the same cell and then run the code in the cell. #Summarise subsetted phyloseq microbiome::summarize_phyloseq(pseq_min11K) microbiome::readcount(pseq_min11K) pseq_min11k We can see that the data lost 26 ASVs (2551 - 2525). Try to write your own R code in a new cell to answer the following questions: What is the difference of the minimum number of reads between pseq_min11k and pseq? r longmcq(opts_p)` How many samples were removed due to the read depth filtering? r longmcq(opts_p)` What is the difference of the minimum number of reads between pseq_min11k and pseq? r longmcq(opts_p)` Tip Combining microbiome::readcount() with min(), length(), and sum() might help. Code solutions + bonus #Difference of minimum read numbers min(microbiome::readcount(pseq_min11k)) - min(microbiome::readcount(pseq)) #Number of samples lost length(microbiome::readcount(pseq)) - length(microbiome::readcount(pseq_min11k)) #Number of reads removed sum(microbiome::readcount(pseq)) - sum(microbiome::readcount(pseq_min11k)) #Bonus #List the removed samples setdiff(phyloseq::sample_names(pseq)), phyloseq::sample_names(pseq_min11k)) We won't actually use this subsetted file as we want to keep all the samples in this case. Additionally, since we didn't need remove any samples we don't need to remove any ASVs as they should all have a total abundance &gt; 0. Therefore you can remove the phyloseq object in a new cell. #Remove subsetted phyloseq rm(pseq_min11K) Once you are finished with this notebook you can save it then close and halt it. 9.7 Minmum read depth: Summary We have assessed the read depth in this chapter and decided to not remove any samples. This assessment included: Viewing a histogram of sample read depths. Creating boxplots to compare the sample read depths across sample groups (siet and media). Producing a rarefaction depth to determine if any samples did not represent a good amount of the ASVs present in the environment. Additionally, we created a new phyloseq object where the samples were filtered by depth. Ultimately we did not keep the filtered phyloseq object. "],["10-Relative_abundance.html", "Chapter 10 Taxa relative abundance 10.1 Taxa relative abundance: setup 10.2 Relative abundance transformation 10.3 Aggregate taxa 10.4 Taxa Relative abundance: summary", " Chapter 10 Taxa relative abundance In this section we are going to create taxonomy bar charts. For this we are going to use relative abundance tables of different taxa levels; Genus, Family, &amp; Phyla. In this chapter we are going to create a phyloseq object with relative abundance values of phyla. We would use read depth filtered data if we wanted to use it for other downstream analyses. But, as stated in the last chapter all our samples had sufficient depth, so we will use our original abundance phyloseq object. 10.1 Taxa relative abundance: setup The first steps before analysis are: Create a new notebook called \"3-taxonomy_barcharts\". We will use this to create our phyloseq objects and taxonomy bar charts. Add a markdown cell with the first level header: # Taxonomy bar charts. Add the below to a code cell to load in the phyloseq object and libraries. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;IRdisplay&quot;) #Load phyloseq object load(&quot;phyloseq.RData&quot;) From now on you will get less instructions on your notebook structure. Please create your own coding and markdown cells where you think appropriate. 10.2 Relative abundance transformation Now that we have the data loaded we can create a new phyloseq object by transforming the abundance values to relative abundances. This is carried out with the microbiome function transform(). With it we transform the ASV abundance table within to a \"compositional\" table (relative abundance). Run the below command in an appropriate place in your notebook: #Transform abundance table to a relative abundance (compositional) table pseq_relabund &lt;- microbiome::transform(pseq, &quot;compositional&quot;) As always it is good to check the contents of the new ASV table. #Summarise and check sample counts which should each amount to 1 microbiome::summarize_phyloseq(pseq_relabund) microbiome::readcount(pseq_relabund) You will notice the read count for each sample is 1. This abundance table contains fractional relative abundances for each ASV. This fraction is relative to the total abundance within each sample. Therefore, all the fractional relative abundance values of ASVs in one sample total 1. We will use this to produce all our different taxa tables. 10.3 Aggregate taxa To produce a taxa table we can use the microbiome function aggregate_taxa(). Run the below command to produce a phylum based phyloseq object. Reminder: You may want a markdown cell to create a 2nd level header for this phylum section. #Check head of tax_table #This will tell us the taxa level names on the column names head(tax_table(pseq_relabund)) #Phylum phyloseq phylum_pseq &lt;- microbiome::aggregate_taxa(pseq_relabund, &quot;Phylum&quot;, verbose = FALSE) Let's check our phyla phyloseq. #Head of phylum relative abundance table head(phyloseq::otu_table(phylum_pseq)) #Number of phyla paste0(&quot;Number of phyla: &quot;, nrow(phyloseq::otu_table(phylum_pseq))) #Summarise microbiome::summarize_phyloseq(phylum_pseq) microbiome::readcount(phylum_pseq) 10.4 Taxa Relative abundance: summary We have produced a phyloseq object containing a Phylum relative abundance table. Next, we will create a taxonomy bar chart with this. "],["11-Taxa_plots.html", "Chapter 11 Taxa plots 11.1 Simple bar chart 11.2 Taxa heatmap 11.3 Aggregate rare taxa 11.4 Plot by media 11.5 Plot by site and media 11.6 Taxa plots: summary", " Chapter 11 Taxa plots Now that we have our Genus relative abundance phyloseq we can create a bar chart. 11.1 Simple bar chart To create a simple genus bar chart we can use the following code. #Simple bar chart phylum_bar &lt;- microbiome::plot_composition(phylum_pseq) phylum_bar We have created and saved a ggplot object called phylum_bar. We then viewed it by calling the object. This is a good start but the plot is a bit hard to read. 11.1.1 Save ggplot as png It can be a good idea to save a ggplot object as a file with ggsave(). This allows you to select the size and resolution (dpi) of the image. #Save ggplot object as png file ggsave(filename = &quot;./phylum_relabund_simple.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) 11.1.2 Display png We can use the R package IRdisplay to display plots from files in jupyter-notebook. Use the function display_png() to display our bar chart. #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./phylum_relabund_simple.png&quot;) 11.1.3 Editing the plot Components can be added to ggplot2 objects to edit the plot. They are added with the + symbol. Go to the cell where you created your plot and add components so it looks like the below: #Simple bar chart phylum_bar &lt;- microbiome::plot_composition(phylum_pseq) + #Change/add the x and y labels xlab(&quot;Sample&quot;) + ylab(&quot;Relative abundance&quot;) + #Add a title to the plot ggtitle(&quot;Phylum relative abundance bar chart&quot;) Now save and display the plot. 11.2 Taxa heatmap Our bar chart looks quite nice but for displaying all taxa present it may be better to use a heatmap. Use the below code to produce and visualise a heatmap. Tip: I encourage you to copy and paste your previous bar chart code to edit. #Produce heatmap ggplot phylum_heatmap &lt;- microbiome::plot_composition(phylum_pseq, plot.type = &quot;heatmap&quot;) + xlab(&quot;Phylum&quot;) + ylab(&quot;Sample&quot;) + ggtitle(&quot;Phylum relative abundance heatmap&quot;) #Save ggplot object as png file ggsave(filename = &quot;./phylum_relabund_heatmap.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./phylum_relabund_heatmap.png&quot;) With the heatmap it is much easier to tell what the relative abundances of different phyla are. What is the most abundant phyla across the samples? Chloroflexi Firmicutes Proteobacteria 11.3 Aggregate rare taxa From our bar chart and our heatmap we can see that there are a few high abundance phyla (Actinobacteria, Bacteroidetes, Firmicutes, &amp; Proteobacteria) and many low abundance phyla. To make a better visualisation we will aggregate the rare phyla. This will give us less phyla to plot so we don't need to use so many colours. To carry this out we will use the microbiome function aggregate_rare(). The function has three main options: level =: Taxa level to aggregate table. detection =: Detection threshold (see below). prevalence =: Prevalence threshold (see below). The function will aggregate taxa to our specified level. Whilst doing this it will aggregate the rare taxa of that level to one group called \"Other\". Rare taxa are specified via the detection and prevalence thresholds. Any taxa with an abundance &gt;= to the detection threshold in a number of samples &gt;= to the prevalence threshold will be kept. The taxa which don't reach these thresholds will be classified as rare and aggregated into \"Other\". In the below example we are aggregating the rare taxa with our ASV relative abundance phyloseq object. Any phyla with a relative abundance &gt;= to 0.01 (detection) in at least 5% (5/100) of the samples will not be classified as rare. More info on Prevalence &amp; detection. Note: The detection and prevalence thresholds can be given as numbers (1, 2, 1000 etc.), or percentage values (5/100, 50/100, etc.). Aggregate the relative abundance table to phyla with the rare thresholds: #Aggregate rare phyla phylum_rareaggregate_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Phylum&quot;, detection = 0.01, prevalence = 5/100 ) We will plot this as a new taxonomy bar chart with some additions: #Plot #Add otu.sort to sort phyla by abundance (highest to lowest) phylum_bar &lt;- microbiome::plot_composition(phylum_rareaggregate_pseq, otu.sort =&quot;abundance&quot;) + xlab(&quot;Sample&quot;) + ylab(&quot;Relative abundance&quot;) + ggtitle(&quot;Phylum relative abundance bar chart&quot;) + #Change colours of Phylum to that of the &quot;Paired&quot; palette from colour brewer scale_fill_brewer(&quot;Phylum&quot;, palette = &quot;Paired&quot;) #Save ggplot object as png ggsave(filename = &quot;./phylum_relabund_rareaggregate.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display plot IRdisplay::display_png(file=&quot;./phylum_relabund_rareaggregate.png&quot;) Colour brewer palettes Source That is a very nice and clean bar chart. We can quite easily see that there are 7 main phyla (excluding other). Additionally, it seems that the biggest difference between samples is due to the media used. 11.4 Plot by media One of the many great advantages of ggplot2 is that you can create plots tailored to your metadata. As an example we will create another taxonomy bar chart but have one bar for each media site. We'll use a very similar code as the above bar chart but add the microbiome::plot_composition option average_by =. With this we will average the rare aggregated relative abundance values by the four different media. #Plot by media phylum_media_bar &lt;- microbiome::plot_composition(phylum_rareaggregate_pseq, otu.sort =&quot;abundance&quot;, average_by = &quot;media&quot;) + xlab(&quot;Sample&quot;) + ylab(&quot;Relative abundance&quot;) + ggtitle(&quot;Phylum relative abundance bar chart by media&quot;) + scale_fill_brewer(&quot;Phylum&quot;, palette = &quot;Paired&quot;) #Save ggplot object as png ggsave(filename = &quot;./phylum_relabund_media_rareaggregate.png&quot;, plot = phylum_media_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display plot IRdisplay::display_png(file=&quot;./phylum_relabund_media_rareaggregate.png&quot;) Now we get a good picture of which medias have the highest and lowest phlya diversity. The Environmental samples (ENV) definitely have the highest diversity with clear presence of all phyla. Which media has the highest relative abundance of Protoebacteria and the lowest phyla diversity (excluding ENV)? CVP KBC TSA Which media has the lowest relative abundance of Protoebacteria and the highest phyla diversity (excluding ENV)? CVP KBC TSA Later in this book we will investigate diversity more thoroughly with alpha and beta diversity visualisation and statistics. 11.5 Plot by site and media Task: In the sample_data there is a column called site.media. Use this column to create a phyla bar chart averaged by site and media. Please make a good effort at the task before look at the solution in the below box. Site and media bar chart solution #Plot by site and media phylum_site_media_bar &lt;- microbiome::plot_composition(phylum_rareaggregate_pseq, otu.sort =&quot;abundance&quot;, average_by = &quot;site.media&quot;) + xlab(&quot;Sample&quot;) + ylab(&quot;Relative abundance&quot;) + ggtitle(&quot;Phylum relative abundance bar chart by site &amp; media&quot;) + scale_fill_brewer(&quot;Phylum&quot;, palette = &quot;Paired&quot;) #Save ggplot object as png ggsave(filename = &quot;./phylum_relabund_site_media_rareaggregate.png&quot;, plot = phylum_site_media_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display plot IRdisplay::display_png(file=&quot;./phylum_relabund_site_media_rareaggregate.png&quot;) 11.6 Taxa plots: summary In this chapter we have: Created taxa bar charts with microbiome and ggplot2. Saved ggplot2 plots as pngs with ggsave(). Displayed pngs with IRdisplay::display_png(). Produced taxa heatmaps. Aggregated rare taxa based on detection and prevalence. Grouped bars in bar charts by metadata groups. We will reinforce this by producing Family and Genus based plots in the next chapter. "],["12-Family_and_Genus_taxa.html", "Chapter 12 Family &amp; Genus plots 12.1 Family taxa plots 12.2 Genus taxa plots", " Chapter 12 Family &amp; Genus plots In this chapter you will: Create Family plots by following example code. Be tasked to create Genus plots with little instruction. I highly encourage you to copy previous code and edit it. It is a major time saver. However, it can be easy to overlook some edits. It is a good idea to double check your edited code to ensure you have changed the relevant options, and object &amp; file names. 12.1 Family taxa plots This part will show you a nice workflow for creating some family based taxa plots. Run this at the bottom of your \"3-taxonomy_barchart.ipynb\" notebook. 12.1.1 Aggregate families First we will create a phyloseq object by aggregating the families from the relative abundance phyloseq object. Let us also then check the family phyloseq object. #Family phyloseq family_pseq &lt;- microbiome::aggregate_taxa(pseq_relabund, &quot;Family&quot;, verbose = FALSE) #Head of phylum relative abundance table head(phyloseq::otu_table(family_pseq)) #Number of families paste0(&quot;Number of families: &quot;, nrow(phyloseq::otu_table(family_pseq))) #Summarise microbiome::summarize_phyloseq(family_pseq) microbiome::readcount(family_pseq) We have 112 families. Quite a bit but hopefully they will all fit into a heatmap. 12.1.2 Family heatmap We will create a heatmap as before with one added ggplot2 component. As there are a lot of Families (112) and fewer samples (36) it will be easier to view if we have the families on the y-axis. By default microbiome::plot_composition() will plot the taxa/families on the x-axis. Thankfully we can use the ggplot2() function/component coord_flip() to flip/swap the x and y axes. Note: The xlab() and ylab() are specified the before this flipping. E.g. xlab() is set to \"Family\" which will appear on the y axis because of the flip. #Family heatmap family_heatmap &lt;- microbiome::plot_composition(family_pseq, plot.type = &quot;heatmap&quot;) + xlab(&quot;Family&quot;) + ylab(&quot;Sample&quot;) + ggtitle(&quot;Family relative abundance heatmap&quot;) + #Flip the x and y axes coord_flip() #Save ggplot object as png file ggsave(filename = &quot;./family_relabund_heatmap.png&quot;, plot = family_heatmap, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./phylum_relabund_heatmap.png&quot;) The plot is quite large. You can right click on the image and click \"Open Image in New Tab\" to view the whole image in a new tab. With this heatmap we can see that the KBC and TSA samples have a high relative abundance of Pseudomonadaceae whilst the TSA samples have a high relative abundance of Aeromonadaceae. Additionally, we can see that a lot of families have relatively low relative abundances. Once you are finished looking at the plot the tab containing the plot. This will help to keep the used resources low on the cluster. Next we'll carry out our rare aggregation and produce some bar charts. 12.1.3 Family rare aggregation To aggregate our rare families we need to choose a suitable detection and prevalence threshold. Generally, this is a process of trial and error trying to get a total of 12 taxa. Twelve is a good number as it is the total number of colours in the Paired palette from Colour brewer. You may need more in your own analysis so it is not a hard limit. Therefore, lets try out various thresholds and see how many families we get. To get a good idea where to start we can get a summary of the mean relative abundance values of the families. #Summary of row means (families) from the family otu table summary(rowMeans(phyloseq::otu_table(family_pseq))) We have a lot of families so we will want to remove a good amount of them. For our first attempt at rare aggregation we will use a value near the 3rd Quartile (0.0021601). This will hopefully remove at least 3/4 of the families. We'll set up the code a bit differently so we can easily copy and paste it to try out various other values of detection and threshold. #Tests #1 d &lt;- 0.002 p &lt;- 5/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Family&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of families = &quot;, nrow(phyloseq::otu_table(test_pseq))) That gives us 56 families which is too high for a nice visualisation. We'll therefore try a bunch of trial and error to get 12 families after aggregation. #2 Increase prevalence threshold d &lt;- 0.002 p &lt;- 10/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Family&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of families = &quot;, nrow(phyloseq::otu_table(test_pseq))) #3 Increase detection threshold d &lt;- 0.005 p &lt;- 10/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Family&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of families = &quot;, nrow(phyloseq::otu_table(test_pseq))) #4 Increase detection threshold d &lt;- 0.02 p &lt;- 10/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Family&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of families = &quot;, nrow(phyloseq::otu_table(test_pseq))) #5 Increase prevalence threshold d &lt;- 0.02 p &lt;- 20/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Family&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of families = &quot;, nrow(phyloseq::otu_table(test_pseq))) #Remove unwanted test_pseq rm(test_pseq) Super! A Detection threshold of 0.02 and a prevalence threshold of 20/100 gives us 12 families. We'll now create a new phyloseq object using this info in a new cell. #Aggregate families phyla family_rareaggregate_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Family&quot;, detection = 0.02, prevalence = 20/100 ) Choosing a good detection and prevalence threshold is quite difficult. It takes a lot of trial and practice and I find the thresholds to not be very intuitive to understand. One piece of advise is to only change one threshold at a time during your trial and errors. 12.1.4 Family bar chart With our family rare aggregated phyloseq object we'll create a bar chart. #Plot family_bar &lt;- microbiome::plot_composition(family_rareaggregate_pseq, #otu.sort to sort family by abundance otu.sort = &quot;abundance&quot;, group_by = &quot;media&quot;) + xlab(&quot;Sample&quot;) + ylab(&quot;Relative abundance&quot;) + ggtitle(&quot;Family relative abundance bar chart&quot;) + #Change colours of families to that of the &quot;Paired&quot; palette from colour brewer scale_fill_brewer(&quot;Family&quot;, palette = &quot;Paired&quot;) #Save ggplot object as png ggsave(filename = &quot;./family_relabund_rareaggregate.png&quot;, plot = family_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./family_relabund_rareaggregate.png&quot;) Brilliant, we are no finished with the Family taxa plots. Onto something harder. 12.2 Genus taxa plots In this section you are running your own analysis for the Genus information in the \"3-taxonomy_barchart.ipynb\" notebook. Carry out the following tasks with the relative abundance phyloseq object (pseq_relabund): Create an aggregated genus phyloseq object and summarise it (no rare aggregation). Create a heatmap of the genera relative abundances. Carry out genus rare aggregation so the resulting phyloseq object only contains 12 genera. Use the rare aggregated phyloseq object to create a bar chart grouped by media. In essence you are going through the workflow for the family data but for genus instead. Again, I encourage you to copy, paste, and edit previous code. You will most likely need to change names of objects and also change various options. 12.2.1 Genus taxa plots solutions Please give the task a good try before looking at the solutions in the expandable boxes. However, if you are really stuck or want to compare your code to mine please have a look. Please, remember that there are many ways to do the same thing. If your code is different but it works and you understand it then that is fine. Aggregate genus and summarise #Genus phyloseq genus_pseq &lt;- microbiome::aggregate_taxa(pseq_relabund, &quot;Genus&quot;, verbose = FALSE) #Head of genus relative abundance table head(phyloseq::otu_table(genus_pseq)) #Number of genera paste0(&quot;Number of families: &quot;, nrow(phyloseq::otu_table(genus_pseq))) #Summarise microbiome::summarize_phyloseq(genus_pseq) microbiome::readcount(genus_pseq) Heatmap #Genus heatmap genus_heatmap &lt;- microbiome::plot_composition(genus_pseq, plot.type = &quot;heatmap&quot;) + xlab(&quot;Genus&quot;) + ylab(&quot;Sample&quot;) + ggtitle(&quot;Genus relative abundance heatmap&quot;) + #Flip the x and y axes coord_flip() #Save ggplot object as png file ggsave(filename = &quot;./genus_relabund_heatmap.png&quot;, plot = genus_heatmap, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 450, width = 300) #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./genus_relabund_heatmap.png&quot;) Aggregate rare genus #Summary of row means (families) from the family otu table summary(rowMeans(phyloseq::otu_table(genus_pseq))) #Tests #1 d &lt;- 0.001 p &lt;- 5/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Genus&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of genera = &quot;, nrow(phyloseq::otu_table(test_pseq))) #2 d &lt;- 0.01 p &lt;- 5/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Genus&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of genera = &quot;, nrow(phyloseq::otu_table(test_pseq))) #3 d &lt;- 0.01 p &lt;- 20/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Genus&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of genera = &quot;, nrow(phyloseq::otu_table(test_pseq))) #4 d &lt;- 0.005 p &lt;- 20/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Genus&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of genera = &quot;, nrow(phyloseq::otu_table(test_pseq))) #1 d &lt;- 0.006 p &lt;- 20/100 test_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Genus&quot;, detection = d, prevalence = p ) paste0(&quot;Detection = &quot;, d, &quot;, Prevalence = &quot;, p, &quot;, Number of genera = &quot;, nrow(phyloseq::otu_table(test_pseq))) #Remove unwanted test_pseq rm(test_pseq) #Aggregate genus phyla genus_rareaggregate_pseq &lt;- microbiome::aggregate_rare( pseq_relabund, level = &quot;Genus&quot;, detection = 0.006, prevalence = 20/100 ) Bar chart #Plot genus_bar &lt;- microbiome::plot_composition(genus_rareaggregate_pseq, #otu.sort to sort genera by abundance otu.sort = &quot;abundance&quot;, group_by = &quot;media&quot;) + xlab(&quot;Sample&quot;) + ylab(&quot;Relative abundance&quot;) + ggtitle(&quot;Genus relative abundance bar chart&quot;) + #Change colours of genera to that of the &quot;Paired&quot; palette from colour brewer scale_fill_brewer(&quot;Genus&quot;, palette = &quot;Paired&quot;) #Save ggplot object as png ggsave(filename = &quot;./genus_relabund_rareaggregate.png&quot;, plot = family_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 200, width = 300) #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./genus_relabund_rareaggregate.png&quot;) Once you are happy you can Close and Halt the notebook. "],["13-Diversity_analysis.html", "Chapter 13 Diversity analysis intro", " Chapter 13 Diversity analysis intro In the next X chapters we will carry out diversity analyses. This will include calculating and visualising diversity values plus carrying out the associated statistics. In the chapters we will carry out: Rarefaction of our ASV table. Alpha diversity of the rarefied data. Beta diversity of the rarefied data. Biomarker detection. During this we will attempt to answer our questions from Chapter 2: How does the bacterial communities change across the anthropisation gradient? Is there a difference in the replicates of one site and media combination. I.e. do any of the media produce inconsistent profiles. Is there more difference between the sites or the media used? Do any of the media produce a similar taxonomic profile to the environmental sample? "],["14-Rarefaction.html", "Chapter 14 Rarefaction 14.1 Rarefaction: setup 14.2 Rarefaction curve 14.3 Rarefaction slope 14.4 Rarefy data 14.5 Rarefaction: summary", " Chapter 14 Rarefaction We are going to create a rarefied abundance table in this chapter. This can be a controversial topic. Please make your own decision if you want to do this or not in your own analysis. 14.1 Rarefaction: setup We will use a new notebook called \"4-rarefaction.ipynb\". Add the following to the top of this new notebook to load the required libraries/packages and data. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;vegan&quot;) library(&quot;IRdisplay&quot;) #Load phyloseq object load(&quot;phyloseq.RData&quot;) #Load ASV count vector load(&quot;num_asvs_vec.RData&quot;) Ensure you add markdown and code cells to this notebook to give yourself a good structure. 14.2 Rarefaction curve Prior to rarefying our data we need to determine the depth we want to use. We can carry this out with a rarefaction curve. A rarefaction curve is produced by randomly sampling the sequences in a sample (without replacement). The rarefaction curve extracts the number of unique ASVs in the first N sequences of each sample. N is equal to the step size which we will set as 50 (step = 50). This is followed by the number of unique ASVs found in 2N, then 3N etc. The plot will show the number of total unique ASVs it has found against the depth it has currently sampled. Therefore, after 10 steps it will be at a depth of 500 on the x-axis (50 * 10) and it will show how many unique ASVs it has currently discovered from all 10 samplings. 14.2.1 Bird analogy You are cataloguing the bird diversity (ASV diversity) in three forests/woods in Hampshire (3 samples of our abundance table). You record your findings over a week for each forest. Your record on the cumulative amount of unique species you find over the 3 separate weeks are in the table below: Cumulative bird species found in Hampshire forests/woods over a week Day New Forest (93900 acres) Telegraph woods (50 acres) Old Lords wood (4.67 acres) 1 12 7 8 2 21 12 10 3 32 16 11 4 40 21 13 5 49 23 13 6 60 24 13 7 65 25 13 This can then be plotted in a rarefaction plot like below. In this case we can be fairly confident that seven days is enough to find all the birds we can in the Old Lords wood (green). I.e. the sampling depth is enough. Just like bird watching, it is very hard to find all the species present in a sample with metabarcoding or shotgun metagenomics. This can be caused by our barcodes not picking up all species, our sampling wasn't perfect, some species are very rare, or errors that DNA sequencing introduces. A week seems like a good amount for sampling the Telegraph woods (Blue) but it is possible that some more species have not been recorded. Strikingly, a week does not appear to be enough time for the New Forest (red). The amount of new species decreased to 5 on day 7 but the curve has not yet plateau'd. This hopefully helps you understand why rarefaction curves are a useful measure of how well we have captured the diversity of samples at different depths. 14.2.2 Rarefaction curve: simple plot We'll use vegan to create our rarefaction curve like we did in Chapter 9. #Extract ASV table as data frame asv_abund_df &lt;- as.data.frame(t(phyloseq::otu_table(pseq))) #Rarefaction curve vegan::rarecurve( x = asv_abund_df, step = 50, xlab = &quot;Read depth&quot;, ylab = &quot;ASVs&quot; ) 14.2.3 Rarefaction curve: better plot It is a useful plot but we can make it bigger and better! We will do that with the following additions: Saving it as a .png file with the functions png() and dev.off(). Adding extra options to vegan::rarecurve(): lwd: Sets the line width of the plot. label: Turn the sample labels on (T) or off (F). sample: Draws a vertical line at the specified depth. Additionally, draws a horizontal line for each sample showing how many ASVs were discovered at the sampling depth. We will initially use our minimum sample depth as our rarefaction/sampling depth. This is a good idea if it seems like a good amount as it will allow us to keep all our samples after rarefaction. Any samples with a lower depth than are final rarefaction size will be removed. #Improved plot saved as file png(filename = &quot;./rarefaction_plot.png&quot;, res = 300, units = &quot;mm&quot;, height = 200, width = 300) #Plot vegan::rarecurve( x = asv_abund_df, step = 50, xlab = &quot;Read depth&quot;, ylab = &quot;ASVs&quot;, lwd=1, label = F, sample = min(microbiome::readcount(pseq)) ) dev.off() #Display the plot in jupyter notebook IRdisplay::display_png(file=&quot;./rarefaction_plot.png&quot;) From this plot we can see that most of the samples have plateu'd quite nicely at the minimum depth. This indicates that this is a good sampling depth, i.e. depth to be chosen for rarefying the data. The grey horizontal lines help show how many more ASVs are found in a sample after the chosen sampling depth. This can be seen in the sample with the highest number of ASVs where 5-20 more ASVs are discovered with its final depth of ~16,000. 14.3 Rarefaction slope We can calculate the slope of each sample at our specified sampling depth. A slope of 0 shows a flat horizontal line (what we want). A slope of 1 shows a flat vertical line (not what we want). To get the slope of each sample we will use vegan::rareslope(). #Rarefaction slopes rarefaction_slopes &lt;- vegan::rareslope( x = asv_abund_df, sample = min(microbiome::readcount(pseq)) ) #View slopes from lowest to highest value sort(rarefaction_slopes) #Summary of slopes summary(rarefaction_slopes) #Histogram of slopes hist(rarefaction_slopes) With the calculated slopes attempt the following questions: Which sample has the largest slope value? UD_ENV_rep2 MD_ENV_rep3 LD_CVP_rep1 Which sample has the lowest slope value? UD_ENV_rep2 MD_ENV_rep3 LD_CVP_rep1 Which samples have larger slope values; the environmental samples or media samples? Environmental Media Overall the slopes values are low (&lt;0.01). It is noticeable that the environmental samples have higher slopes than the media samples. Biologically, this makes sense as there is no bias being introduced by media. 14.4 Rarefy data The minimum sample depth appears to be a good choice for rarefying. It keeps all the samples and at this depth the samples have a very good coverage of the ASVs present in the data. This is represented by the good plateauing in the rarefaction plot and the low valued slopes (&lt;0.01). In your own analyses you may need to balance the loss of samples with the loss of depth. With that decision we will rarefy our data to the minimum depth. #Rarefy to minimum depth pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = min(microbiome::readcount(pseq)), rngseed = 1000 ) The options we provided to the function rarefy_even_depth were: pseq: The phyloseq object to rarefy. sample.size =: The sampling depth to rarefy to. rngseed: This is the seed used for random subsampling. If you rarefy the data again with the same seed it will extract the same data. This is useful so you and others can replicate your work. Additionally, it means you will get the same output as me (the writer) so you can accurately compare your findings to mine. As always, it is useful to check our data. #Summarise and check sample counts which should each amount to 10433 (min depth) microbiome::summarize_phyloseq(pseq_rarefy) microbiome::readcount(pseq_rarefy) #ASV counts #Add relative abundance ASV count num_asvs_vec[&quot;rarefied&quot;] &lt;- nrow(phyloseq::otu_table(pseq_rarefy)) num_asvs_vec #ASV counts #Add relative abundance ASV count, read in at start of notebook num_asvs_vec[&quot;rarefied&quot;] &lt;- nrow(phyloseq::otu_table(pseq_rarefy)) num_asvs_vec With this we can see that all our samples have the correct depth (10,433) and very few ASVs have been lost (2551-2498 = 53). I would definetly be happy with this outcome. Once you have viewed the outputs save your phyloseq object and ASV count vector. #Phyloseq save save(pseq_rarefy, file =&quot;phyloseq_rarefied.RData&quot;) #ASV count save save(num_asvs_vec, file=&quot;num_asvs_vec.v2.RData&quot;) Now you can close and halt the notebook. 14.5 Rarefaction: summary In this chapter we: Determined the sampling depth to rarefy to with rarefaction curves and slopes. Rarefied our samples to the minimum read depth. This retained all our samples whilst using a good depth. We now have an abundance table, relative abundance table, and rarefied abundance table. We will use these to carry out some analyses. "],["15-Alpha.html", "Chapter 15 Alpha diversity 15.1 Alpha: setup 15.2 Alpha: simple plot 15.3 Alpha: stats 15.4 Alpha diversity: violin plot 15.5 Alpha: Site plots and statistics 15.6 Alpha: summary", " Chapter 15 Alpha diversity In this chapter we are going to produce alpha diversity plots and statistics with our rarefied data. Alpha diversity is carried out by producing a metric for each sample. These metrics are primarily interested in the evenness or diversity of a sample. Generally, these metrics are carried out on the ASV data to see the most fine grain differences between samples. However, you can also use different taxa levels which we will show later on. This can be useful if there is too much difference in the ASVs from sample to sample or you can only accurately classify sequences to a high level taxonomy (such as with KRAKEN2 output). Once we have a value for each sample they can be used to compare samples and sample groups. Box plots are used for visualisation. Statistics are used to determine if there is a significant difference between groups. We'll start out by producing a basic box plot and statistics. Next we'll improve the plot with some extra R packages. With these tools we will compare the metrics across the various metadata fields we have. 15.1 Alpha: setup We will use a new notebook called \"5-alpha_diversity.ipynb\". Add the following to the top of this new notebook to load the required libraries/packages and data. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;IRdisplay&quot;) library(&quot;ggforce&quot;) #Load phyloseq object load(&quot;phyloseq_rarefied.RData&quot;) Reminder to use markdown and code cells in the notebook. 15.2 Alpha: simple plot The first step is to calculate and plot the alpha diveristy metrics based on the ASV data. Thankfully, the command phyloseq::plot_richness() will do both of these. Try it out. phyloseq::plot_richness(physeq = pseq_rarefy) The resulting plot is pretty good but unreadable. We can do 3 major things to make the contents easier to read. 15.2.1 Metric choice We can choose certain alpha diversity metrics to plot. Currently it is showing 7 metrics (Observed, Chao1 etc.). I like to use: Observed: This is the number of observed features (ASVs, Genera, etc) in each sample. Chao1: This is an estimate number of the total number of features in each sample. Shannon: A measure of diversity where a higher number means higher diversity. Shannon's index accounts for both abundance and evenness of the features present. We'll choose these metrics with the measures = option. Either make a new code block with new code or you can edit and run the previous code you wrote. phyloseq::plot_richness(physeq = pseq_rarefy, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) To see which measures are available you can see the help page of phyloseq::plot_richness(). For a list and full description of the metrics please see the APPENDIX LINK NEEDS TO BE ADDED ABOVE WHEN APPENDIX MADE. ?phyloseq::plot_richness 15.2.2 Sample grouping &amp; box plot The last plot looks a bit better. To actually make them box plots we'll change the x axis so they are based on media rather than individual samples. The phyloseq::plot_richness() function produces a ggplot2 object. To convert our dot plot into a box plot we can add the layer geom_boxplt() like with our depth boxplots. This will combine samples from one media into one IQR box. phyloseq::plot_richness(physeq = pseq_rarefy, x = &quot;media&quot;, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) + ggplot2::geom_boxplot() 15.2.3 Save and display as png Like we have done a few times we can save the plot as a png and view it. # Produce ggplot object of boxplot alpha_boxplot &lt;- phyloseq::plot_richness(physeq = pseq_rarefy, x = &quot;media&quot;, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) + ggplot2::geom_boxplot() #Save ggplot2 object with ggsave ggsave(filename = &quot;./Alpha_diversity_media_boxplot.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file=&quot;./Alpha_diversity_media_boxplot.png&quot;) How do I choose a good height and width? This comes down to trial and error and experience. You want something with a good aspect ration for the plot and you want all the text to be clear. Additionally, the size requirements of figures for journals will play a big consideration as well. One of the nice things with creating jupyter-notebooks or R markdowns with all your code is that you can go back, edit, and rerun the code relatively easily and quickly. 15.3 Alpha: stats Along with the plot it is also good to carry otu statistics. This will allow us to statistically determine if the alpha diversity values between groups are statistically significant. Before carrying out statistics we will need a data frame with the alpha diveristy values for each sample. This can be carried out with the functionphyloseq::estimate_richness(). #Produce data frame of all alpha diversity values alpha_df &lt;- phyloseq::estimate_richness(physeq = pseq_rarefy) head(alpha_df) We have all the alpha metrics in the new data frame. Additionally, we also have the standard error for some of the metrics (e.g. se.chao1). With this information we can carry out a pairwise comparison using Wilcoxon rank sum test (the same way as QIIME2). Base R comes with the function pairwsie.wilcox.test() to carry this out. We'll do this using media as our groups from the sample_data() and the Observed metric from the #Paired wilcoxon test #Observed pairwise.wilcox.test(alpha_df$Observed, phyloseq::sample_data(pseq_rarefy)$media) You can ignore the warning messages in this case. Observe the results. Are all the pairwise comparisons significant different (&lt;0.05)? Yes No The test has carried out P value adjustments using the Holm-Bonferroni method (P value adjustment method: holm) which is good. In this case the p-values are all identical as the values do not vary greatly but there are clear differences. The only group with a large variance is the ENV group with values going from &lt; 150 to &gt; 450. 15.3.1 Alpha stats task Carry out the same statistical analysis (media as the grouping) with the Chao1 and Shannon metrics. Alpha stats solution #Chao1 pairwise.wilcox.test(alpha_df$Chao1, phyloseq::sample_data(pseq_rarefy)$media) #Shannon pairwise.wilcox.test(alpha_df$Shannon, phyloseq::sample_data(pseq_rarefy)$media) With these we can see that the differences between the Chao1 values of the different media are significantly different. However, the p-values when comparing the Shannon values are not all significant. The only significant differences are between ENV &amp; KBC, and between KBC &amp; TSA. Going back to the boxplot, does this look like the case? I would say yes as the IQRs for CVP, KBC, and TSA all overlap. There is little to no overlap of the IQRs of KBC and TSA against ENV. We can therefore make these claims about the alpha diversity values of the groups. ENV has the highest number of observed ASVs and the highest diversity. ENV appears to have a wider range of diversities across its samples. The medias have much lower numbers of ASVs and diveristy compared to ENV. Within each media grouping the samples have very similar numbers of ASVs present. 15.4 Alpha diversity: violin plot Boxplots are quite nice but violin plots can be even nicer. They show the distribution of the data in the IQR better and in fact you can easily display each value. We can change our boxplot to a violin plot by changing ggplot2:geom_boxplot() to ggplot2::geom_violin(). Copy and paste the previous boxplot code to a new cell at the bottom of your notebook. Edit and run the code so it looks like the below. Tip: Remember to change the name of your png file in the ggsave() and IRdisplay::display_png() functions. # Produce ggplot object of violin plot alpha_boxplot &lt;- phyloseq::plot_richness(physeq = pseq_rarefy, x = &quot;media&quot;, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) + ggplot2::geom_boxplot() #Save ggplot2 object with ggsave ggsave(filename = &quot;./Alpha_diversity_media_boxplot.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file=&quot;./Alpha_diversity_media_boxplot.png&quot;) We can also add semi transparent dots representing the values for each sample. To do this, add the ggplot2 layer ggforce::geom_sina(). This has the option alpha=0.5 where alpha resents the transparency of the dots and 0.5 represents 50% transparency. Alpha is a common option used for many plots. # Produce ggplot object of violin plot alpha_boxplot &lt;- phyloseq::plot_richness(physeq = pseq_rarefy, x = &quot;media&quot;, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) + ggplot2::geom_boxplot() + ggforce::geom_sina(alpha=0.5) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Alpha_diversity_media_boxplot.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file=&quot;./Alpha_diversity_media_boxplot.png&quot;) 15.5 Alpha: Site plots and statistics With all the knowledge, skills, and code from this chapter carry out the following tasks: Produce a violin plot of Observed, Chao1, Shannon, and Inverse Simpson with the Site groups. Carry out paired Wilcoxon test for Observed, Chao1, Shannon, and Inverse Simpson with the Site groups. Alpha sites solution # Produce ggplot object of violin plot alpha_boxplot &lt;- phyloseq::plot_richness(physeq = pseq_rarefy, x = &quot;site&quot;, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) + ggplot2::geom_boxplot() + ggforce::geom_sina(alpha=0.5) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Alpha_diversity_site_boxplot.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file=&quot;./Alpha_diversity_site_boxplot.png&quot;) #Paired wilcoxon test #Observed pairwise.wilcox.test(alpha_df$Observed, phyloseq::sample_data(pseq_rarefy)$site) #Chao1 pairwise.wilcox.test(alpha_df$Chao1, phyloseq::sample_data(pseq_rarefy)$site) #Shannon pairwise.wilcox.test(alpha_df$Shannon, phyloseq::sample_data(pseq_rarefy)$site) The plots and stats do not show anything particularly interesting in terms of site unfortunately. There is too much difference caused by the media. To view this we can add the option aes(colour=media) to ggforce_sina(). This will colour the points by media. If we only do this it will give us a legend with the title \"colour\". We can fix this by adding the layer `ggplot2::labs(colour = \"Media\"). # Produce ggplot object of violin plot alpha_boxplot &lt;- phyloseq::plot_richness(physeq = pseq_rarefy, x = &quot;site&quot;, measures = c(&quot;Observed&quot;,&quot;Chao1&quot;,&quot;Shannon&quot;) + ggplot2::geom_boxplot() + ggforce::geom_sina(alpha=0.5, aes(colour=media)) + ggplot2::labs(colour = &quot;Media&quot;) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Alpha_diversity_site_boxplot.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file=&quot;./Alpha_diversity_site_boxplot.png&quot;) When you are happy you can close and halt the notebook. 15.6 Alpha: summary In this chapter we have created alpha diversity plots and run pairwise comparisons. The biggest difference between samples is caused by the media choice which overwrites differences we can see between sites. The environmental samples have much higher diversirty samples than the media samples but this is expected. "],["16-Beta.html", "Chapter 16 Beta 16.1 Beta: setup 16.2 Beta: ordination 16.3 Beta: plot ordination 16.4 Beta: statistics", " Chapter 16 Beta In this chapter we are going to carry out beta diversity analysis. This will include the production of ordination plots and statistical analysis. When carrying out beta diversity all samples are compared in a pairwise manner. Using various metrics a table of pairwise distances is created. These distance are dissimilarity measures with smaller values indicating higher similarity and larger values representing higher dissimilarity. With these dissimilarity measures we can produce scatter plots based (e.g. PCoA, &amp; NMDS plots). Samples with low dissimilarity (i.e. similar samples) will be close to each other (cluster). Samples with high dissimilarity will be apart from each other. In a perfect example samples from the same group will form clusters that are distinct from the clusters of other groups. In this chapter we will: Calculate beta diversity ordination metrics plot it as a scatter plot. Determine if there is a statistical difference between beta diversity metrics of sample groups. 16.1 Beta: setup We will use a new notebook called \"6-beta_diversity.ipynb\". Add the following to the top of this new notebook to load the required libraries/packages and data. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;IRdisplay&quot;) #Load phyloseq object load(&quot;phyloseq_rarefied.RData&quot;) 16.2 Beta: ordination In this section we will ordinate our data with the phyloseq::ordinate() function. We will ordinate using the MDS method (AKA PCoA). We will be using the Weighted Unifrac metric as beta diversity dissimilarity scores. This uses the count data along with the phylogenetic distances to calculate pairwise dissimilarity. #Ordinate data ord.mds.wunifrac &lt;- phyloseq::ordinate(pseq_rarefy, metho = &quot;MDS&quot;, distance = &quot;wunifrac&quot;) To see the different methods and distances that can used please try ?phyloseq:ordinate and ?distance respectively. More information about the different distances please see the APPENDIX. ADD LINK TO APPENDIX 16.3 Beta: plot ordination Now that we have our ordination we can plot it. The below script uses phyloseq::plot_ordination() to plot our ordination. It needs the phyloseq object used for ordination (for the metadata) and the ordination data. We will add the options color = and shape = to colour the points by site and shape the points by media. #Plot ordination nmds.wunifrac &lt;- phyloseq::plot_ordination(pseq_rarefy, ord.mds.wunifrac, color = &quot;site&quot;, shape = &quot;media&quot;) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Beta_diversity_mds_wunifrac_media_site.png&quot;, plot = nmds.wunifrac, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 125, width = 150) #Display plot IRdisplay::display_png(file=&quot;./Beta_diversity_mds_wunifrac_media_site.png&quot;) In this plot we can see that there are 3 main clusters: TSA ENV CVP &amp; KBC A very important feature of ordination plots is the percentage values on the axes. These are the percentage variation explained values. These values show how much of the variation of the data is explained by each axis. We need these as we are converting high dimensional data (many pairwise comparisons) into a 2 dimensional plot. In our plot axis 1 has a very high percentage variation explained value of 72.5%. This indicates that most of the variation in our data is explained by the differences between the media samples (CVP, KBC, &amp; TSA) and the ENV samples. This is because the ENV samples are far removed (large distances) from the media samples in terms of axis 1. On the other hand, axis.2 (15.8%) seems to be primarily showing the difference between the TSA samples and the other samples, and within the TSA samples. The higher the total variation explained value is the better are plot represents the beta diversity in our data. In this case the total is &gt;88% which is very good. &lt;30% is poor &gt;30% is not very good &gt;50% is good &gt;70% is very good &gt;90% is exceptional Additonally, we can see that there seems to be some separation of the sites within the different media groups. This is clear in TSA and ENV but not in CVP and KBC since the cluster is very tight (short distances). 16.4 Beta: statistics "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
