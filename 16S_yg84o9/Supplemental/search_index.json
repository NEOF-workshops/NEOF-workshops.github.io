[["01-16S_supplemental.html", "Bacterial 16S metabarcoding supplemental Chapter 1 Introduction", " Bacterial 16S metabarcoding supplemental Matthew Gemmell 2023-06-19 Chapter 1 Introduction This bookdown is a supplement to the main one. It contains some workflows and tools that are not part of the core QIIME2 workflow. However, they may prove useful depending on your needs. The sections in this supplement will cover: Exporting QIIME2 artifacts to text files Handy QIIME2 commands Carrying our functional prediction with a taxonomy abundance table Introduction to some R packages for 16S rRNA analysis Ensure you have the QIIME2 environment activated for all of these materials. For convenience the command is: . useqiime2-2021.2 This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Exporting_artifacts.html", "Chapter 2 Exporting Artifacts 2.1 BIOM files 2.2 Setup 2.3 Abundance table export 2.4 Taxonomy info export 2.5 Representative sequences export 2.6 Phylogenetic tree export 2.7 ASV table with taxonomy export 2.8 Rarified table export 2.9 Relative abundance table export 2.10 Taxonomy abundance table export", " Chapter 2 Exporting Artifacts Artifact files are very useful when carrying out analysis in QIIME2. However they are impossible to use (I think) with anything outside of QIIME2. Therefore it can be very useful to know how to export data out of Artifact files. This section will show how to export various different artifact files into text files. However, for some data types they must be converted into a BIOM file first. 2.1 BIOM files BIOM stands for BIological Observation Matrix. BIOM files generally contain abundance tables. These files are not human-readable but can be used with certain programs. Here we will only manipulate them in such ways to get the text files we need. For more information on the BIOM format please see: https://biom-format.org/ We will be using the command biom convert to convert BIOM files to TSV (Tab Separated Value) files. For more info on this please see: https://biom-format.org/documentation/biom_conversion.html 2.2 Setup First copy a new directory that will contain all the QIIME2 output you need and then change directory to it. cp -r /pub39/tea/matthew/NEOF/16s_workshop/16s_export ~/Metagenetics cd ~/Metagenetics/16s_export Before we start exporting it is best to make a few directories. mkdir export mkdir qiime2_exports mkdir final_exports export: This directory is where we will point the various qiime tools export commands. You can only specify an output directory for this command and the command will give the exported file very generic names. This makes it very easy to overwrite files when using this command. qiime2_exports: For some of the exported files we will move and rename them from export to this directory. This is an temporary directory for files we will not want at the end (mostly BIOM files). final_exports: This directory will contain the final exported files we would generaly want to keep. 2.3 Abundance table export First we will export our ASV abundance table. We will have to convert the BIOM file produced by QIIME2 to a TSV file. Export the table to a directory. This will create a BIOM file called feature-table.biom. qiime tools export --input-path table-dada2.qza --output-path export Move the created file whilst renaming it. mv export/feature-table.biom qiime2_exports/ASV_table.biom Finall we will use biom convert to create our TSV file. biom convert \\ -i qiime2_exports/ASV_table.biom \\ -o final_exports/ASV_table.tsv \\ --to-tsv The option --to-tsv (or alternative) must be provided or the command will not run and only complain. Use a text viewer/editor of your choice to inspect the final file. Make sure to do this for all the files in this tutorial. 2.4 Taxonomy info export Exporting the taxonomy info. qiime tools export --input-path taxonomy.sklearn.qza \\ --output-path export #Move the produced tsv file to the final_exports directory mv export/taxonomy.tsv final_exports 2.5 Representative sequences export Export the representative sequences to a fasta file. qiime tools export --input-path rep-seqs-dada2.qza \\ --output-path export #Move and rename the produced fasta file mv export/dna-sequences.fasta final_exports/ASV_rep_seqs.fasta 2.6 Phylogenetic tree export The below exports the specified phylogenetic tree into a newick format file. For more info on the Newick format please see: https://en.wikipedia.org/wiki/Newick_format qiime tools export --input-path rooted-tree.qza \\ --output-path export #Move and rename the exported newick file mv export/tree.nwk final_exports/fasttree_rooted_tree.nwk 2.7 ASV table with taxonomy export This step will produce a TSV file containing the ASV abundance table with the last column containing the taxonomy assignment of the ASV. To carry out this step you will need the BIOM format produced in the abundance table export and the exported taxonomy file. We need to change the header of the taxonomy file for it to be compatible with the biom command. First create a copy which we will edit cp final_exports/taxonomy.tsv final_exports/taxonomy.header.tsv Then using a text editor of your choice (nano, vim, emacs, etc.) change the first and second column headers to #OTUID and taxonomy. Now we can create a new BIOM file which contains the taxonomy information biom add-metadata \\ --input-fp qiime2_exports/ASV_table.biom \\ --observation-metadata-fp final_exports/taxonomy.header.tsv \\ --output-fp qiime2_exports/ASV_table.tax.biom Export the newly created BIOM file. We will need to include option --header-key taxonomy to include the taxonomy info in the newly TSV file. biom convert \\ -i qiime2_exports/ASV_table.tax.biom \\ -o final_exports/ASV_table.tax.tsv \\ --header-key taxonomy \\ --to-tsv 2.8 Rarified table export You can export a rarefied table. The first step of this is to rarefy our ASV table artifact. The option --p-sampling-depth is our rarefaction threshold. We will choose 20,000 for this example but make sure to pick an appropriate one for your own projects. qiime feature-table rarefy \\ --i-table table-dada2.qza \\ --p-sampling-depth 20000 \\ --o-rarefied-table table-dada2.rarefied_20000.qza After that it is the normal export and convert commands. To be fancy we will include the taxonomy information in the final file. #Qiime tools export qiime tools export \\ --input-path table-dada2.rarefied_20000.qza \\ --output-path export #Move and rename exported biom mv export/feature-table.biom qiime2_exports/ASV_table.rarefied_20000.biom #Add taxonomy info to biom file #Ensure to use the taxonomy with the altered headers biom add-metadata \\ --input-fp qiime2_exports/ASV_table.rarefied_20000.biom \\ --observation-metadata-fp final_exports/taxonomy.header.tsv \\ --output-fp qiime2_exports/ASV_table.rarefied_20000.tax.biom #Convert biom to tsv with taxonomy biom convert \\ -i qiime2_exports/ASV_table.rarefied_20000.tax.biom \\ -o final_exports/ASV_table.rarefied_20000.tax.tsv \\ --header-key taxonomy \\ --to-tsv 2.9 Relative abundance table export Instead of an abundance table you may want a relative abundance table. Thankfully this can easily be done in QIIME 2 with the following command. Note: You will most likely want to get the relative abundance from a rarefied table. qiime feature-table relative-frequency \\ --i-table table-dada2.rarefied_20000.qza \\ --o-relative-frequency-table table-dada2.rarefied_20000.relabund.qza Then you can export it the same way as the rarefied abundance table. #Qiime tools export qiime tools export \\ --input-path table-dada2.rarefied_20000.relabund.qza \\ --output-path export #Move and rename exported biom mv export/feature-table.biom \\ qiime2_exports/ASV_table.rarefied_20000.relabund.biom #Add taxonomy info to biom file biom add-metadata \\ --input-fp qiime2_exports/ASV_table.rarefied_20000.relabund.biom \\ --observation-metadata-fp final_exports/taxonomy.header.tsv \\ --output-fp qiime2_exports/ASV_table.rarefied_20000.relabund.tax.biom #Convert biom to tsv with taxonomy biom convert \\ -i qiime2_exports/ASV_table.rarefied_20000.relabund.tax.biom \\ -o final_exports/ASV_table.rarefied_20000.relabund.tax.tsv \\ --header-key taxonomy \\ --to-tsv 2.10 Taxonomy abundance table export The last recipe I will show you is how to create and then export a taxonomy abundance table. First we collapse our ASV table to a specific taxonomy level. This is carried out by specifying a number to the option --p-level in the command below. With Silva and Greengenes the numbers normally correspond to: Kingdom Phylum Class Order Family Genus Species Be careful though as with some taxonomy databases the levels are not consistent between different organisms. This occurs if sub-level information (such as sub-order, sub-family etc.) is included in some but not all taxonomic classifications. This could mean that the 5th level taxonomy of one organisms could be its sub-order whilst another’s could be its family. Check your export/taxonomy.tsv to see if this could be an issue or not. We will now run our taxonomy collapse command on our rarefied table to produce a Family abundance table. Note: The below command can not be run on a relative abundance table. You will have to run the relative frequency command on its output if you want relative abundance family table. qiime taxa collapse \\ --i-table table-dada2.rarefied_20000.qza \\ --i-taxonomy taxonomy.sklearn.qza \\ --p-level 5 \\ --o-collapsed-table table-dada2-family.rarefied_20000.qza Then you can export it in a similar way as the other tables. However, we should not include the step that adds the taxonomy for this. #Qiime tools export qiime tools export \\ --input-path table-dada2-family.rarefied_20000.qza \\ --output-path export #Move and rename exported biom mv export/feature-table.biom qiime2_exports/family_table.rarefied_20000.biom #Convert biom to tsv with taxonomy biom convert \\ -i qiime2_exports/family_table.rarefied_20000.biom \\ -o final_exports/family_table.rarefied_20000.tsv \\ --to-tsv I hope this is a nice quick reference for your future use. "],["03-Handy_QIIME2_commands.html", "Chapter 3 Handy QIIME2 commands 3.1 Create a manifest file 3.2 Filter ASVs from a table 3.3 Split tables 3.4 Merge tables", " Chapter 3 Handy QIIME2 commands This section will contain a few useful commands for QIIME2 analysis. Copy over a directory with the content you will need and move into it for this section. cp -r /pub39/tea/matthew/NEOF/16s_workshop/handy_qiime2_cmds ~/Metagenetics cd ~/Metagenetics/handy_qiime2_cmds 3.1 Create a manifest file In the main practical you used a premade manifest file. However, in your own analyses you will need to create your own manifest files based on the path of your fastq files. This can be done through manually typing all the information. However, it is best to use commands to create this automatically. The first step is to create a manifest file with the header line. echo &quot;sample-id,absolute-filepath,direction&quot; &gt; manifest.csv Next we will use two long commands with many pipes (|) to append the lines we need to our file. Below are the two commands and below that is an explanation on the various parts. #Append lines for forward reads find /pub39/tea/matthew/NEOF/16s_workshop/RawReads/ -name *R1*fastq.gz | \\ while read path ; do \\ sample=$(basename $path | sed &quot;s/_.*//&quot;) ; \\ echo ${sample},${path},forward ; \\ done &gt;&gt; manifest.csv #Append lines for reverse reads find /pub39/tea/matthew/NEOF/16s_workshop/RawReads/ -name *R2*fastq.gz | \\ while read path ; do \\ sample=$(basename $path | sed &quot;s/_.*//&quot;) ; \\ echo ${sample},${path},reverse ; \\ done &gt;&gt; manifest.csv Note the above is quite complicated and you may get away with just changing the specified directory for your own analyses. Always make sure you check the output manifest file before importing with it. If it is wrong make sure to start from the first step so you reset your file. find /pub39/tea/matthew/NEOF/16sworkshop/RawReads/ -name *R1*fastq.gz This will find all the absolute paths from the specified directory and its subdirectories (/pub39/tea/matthew/NEOF/16sworkshop/RawReads/) that contain “R1” and end with “fastq.gz” (-name *R1*fastq.gz). Ensure the specified directory and its subdirectories only contain your fastq files of interest. while read path ; This is a loop that will loop through all the returned file paths. Everything between the do and done are the commands run in the loop. path is the variable name of the aboslute file path that is used in each instance of the loop. The ; separates commands within the loop. sample=$(basename $path |sed \"s/_.*//\") The sample=$() section assigns a variable called sample to the output from the command/s within $() The command basename removes all the directory path info so you are only left with the file name (e.g. /path/directory/file.txt -&gt; file.txt) sed \"s/_.*//\" is a sed command that will substitute (s) everything after the first “_” (_.*) with nothing (represented by nothing between the last two /). E.g. 3TM_CAGAGAGG-GTAAGGAG_L001_R1_001.fastq.gz -&gt; 3TM More info on sed: https://www.gnu.org/software/sed/manual/sed.html echo ${sample},${path},forward This will create a line for the absolute file path containing the sample name, absolute file path, and read direction separated by commas. &gt;&gt; manifest.csv This appends the output from the loop into our file of interest. If you only use &gt; you will overwrite the file, removing previously added lines. The command is run twice, once for the R1/forward reads and once for the R2/reverse reads. Ensure you change the R1 -&gt; R2 in the find -name option and the forward -&gt; reverse in the echo command for the R2/reverse read running of the command. 3.2 Filter ASVs from a table QIIME2 has many methods to filter out ASVs. I find a lot of these methods are hard to use and I have had much difficulty trying to use them in the past. Thankfully one method always appears to work. The functioning method requires a metadata file to be provided that contains ASV names. The file must have a header of feature-id and then have the names of ASVs you would like removed. An example called asv_names.txt is in your directory. Look at it with less, these are simply the last 10 ASVs in the table for demonstrative purposes. Now we will filter our table to remove these ASVs. #Filter command qiime feature-table filter-features \\ --i-table table-dada2.qza \\ --m-metadata-file asv_names.txt \\ --p-exclude-ids \\ --o-filtered-table table-dada2.asv_filtered.qza #Create new visualisation qiime feature-table summarize \\ --i-table table-dada2.asv_filtered.qza \\ --o-visualization table-dada2.asv_filtered.qzv You can compare the number of features shown in the new table-dada2.asv_filtered.qzv to the provided table-dada2.qzv to ensure that 10 features have been removed. If you do not include the option --p-exclude-ids you will insetad filter out all ASVs except the ASVs in the provided metadata file. You may want to filter out certain ASVs due to certain reasons. Maybe you would like to remove a taxonomic group or remove ASVs below a relative abundance threshold. I wll generally get my list of ASVs using an exported file, such as the ASV_table.rarefied_20000.tax.tsv file created in the “exporting artifacts” chapter or through R (only for those familiar with R and the packages introduced in the 16S R packages chapter). 3.3 Split tables It is possible you may run multiple 16S experiments on a single Illumina run. In this case it can be useful to run it all together for the steps up to and including the phylogenetic tree construction if the experiments are relatively similar (i.e. if they are human gut samples). If the experiments are not similar (i.e. human gut and soil microbiome) I would suggest to split the table after the dada2 denoising. However, I might suggests to keep the samples separate from the start if the experiments are very different as it may make the dada2 denosing take a very long time. Then you would want to split the table into the different experiments. This is done in a similar manner as filtering out ASVs except we filter out samples. The metadata file we use for filtering is the same metadata file we use for alpha and beta diversity analysis, except it must only contain the samples we want included. View the 3 metadata files begiining with “experiment_”. Now we will use those 3 files to create 3 new tables. #Create table for experiment 1 qiime feature-table filter-samples \\ --i-table table-dada2.qza \\ --m-metadata-file experiment_1_metadata.txt \\ --o-filtered-table experiment_1_table.qza #experiment 2 qiime feature-table filter-samples \\ --i-table table-dada2.qza \\ --m-metadata-file experiment_2_metadata.txt \\ --o-filtered-table experiment_2_table.qza #experiment 3 qiime feature-table filter-samples \\ --i-table table-dada2.qza \\ --m-metadata-file experiment_3_metadata.txt \\ --o-filtered-table experiment_3_table.qza It is always important to check your output. Create a visualisation file for each table and then view it with QIIME2 view to ensure they contain only the samples you want. #experiment 1 qiime feature-table summarize \\ --i-table experiment_1_table.qza \\ --o-visualization experiment_1_table.qzv #experiment 2 qiime feature-table summarize \\ --i-table experiment_2_table.qza \\ --o-visualization experiment_2_table.qzv #experiment 3 qiime feature-table summarize \\ --i-table experiment_3_table.qza \\ --o-visualization experiment_3_table.qzv This is also a quick way to remove controls that you do not need in the table any more. The taxonomy, representative sequences, and phylogeny file can all be left as they are and can be used for all the split tables normally. 3.4 Merge tables The opposite of the last section may occur, where you have one experiment over multiple runs. Each run must be run through the QIIME2 steps up to and including the dada2 denoising step. Then they should be merged. As an example we will merge the tables for the 3 experiments back together. #Merge command qiime feature-table merge \\ --i-tables experiment_1_table.qza \\ --i-tables experiment_2_table.qza \\ --i-tables experiment_3_table.qza \\ --o-merged-table experiments_1_2_3_table.qza #Visualise command to ensure it worked properly qiime feature-table summarize \\ --i-table experiments_1_2_3_table.qza \\ --o-visualization experiments_1_2_3_table.qzv If you were merging the output from multiple dada2 commands you would also need to merge the representative sequence artifacts. Below is an example command (don’t run the below one as we don’t have files). qiime feature-table merge-seqs \\ --i-data experiment_1_rep-seqs-dada2.qza \\ --i-data experiment_2_rep-seqs-dada2.qza \\ --i-data experiment_3_rep-seqs-dada2.qza \\ --o-merged-data experiments_1_2_3_rep-seqs-dada2.qza Hopefully you will find this section useful in the future if not now. "],["04-Functional_prediction.html", "Chapter 4 Functional prediction 4.1 PICRUSt2 pipeline 4.2 Commands 4.3 Visualisation 4.4 PICRUSt2 Links", " Chapter 4 Functional prediction Functional prediction is a method to infer the functional pathways within a community. PICRUSt2 uses 16s sequences to infer abundances of the following types of pathways: EC: Enzyme Classification, https://www.qmul.ac.uk/sbcs/iubmb/enzyme/. KO: KEGG Orthology, https://www.genome.jp/kegg/ko.html. MetaCyc: Metabolic pathway, https://metacyc.org/. 4.1 PICRUSt2 pipeline The PICRUSt2 pipeline consists of 5 major steps. The entire pipeline can be visualised below. The steps are: The representative sequences for each ASV are aligned to reference sequences. These reference sequences are within the PICRUSt2 database. The aligned ASV sequences are placed into the PICRUSt reference tree. This allows PICRUSt2 to know the phylogenetic distances between its reference sequences and the ASV sequences. The gene family copy numbers of the ASVs are inferred. This is carried out by comparing an ASV to its phylogenetic neighbours. The gene family copy numbers of the reference genomes (represented by reference sequences) is known. PICRUSt2 therefore predicts that ASVs will have similar gene family copy numbers to closely related sequences/genomes. Gene family abundances are calculated for each sample. This is calculated using the predicted gene content per ASV and the ASV abundances. Pathway abundances are calculated using the predicted gene family abundances and a map of gene families to pathways. 4.2 Commands We will use the abundance table we created in the main QIIME2 tutorial for PICRUSt2. It is recommended to not rarefy the table prior to the PICRUSt2 analysis. Copy over the directory with the relevant files (including the table artifact) and then move into it. cp -r /pub39/tea/matthew/NEOF/16s_workshop/picrust2 ~/Metagenetics cd ~/Metagenetics/picrust2 Although we do not want the table rarefied it is recommended to filter the table to remove very rare ASVs and to remove low depth samples. First we will filter low frequency features/ASVs. You can look at the visualisation of table-dada2.qzv to see an overview of “Frequency per feature”. There seems to be no clear consensus of how many rare features should be filtered. In this case we are going to filter out features/ASVs with a frequency less than 10 across all samples. With 18 samples and a mean frequency of &gt;900 this should be safe. #Filter features command qiime feature-table filter-features \\ --i-table table-dada2.qza \\ --p-min-frequency 10 \\ --o-filtered-table table-dada2.feat_min_freq_10.qza #Visualise filtered table qiime feature-table summarize \\ --i-table table-dada2.feat_min_freq_10.qza \\ --o-visualization table-dada2.feat_min_freq_10.qzv Check the visualisation to see how many rare ASVs have been removed. The next step would then be to remove samples with too low a depth. Generally I would say 20,000 would be a good cutoff but it does depend on your data and what the rarefaction curves show. For demonstration purposes we will choose a depth cutoff of 50,000. We can therefore use the below command to remove samples with a depth lower than 50,000. #Filter command qiime feature-table filter-samples \\ --i-table table-dada2.feat_min_freq_10.qza \\ --p-min-frequency 50000 \\ --o-filtered-table table-dada2.feat_min_freq_10.sample_min_freq_50k.qza # Visualise filtered table qiime feature-table summarize \\ --i-table table-dada2.feat_min_freq_10.sample_min_freq_50k.qza \\ --o-visualization table-dada2.feat_min_freq_10.sample_min_freq_50k.qzv Now that we have carried out the filtering we can run the PICRUSt2 pipeline. The command to run the full PICRUSt2 pipeline is: qiime picrust2 full-pipeline \\ --i-table table-dada2.feat_min_freq_10.sample_min_freq_50k.qza \\ --i-seq rep-seqs-dada2.qza \\ --output-dir q2-picrust2_output \\ --p-placement-tool sepp \\ --p-threads 1 \\ --p-hsp-method pic \\ --p-max-nsti 2 \\ --verbose The command will take ~30 minutes. If you would like to skip running the command or you encounter an issue you can copy the output. cp -r /pub39/tea/matthew/NEOF/16s_workshop/q2-picrust2_output ~/Metagenetics/picrust2 Notes The developers recommend using --p-placement-method epa-ng and --p-hsp-method mp in real analysis. You may also need to include --p-edge-exponent 0 . The options above were chosen due to speed. For information on the parameters please see: https://github.com/picrust/picrust2/wiki/q2-picrust2-Tutorial Issues I have encountered an issue when trying to rerun the PICRUSt2 command with files and directories I have used before. This issue causes the command to fail. This would occur if you rerun with different parameters or a newly filtered file. The way to get around it, seemingly, is to create a new directory somewhere else and copy over the required files to the new directory. Then run the command in the new directory. 4.3 Visualisation Next we will carry out some quick visualisations. First move into the newly created directory with the output. cd ~/Metagenetics/picrust2/q2-picrust2_output List the files in the directory and you will see 3 files: ec_metagenome.qza: Abundance table for Enzyme Classifications. ko_metagenome.qza: Abundance table for KEGG Orthology. pathway_abundance.qza: Abundance table for MetaCyc pathways. We’ll look at the KOs, the first step being to summarize the table. qiime feature-table summarize \\ --i-table ko_metagenome.qza \\ --o-visualization ko_metagenome.qzv Look at the visualisation and you should notice very high frequencies. This is expected as each KO will most likely be found in multiple ASVs. The frequency of a KO is based on the frequency of every ASV it has been matched to. Additionally there are more features (KOs) in this table than in the ASV table. Let us see how the numbers change with the pathways abundance table. qiime feature-table summarize \\ --i-table pathway_abundance.qza \\ --o-visualization pathway_abundance.qzv In this case there are fewer features (pathways) because it is a broader classification (pathways rather than gene orthologs). With these tables you can carry out downstream analysis such as alpha and beta diversity, biomarker detection etc. If you do this in the future you can most likely use the lowest sample frequency number as it will most likely be over 100k. 4.4 PICRUSt2 Links That was a quick run introduction to PICRUSt2. There are good tutorials online you can use to get a stronger understanding of it. Key limitations of analysing PICRUSt2 output: https://github.com/picrust/picrust2/wiki/Key-Limitations Q2 PICRUSt2 tutorial: https://github.com/picrust/picrust2/wiki/q2-picrust2-Tutorial Q2 PICRUSt2 installation: https://library.qiime2.org/plugins/q2-picrust2/13/ PICRUSt2 tutorial: https://github.com/picrust/picrust2/wiki/PICRUSt2-Tutorial-(v2.4.1) "],["05-16S_R_packages.html", "Chapter 5 16S R packages 5.1 qiime2R 5.2 phyloseq 5.3 microbiome", " Chapter 5 16S R packages There are various R packages that can be used to analyse 16S data. Generally these will take the output from QIIME2 so you can carry out further downstream analysis on the QIIME2 created ASV table, taxonomy, and phylogenetic tree. I would recommend only those with a good foundation in R to use these packages. If you do not have this I would recommend trying to gain it. 5.1 qiime2R https://github.com/jbisanz/qiime2R qiime2R is an R package to import QIIME2 artifacts into R compatible files. It can convert artifacts into data structures that are useable in R. Additionally it can also create some plots. One of its most useful commands is qza_to_phyloseq() which converts a .qza artifact into the phyloseq data structure. 5.2 phyloseq https://joey711.github.io/phyloseq/ phyloseq is a very powerful R package to carry out microbiome profile analysis. It is a great way to produce custom plots for alpha and beta diversity, heatmaps, network plotting, etc. It can be used to analyse any type of community based data such as shotgun metagenomic data. There are two large caveats: It can be quite difficult and laborious to convert data to the required phyloseq R object (a data structure created for phyloseq). qiime2R does make this much easier for 16S data though. The documentation can be quite hard to follow and assumes you already have a lot of specific knowledge. It uses ggplot2 coding conventions so it is essential you learn the R package “ggplot2” prior to trying phyloseq. 5.3 microbiome https://microbiome.github.io/tutorials/ Once you start using phyloseq you will probably notice there are many commands missing you may require. Thankfully the microbiome R package is a very good supplemental package to phyloseq. This package supports the phyloseq data format and acts to expand the available toolkit to analyse this data format. I would highly recommend using it if you start using phyloseq. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
