[["01-Intro.html", "RNA-seq gene expression and pathway analysis Chapter 1 Introduction", " RNA-seq gene expression and pathway analysis Katy Maher, Helen Hipperson, Steve Paterson, Bert Overduin, Matthew Gemmell, Xuan Liu 2023-06-01 Chapter 1 Introduction In this practical session we will introduce you to the analysis of RNA-seq datasets. We will go through: Background Logging onto our teaching VNC and accessing the data Quality control Aligning Illumina data to a reference genome Counting reads Differential gene expression Gene Ontology enrichment analysis This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Background.html", "Chapter 2 Background", " Chapter 2 Background We will carry out a differential gene expression analysis of a subset of Drosophila pseudoobscura samples from a sexual selection experiment. RNA-Seq (AKA whole transcriptome shotgun sequencing) aims to determine the presence and quantity of RNA in a biological sample at a given moment in time, i.e. allows you to determine the transcriptome. Whilst the genome of an organism shows the genes present in an organism the transcriptome allows you to determine the level of expression of these genes. When comparing the transcriptome of different biological samples you are analysing the Differential Gene Expression (DGE). Analyses of differential gene expression (DGE) tend to follow a similar pattern to the above image. There are variations on this pattern. For instance, if no genes have been annotated in the reference genome these can be annotated using the RNA-seq reads as a guide. If no reference genome has been sequenced, it may be possible to assemble RNA-seq reads directly, but this is very computationally intensive. We will not be assembling de-novo transcriptomes in this workshop, instead we will map our reads to an assembled genome. "],["03-Cluster_Introduction.html", "Chapter 3 Cluster Introduction 3.1 Logon instructions 3.2 The Terminal Window 3.3 Accessing the example data", " Chapter 3 Cluster Introduction 3.1 Logon instructions For this workshop we will be using Virtual Network Computing (VNC). Connect to the VNC with a browser by using the webVNC link you were sent. You will now be in a logged-in Linux VNC desktop with two terminals. You will see something as below (there may be only one terminal which is fine). If you do not see something similar please ask for assistance. If the VNC is taking up too much/little space of your browser you can use the zoom of your browser to adjust the size. Ensure you can see one whole terminal. These instructions will not work outside of this workshop. If you would like to install your own Linux OS on your desktop or laptop we would recommend Mint Linux The following link is a guide to install Mint Linux: https://linuxmint-installation-guide.readthedocs.io/en/latest/ 3.2 The Terminal Window In our case the terminal window looks like the picture below. We are using the terminal window as our shell to interpret our commands to the kernel. Depending on your system and preferences it may look different. Already there is useful information for us on the terminal window. nsc006: This is the login name, also known as the username. In this case nsc006 is a demonstrator's account. Your screen should show a different account name which will be your username for the Linux machine/cluster you are logged into. gauss03: This is the machine name the user is logged into. ~: This represents the current directory of the user, or the directory a command was run in. In the Linux OS and others '~' is a shortcut to the user's home directory. Everything after the '$' is where commands are typed into the terminal. This is also referred to as the command line. To open a new terminal window, right click on the main screen, choose Applications -&gt; Shell -&gt; bash 3.3 Accessing the example data Before we can start we first need to make a directory which will be used to contain all the files you generate throughout this workshop. To do this type the following commands. #Make sure you are in your home directory cd ~ Then copy the directory with the example data into your 'home' directory. cp -r /pub14/tea/nsc206/NEOF/rnaseq . You will need to activate the rnaseq conda environment before continuing. Carry this out with the following command. Note: Ensure you include the dot and space (. ) at the start before usernaseq . usernaseq You're now ready to start the analyses! "],["04-QC.html", "Chapter 4 Quality Control 4.1 Workshop data 4.2 Quality assessment 4.3 Quality control", " Chapter 4 Quality Control This tutorial will give hands on experience with quality control of transcriptomic Illumina data. We will first look at the quality of the data. 4.1 Workshop data Before we can carry on with the workshop we need to change into the directory containing the raw data for two Drosophila samples. cd ~/rnaseq/Practical_one List the contents of the current directory to confirm the four fastq files are there (the files ending in .fq.gz). ls Have a look at the structure of the input fastq file: zcat 17_slice_R1.fq.gz | head These fastq files are compressed (with the .gz file extension). zcat is a command for viewing the contents of compressed files, the pipe | symbol then passes this to head to display only the first few lines of the file. Fastq files contain a header line, the nucleotide sequence, and its corresponding quality scores. You can see more information on the fastq file format in our intro to unix materials. 4.2 Quality assessment Weâ€™ll run the raw sequence data through FastQC to summarise the data quality. First make a directory for the output. mkdir raw_fastqc_output Now we can run fastqc. Note: The below command can be run over one line excluding the \\ Alternatively, you can type \\ during a command and then press the enter key. The next line on the command line will start with &gt;. This will allow you to continue typing the command on the line. This can be used to type one command over multiple lines. fastqc -o raw_fastqc_output \\ 17_slice_R1.fq.gz 17_slice_R2.fq.gz Normally when you run a command it will run the process in the foreground. This means your command line will be locked whilst the process is running. You will only be able to type a new command in the terminal once the foreground process is finished. This is usually wanted but not always, for example when you run a process like firefox. To run a process in the background, so you can type and run new commands, you can add the symbol &amp; to the end of a command. We will use this for running firefox. Please see the following link for more info on the foreground and background. Using firefox have a look at the output html reports and answer the following questions. To look at the R1 &amp; R2 fastqc output (2 tabs will be opened): firefox raw_fastqc_output/17_slice_R1_fastqc.html &amp; You may see a warning message on your terminal, but you can press enter to continue to type in the terminal. To look at R2 fastqc output firefox raw_fastqc_output/17_slice_R2_fastqc.html &amp; 4.2.1 Quality assessment: questions Answer the following questions based on the reports. How many total reads are there in the R1 file? 44 101 539,580 What is the length of the reads? 44 101 539,580 What is the GC content (%) of the R2 reads? 44 101 539,580 In the read 2 (R2) file, at what base position range does the quality of the reads go below 28 (I.e. the position where a part of the boxplot, including outliers, goes into the orange)? 18-19 84-85 96-97 4.2.2 Quality assessment: summary In this case the reads seem to be good quality but we do see the quality decline towards the ends of the reads. This is common for Illumina datasets and will require trimming and filtering. Other common quality issues seen in most datasets: The R2 reads have poorer quality than the R1 reads The read sizes have a range compared to all being one size, however most of the reads are towards the long end of the range. Generally even if data does look very nice we would carry out quality control to get rid of any poor data that is masked by the very good data and to remove any adapter sequences. 4.3 Quality control Quality control generally comes in two forms: Trimming: This is directly cutting off bits of sequence. This is typical in the form of trimming off low quality bases from the end of reads and trimming off adapters at the start of reads. Filtering: This occurs when entire reads are removed. A typical occurrence of this is when a read is too small as we do not want reads below a certain length. To carry this out we are going to use Trimmomatic. First we'll make a directory for the trimmed dataset. mkdir trimmed To run Trimmomatic with the reads we will use the below command. trimmomatic \\ PE -phred33 \\ 17_slice_R1.fq.gz 17_slice_R2.fq.gz \\ trimmed/17_slice_R1_out_paired.fastq trimmed/17_slice_R1_out_unpaired.fastq \\ trimmed/17_slice_R2_out_paired.fastq trimmed/17_slice_R2_out_unpaired.fastq \\ ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 \\ LEADING:3 TRAILING:3 SLIDINGWINDOW:4:30 MINLEN:50 The parameter meanings are: PE: Input data consists of paired-end reads. -phred33: Type of quality Phred encoding. In this case it is phred33 as our fastq files use the sanger encoding like most Illumina data. Next the raw input forward (1) and then reverse (2) read files for quality control are specified. On the next line the output files for read 1 are specified, first for paired reads and second for unpaired reads. This comes about when one read from a pair is filtered out but the other one is not. We can normally ignore the unpaired file after the trimming. However, trimmomatic must have this value to run. Next the output files for read 2 are specified, first paired then unpaired. ILLUMINACLIP: These settings are used to find and remove Illumina adapters. First a fasta file of known adapter sequences is given, followed by the number of mismatches (2) allowed between the adapter and read sequence and then thresholds (30) for how accurate the alignment is between the adapter and read sequence. LEADING: The minimum quality value required to keep a base at the start of the read. TRAILING: The minimum quality value required to keep a base at the end of the read. SLIDINGWINDOW: This specifies to scan the read quality over a 4bp window, cutting when the average quality drops below 30. MINLEN: This specifies the minimum length of a read to keep, any shorter than 50bp are discarded. Once the command is run it will give you some useful output to the screen. Based on it, approximately what percentage of paired reads were kept? ~25% ~50% ~75% 4.3.1 Post Quality control check To see how successful the quality control has been we need to run fastqc on the trimmomatic output. First create a new directory for the fastqc output. mkdir trimmed_fastqc_output Now run fastqc on the two paired read files. fastqc -o trimmed_fastqc_output \\ trimmed/17_slice_R1_out_paired.fastq trimmed/17_slice_R2_out_paired.fastq We can open the fastqc output with the following commands firefox \\ trimmed_fastqc_output/17_slice_R1_out_paired_fastqc.html &amp; firefox \\ trimmed_fastqc_output/17_slice_R2_out_paired_fastqc.html &amp; 4.3.2 Quality control: questions To see how well the reads have improved letâ€™s answer the below questions and compare to them to the answers of the raw read fastqc questions. How many total reads are there in the R1 file? 44 50-101 409,267 What is the length of the reads? 44 50-101 539,580 What is the GC content (%) of the R2 reads? 44 50-101 539,580 In the read 2 (R2) file, at what base position range does the quality of the reads go below 28 (I.e. the position where a part of the boxplot, including outliers, goes into the orange)? 18-19 84-85 They don't 4.3.3 Quality assessment: summary Some things to note: The amount of reads has significantly decreased due to quality control. This is expected, however this will need to be taken into account. If you do not have enough reads for the downstream analysis you will need to be less stringent on the trimming or filtering. Often in your own datasets the R2 quality will still be slightly worse than R1 quality towards the end of the reads after trimming. Again this is normal. You could be more stringent but as previously mentioned you may be removing too many reads. We have successfully carried out quality control of our reads. With our good quality data we can go onto alignment. "],["05-Aligning.html", "Chapter 5 Aligning Illumina transcriptome data to a reference genome 5.1 Reference sequence preparation 5.2 Read mapping 5.3 Assess mapping quality 5.4 Visualising the mapping", " Chapter 5 Aligning Illumina transcriptome data to a reference genome HISAT2 is a fast and memory efficient alignment program for mapping next-generation sequencing reads (whole-genome, transcriptome, and exome sequencing data) against a reference genome. It is also a splice-aware aligner. Splice-aware aligners map reads over exon/intro junctions and are appropriate for aligning reads to a genome reference. Splice-unaware aligners are not aware of exon/intron junctions and are therefore only appropriate for mapping RNA-sequencing data to a transcriptome. 5.1 Reference sequence preparation HISAT2 uses indexing of the reference genome to speed up the mapping. The index needs to be prepared before we map our reads. To index the genome run hisat2-build -f slice.fa slice # view the index files ls This produces index files with the extension '.ht2' that will be automatically detected and used in the mapping step below. 5.2 Read mapping Now we are ready to map our reads. First make a directory for our output. mkdir aligned To map our paired-end, trimmed reads type the following: hisat2 \\ -x slice \\ -1 trimmed/17_slice_R1_out_paired.fastq \\ -2 trimmed/17_slice_R2_out_paired.fastq \\ -p 8 \\ -q \\ --met-file aligned/17_slice.stats | \\ samtools sort -O BAM &gt; \\ aligned/17_slice.sorted.bam The options used are: -x The index filename prefix -1 Path to forward paired-end reads to use for aligning -2 Path to reverse paired-end reads to use for aligning. -p Use this many threads to align reads. The default is 1 -q Reads are FASTQ files. FASTQ files usually have extension .fq or .fastq. FASTQ is the default format --met-file path Write hisat2 metrics to file. Having alignment metrics can be useful for debugging certain problems, especially performance issues. See also: --met. Default: metrics disabled. There are many different mapping parameters you can specify, see here. While it is often sufficient to run HISAT2 with default settings, we recommend reading the manual and considering your own dataset carefully when running any analysis. HISAT2 outputs a SAM file (Sequence Alignment Map format). However, here we pipe the output to samtools, a program for writing, viewing and manipulating alignment files, to sort and generate a BAM format, a binary, compressed version of SAM format. This sorts the SAM file by position (this is the default) and outputs it as a BAM file to save space. We can view this file using samtools view, and head to display only the first few lines: samtools view -h aligned/17_slice.sorted.bam | head The header section consists of lines starting with '@'. In this case we have a header line showing the SAM/BAM format version (@HD VN:), information on the reference sequence (@SQ) contig names (SN:) and lengths (LN:) and program information on how the SAM/BAM file was generated (@PG). To look at the information in the alignment section we can leave out the -h option: samtools view aligned/17_slice.sorted.bam | head Here is an example of one line, representing information from one sequence read. Each column contains information on where and how well the read aligns to the reference. After column 11 there can be several optional tags, often specific to the aligner used and can be useful for downstream analysis. The image above is from a different alignment file to the one you have generated here. On the first line of your alignment file what is the query sequence name? What is the reference contig name? 5.3 Assess mapping quality We can use the Samtools command flagstat to find information on how the reads mapped: samtools flagstat aligned/17_slice.sorted.bam How many reads have mapped? 5,734 824,268 762,382 700,842 This information is a summary of the 'FLAG' values - the second field in the sam/bam file. These values can be used if you want to extract or exclude a specific set of reads for downstream analysis. Here we will run a command that will keep only high quality, unique alignments and discard unmapped reads and unmapped mates. mkdir aligned_clean samtools view -b -q 40 -f 2 \\ -F 12 aligned/17_slice.sorted.bam &gt; \\ aligned_clean/17_slice.sorted.clean.bam The options used are: -b output in bam format -q have a mapping quality greater or equal to the number specified -f to include the reads with the specified flag -F only include reads without this flag The Broad Institute has a useful website to interpret the FLAG values, likewise they are listed in the samtools documentation. Run flagstat on the bam file from which we have excluded unmapped reads. How many reads are in the cleaned file in total? 690,248 824,268 700,842 345,124 What proportion of the reads in this file are now mapped? 0% 84% 98% 100% 5.4 Visualising the mapping To get a better feel for the mapping we have just done, we will visualise our mappings in IGV, the Integrative Genomics Viewer. First, we need to index the BAM file in order for the viewer to rapidly go to any bit of the genome: samtools index aligned_clean/17_slice.sorted.clean.bam To launch IGV first open a new terminal window: right click on the main screen, choose Applications -&gt; Shell -&gt; bash Then type: igv &amp; The &amp; (ampersand) opens IGV â€œin the backgroundâ€™, so you can still enter commands in the terminal window if you want. Once IGV has opened (this can take a few minutes) import the genome, mapped reads and gene annotations: To import the genome: Select â€˜Genomesâ€™ -&gt; â€˜Load Genome from Fileâ€¦â€™. Select slice.fa (which should be in rnaseq/Practical_one). Click [Open]. To import the mapped reads: Select â€˜Fileâ€™ -&gt; â€˜Load from Fileâ€¦â€™. Select 17_slice.sorted.clean.bam (which should be in rnaseq/Practical_one/aligned_clean). Click [Open]. To import the gene annotations: Select â€˜Fileâ€™ -&gt; â€˜Load from Fileâ€¦â€™. Select slice.FlyBase.gff (which should be in rnaseq/Practical_one). Click [Open]. And show this track in â€˜expandedâ€™ mode: Right-click on the slice.FlyBase.gff track label. Select â€˜Expandedâ€™. Now type Chr2:1,014,346-1,015,966 into the white box with â€˜Goâ€™ next to it. You should now be looking at gene FBgn0072602: Mapped reads are shown as fat grey arrows. Some of these are split across an intron. The blue track at the bottom shows the FlyBase gene annotations. You can move to different parts of the genome and you may see that some reads map well to the gene models and some donâ€™t. The latter will be due to a combination of 5â€™ and 3â€™-UTRs (which are not part of the gene annotations), reads transcribed from non-coding DNA, transposons, or from regions where the gene prediction program used to generate the models has missed a gene. The RNA-seq data here can be used to refine gene models, but thatâ€™s beyond the scope of this practical. "],["06-Counting_reads.html", "Chapter 6 Counting Reads using HTSeq-Count 6.1 Exercise", " Chapter 6 Counting Reads using HTSeq-Count The next step is counting the number of reads per gene and exon. For this we will use htseq-count. htseq-count needs a BAM file and an annotation (gff/gtf) file. First make a directory to contain our htseq output files. mkdir htseq We are now ready to run htseq-count. First we will run it to count the number of reads per gene. htseq-count \\ -m union \\ -s yes \\ -t gene \\ -i ID \\ -r pos \\ -f bam \\ aligned_clean/17_slice.sorted.clean.bam \\ slice.FlyBase.gff &gt; \\ htseq/17_genecount.htseq -m mode to handle reads overlapping more than one feature (â€˜unionâ€™ means that reads falling across an intron are counted) -s means our data is stranded, i.e. the sequenced read-pair occur in a particular orientation (for more information see here) -t feature type (3rd column in GFF file) to be used (e.g. gene or exon) -i GFF attribute to be used as feature ID. Several GFF lines with the same feature ID will be considered as parts of the same feature. The feature ID is used to identity the counts in the output table. -r For paired-end data, the alignment have to be sorted either by read name (name) or by alignment position (pos) -f Format of the input data. bam is specified for binary BAM files &lt;first flagless option&gt; is the BAM file you are wanting to count reads per feature in &lt;second flagless option&gt; is the name of the gff file In this case direct the output to a file we name \"17_genecount.htseq\" which is a text file. Lets have a look at the output file that we have generated. less htseq/17_genecount.htseq There are two columns, one for the name of the feature, the other for the number of reads mapping to each feature. We will now run htseq-count again. This time to count the number of reads per exon. htseq-count \\ -m union \\ -s yes \\ -t exon \\ -i ID \\ -r pos \\ -f bam \\ aligned_clean/17_slice.sorted.clean.bam \\ slice.FlyBase.gff &gt; \\ htseq/17_exoncount.htseq # To look at the output file less htseq/17_exoncount.htseq You now have your read counts per gene and per exon for one of your samples! 6.1 Exercise Repeat the process in chapters 4, 5, &amp; 6 to map the reads for the second sample 19_slice. You can load multiple BAM files in IGV to see how they compare. Tip: Avoid typing all commands for sample 19 from scratch by using the Linux history to go back to the commands for sample 17 and modify these for sample 19. Questions How many reads are in the R1 raw fastq file for 19_slice? 611,202 469,246 101 How many reads are in the R1 trimmed fastq file for 19_slice? 611,202 469,246 101 How many total reads are in the pre-filtered mapped bam file for 19_slice? 611,202 793,674 944,629 How many total reads are in the filtered mapped bam file for 19_slice? 611,202 793,674 944,629 How many properly paired reads are in the pre-filtered mapped bam file for 19_slice? 611,202 793,674 797,522 How many properly paired reads are in the filtered mapped bam file for 19_slice? 611,202 793,674 797,522 Commands Commands to rerun for 19_slice. We thankfully don't need to make and directories again as we have already created them. #QC #FastQC of raw reads fastqc -o raw_fastqc_output \\ 19_slice_R1.fq.gz 19_slice_R2.fq.gz #Check fastqc reports firefox \\ raw_fastqc_output/19_slice_R1_fastqc.html \\ raw_fastqc_output/19_slice_R2_fastqc.html &amp; #Quality control trimmomatic \\ PE -phred33 \\ 19_slice_R1.fq.gz 19_slice_R2.fq.gz \\ trimmed/19_slice_R1_out_paired.fastq trimmed/19_slice_R1_out_unpaired.fastq \\ trimmed/19_slice_R2_out_paired.fastq trimmed/19_slice_R2_out_unpaired.fastq \\ ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 \\ LEADING:3 TRAILING:3 SLIDINGWINDOW:4:30 MINLEN:50 #FastQC of trimmed reads fastqc -o trimmed_fastqc_output \\ trimmed/19_slice_R1_out_paired.fastq trimmed/19_slice_R2_out_paired.fastq #Firefox of fastqc reports firefox \\ trimmed_fastqc_output/19_slice_R1_out_paired_fastqc.html \\ trimmed_fastqc_output/19_slice_R2_out_paired_fastqc.html &amp; #Read alignment #We don&#39;t need to rebuild the reference as it is already built #hisat2 alignment hisat2 \\ -x slice \\ -1 trimmed/19_slice_R1_out_paired.fastq \\ -2 trimmed/19_slice_R2_out_paired.fastq \\ -p 8 \\ -q \\ --met-file aligned/19_slice.stats | \\ samtools sort -O BAM &gt; \\ aligned/19_slice.sorted.bam #View info on mapped reads samtools flagstat aligned/19_slice.sorted.bam #Discard unwanted reads samtools view -b -q 40 -f 2 \\ -F 12 aligned/19_slice.sorted.bam &gt; \\ aligned_clean/19_slice.sorted.clean.bam #Index bam file samtools index aligned_clean/19_slice.sorted.clean.bam #View 17_slice and 19_slice with igv igv &amp; #htseq-count #gene count htseq-count \\ -m union \\ -s yes \\ -t gene \\ -i ID \\ -r pos \\ -f bam \\ aligned_clean/19_slice.sorted.clean.bam \\ slice.FlyBase.gff &gt; \\ htseq/19_genecount.htseq #exon count htseq-count \\ -m union \\ -s yes \\ -t exon \\ -i ID \\ -r pos \\ -f bam \\ aligned_clean/19_slice.sorted.clean.bam \\ slice.FlyBase.gff &gt; \\ htseq/19_exoncount.htseq "],["07-Differential_Gene_Expression.html", "Chapter 7 Differential Gene Expression using DeSeq2 7.1 Jupyter 7.2 R 7.3 Introduction to DGE and DESeq2 7.4 The dataset 7.5 Differential expression analysis 7.6 Visualising the results 7.7 Export the results", " Chapter 7 Differential Gene Expression using DeSeq2 7.1 Jupyter Jupyter-notebook is a nice browser based method to write, edit, and run code. It was initally created for Python coding, but has since branched out to many other languages, such as R. We are using it in this workshop for a variety of its properties: It is popular and well maintained. It is lightweight. Other heavier weight programs, such as RStudio, would struggle in our HPC due to the graphical and CPU load. It is interactive and displays code output. It allows for easier annotation, editing, and debugging than the command line. It provides a graphical interface for changing directories and choosing files. Before carrying out any analysis we will go through a quick tutorial of jupyter-notebook. But first we will change directories so we have the data we need available for the next two chapters. cd ../Practical_two 7.1.1 Open Jupyter-notebook The first step is to open jupyter-notebook. Run the below command in your (rnaseq) environment. jupyter-notebook This will open jupyter-notebook in firefox. We won't need to access the linux terminal anymore. Leave the terminal running jupyter-notebook and full screen your firefox so you should see something like below. 7.1.2 Create R notebook The next step is to create a R notebook. Click on the \"New\" button towards the top right, right of the \"Upload\" button. From the dropdown click \"R\" below \"Python 3 (ipykernel)\". This will open up a new R notebook like below. 7.1.3 Cells and code Jupyter-notebook uses cells (the gray boxes) to separate code. This is very useful to compartmentalise our code. There will already be one cell. Within the cell, type in the below commands. 1+1 2-3 When pressing enter in cells it will create a new line. To run all commands in a cell press CTRL + enter. Run your current cell and you should see something like below. 7.1.4 Create new cells You can create new cells by 2 different means. Press the + button on the tool bar (between the floppy disk and scissors ). This will add a cell below your currently selected cell. Click on the Insert button and use the dropdown to add a cell above or below your currently selected cell. Tip: Hover over the toolbar icons to display a text based description of its function. With that knowledge add a second cell below the first cell. Add the following code to your second cell but do not run it. num_1 &lt;- 3 num_2 &lt;- 10 Tip: Notice there are green lines around your selected cell. Insert a third cell and add the following code to it. Do not run the code. num_1 * num_2 7.1.5 Running code Try to run the code in the third cell. There should be an error as we have not created the objects num_1 &amp; num_2. We have only written the code for these objects but not run them. We can run all the code in a notebook starting from the first cell to the last cell. To run all cells from the start: Click on the \"Cell\" button. Click \"Run All\" from the drop-down options. You should then see something like the below in your notebook. There is no output printed for cell 2 because we are assigning variables. However, the correct output for Cell 3 is below it. This is because the variables were assigned in cell 2 before cell 3 was run. 7.1.6 Saving the file As with RStudio and other good coding interfaces we can save our notebook. First we should rename the file. Rename the notebook to \"jupyter_tut\": Click on the name of the notebook, currently called \"Untitled\". This is at the very top of the notebook, right of the Jupyter logo. A pop-up called \"Rename Notebook\" will appear. Change the Name to \"jupyter_tut\". Click \"Rename\". Now we can save the file. Two methods to save are: Click the floppy disk on the toolbar. Click on the \"File\" button. Click \"Save and Checkpoint\" from the dropdown options. 7.1.7 Title cells with markdown We will be using multiple notebooks in this workshop. We will also have multiple sections per notebook. It will be useful to create header cells with markdown to create visual separation of the different sections. To add a header cell to the top of our notebook: Create a new cell at the top of the notebook. Click on the \"Code\" drop down and select \"Markdown\". The \"Heading\" option no longer works. Add the following to the \"Markdown\" cell to create a first level header. Ensure you have a space between the # and header text (\"Tutorial\"). # Tutorial Great, we can now add nice headers in our notebooks. Save the notebook once more before carrying on to the next section. Markdown You won't need to know more about Markdown but if you are interested please see the Markdown guide. 7.1.8 Close the notebook To close the notebook: Click on \"File\". From the dropdown options click \"Close and Halt\". When you are back in the file explorer page you may not yet see the new file you saved. If so, you will need to refresh the page with the Refresh button towards the top right. With that quick tutorial of jupyter-notebook we can start our differential expression analysis. 7.1.9 Video tutorial 7.2 R As mentioned above we will be using R to run the differential gene expression analysis within Jupyter Notebooks. If you are not familiar with R we have described some of the common terminology and put a few hints to help you understand how to run a few basic commands in Chapter 2 in our supplemental bookdown. Feel free to look at this first before continuing. 7.3 Introduction to DGE and DESeq2 Differential gene expression (DGE) is an analysis used to find genes that are differentially expressed in response to a treatment or variable and it estimates the size and direction of the effect. Most RNA-seq experiments involve comparing two (or more) treatments. The method we will be using uses generalised linear models to explicitly model the count data. We will be using the R package DESeq2 to run the differential expression analysis. DESeq2 performs differential expression analysis using a table of count data for each gene per sample. It tests for differential expression based on a model using the negative binomial distribution and uses a shrinkage estimation for dispersions and fold changes to improve stability and interpretability of estimates. For more information see the publication, manual and vignette. To summarise the general workflow we will be following we will: Read the data into R. This comes in the form of 2 files, a count data file and a metadata file. We then merge these together into a single data structure. Filter the data. Many genes have either no or virtually no counts recorded for them. These can cause problems for the statistical analysis downstream so are often removed. (Plus, if theyâ€™re not expressed in any treatment they wonâ€™t be differentially expressed). Normalise the data. In addition to interesting biological reasons why counts of reads from genes will be different, there are plenty of dull technical reasons why they differ that we have to control for. Normalisation controls for the number of reads in total from the library, the fact that genes at a low expression level tend to vary more than highly expressed genes, and that different genes have different amounts of variation. DESeq2 uses a modelling approach to perform normalisation, internally correcting for library size. Find differentially expressed genes. This is where we identify genes that differ systematically between treatments. 7.4 The dataset To do this we will use a pre-prepared data set which contains multiple individuals belonging to different treatment groups needed for DGE analysis. The data comes from Mike Ritchie and Paris Veltsos, University of St Andrews. The full experiment involved 96 samples, but here we just use subsets of these. Drosophila were selected for many generations with either one or many tissue samples taken from males or females, head or thorax and from virgin or mated flies. In this subset there are three regimes: B: Baseline population M: Multiple mates. These were flies with elevated polyandrous activity. E: Evolved. These flies were forced to have monogamous activity. Factor Value Regime (Base, Multiple mates, Evolved) B, M, E Sex (Male or Female) M, F Status (control or virgin) C, V Tissue (Head or body) H, B Line (replicate selection lines) 1 - 4 The subset we will use contains 24 samples. All samples are head tissue (H), from males (M) and females (F), grown under three different regimes (B, M and E). Important note: In real experiments you should have biological replicates. The absolute minimum should be 3. It will be difficult to distinguish any real patterns of expression between conditions from background biological variation present within conditions without sufficient replicates. Even using 3 replicates, it is likely that you can expect false-positives within your dataset and it will be harder to detect genes with smaller effects. 7.5 Differential expression analysis Create a new notebook called \"Chp07-Differential_gene_expression\". - Add a markdown cell with the first level header: # Differential gene expression - Add the below to a code cell and run the cell to load the DESeq2 library. library(&quot;DESeq2&quot;) 7.5.1 Loading in the data Create a new code cell. First we will read in a table which contains the count data per gene for all the individuals we will be examining. # The row names are your gene ids counts&lt;-read.table(&quot;genecount.set1.tsv&quot;, header=T, row.names = 1) # Print the start of the dataframe to look at its structure. head(counts) In a new cell we will read in the metadata for the samples. This table includes information about the regime, sex, status, tissue and line for each sample (for more information see above). coldata&lt;-read.table(&quot;design.set1.tsv&quot;, header=T, row.names = 1) From now on you will get less instructions on your notebook structure. Please create your own coding and markdown cells where you think appropriate. We are going to run a simple analysis to examine which genes are differentially expressed between males and females (i.e. sex-biased genes). Sex-biased gene expression is common in animals and sex-biased genes are thought to drive many behavioural, physiological and morphological differences between the sexes. In our model we need to make sure that sex is treated as a factor. To do this we can run the following command. coldata$sex &lt;- factor(coldata$sex) It is essential that the order of the sample names in your metadata and count tables are in the same order. We can check this by comparing whether all the row names in our metadata match the column names in our count data. Run the following function. If TRUE is printed to the screen then all the sample names match and we can proceed. all(rownames(coldata) == colnames(counts)) Now we set up our DESeqDataset, which will store our read counts and metadata. We must also specify an associated design formula, which expresses the variables which will be used in modeling. In this instance we are interested in how sex affects gene expression patterns so we specify this as a term of interest after a tilde (~) in our formula design. dds &lt;- DESeqDataSetFromMatrix(countData = counts, colData = coldata, design= ~ sex) 7.5.2 Filtering the data We will now filter the data to remove genes that have extremely low expression in all samples. You do not have to do this step but there are a couple of reasons why this can be useful: removing genes (rows) which have very few reads we can reduce the memory needed to process the dds data object this will speed up the analysis. In this case we will remove low count genes with less than 10 reads in total across samples. (A stricter filtering is applied to increase power via an independent filtering on the mean of normalised counts when we run the results function further down). # check the number of genes contained in the dataframe nrow(dds) # we start with 16,707 genes # remove genes with less than or equal to 10 reads across all samples keep &lt;- rowSums(counts(dds)) &gt;= 10 dds&lt;- dds[keep,] # re-count the number of genes we have retained after filtering nrow(dds) # we have 15,675 genes after filtering How many genes do we have after filtering? 67,569 12,675 15,675 Note: The reference level of for factors used within the model are by default based on alphabetical order. It might not matter which factor is set as the reference in your analysis but if for example you had a control/wild type group it would make sense to set this as the reference to compare against. One way you can tell R how to set your reference is using the relevel function. For example if we had a term called condition and we wanted to make sure our wild type (wt) samples were set as the reference compared to the mutant (mt) we could do this using the following command: dds$condition &lt;- relevel(dds$condition, ref = \"wt\"). This would mean that positive fold changes in gene expression in our results would mean that expression was higher in the mutant. You would need to do this before running the DESeq function below for the re-leveling to be reflected in your results. 7.5.3 Running the analysis and obtaining the DGE results Now we will run the DESeq function on our filtered DESeqDataSet. This function performs a differential expression analysis based on the negative binomial distribution. It will: estimate size factors estimate dispertions fit a negative binomial general linear model and wald statistics dds &lt;- DESeq(dds) For more details of each step you can check the help section of the DESeq2 help using: ?DESeq You can also read more about the estimation steps here or in the DESeq2 publication. We will now extract the results table for our DGE analysis using the results function. res &lt;- results(dds) We can look at the start of our results object by running. head(res) You can see we have several columns in our results: baseMean: the average of the normalized count values, dividing by size factors, taken over all samples log2FoldChange: the effect size estimate. It tells us how much the geneâ€™s expression seems to have changed due to the \"treatment\". This value is reported on a logarithmic scale to base 2. (In this case a value of 1 means that the expression level for a gene in males is twice that in females). lfcSE: The log2 fold change estimate standard error (the uncertainty associated with the estimate) stat: Wald statistic pvalue: Wald test p-value (The p-value will be reported as NA if all counts for a particular gene are zero, or if the gene was excluded from analysis because it contained an extreme count outlier). padj: Benjamini-Hochberg adjusted p-value (This is a p-value adjusted to account for multiple testing. We need to apply a correction as we have run thousands of tests which means that the chance of getting a false significant result is much higher. For more info see this link. We can summarise the results by running the following command. summary(res) This shows us that we have 646 genes with a positive log fold change (higher expression in males and lower expression in females) How many genes have a negative log fold change (higher expression in females and lower expression in males)? 646 690 3,661 We can order our results by the adjusted p-value to look at the most significant DEG. res &lt;- res[order(res$padj),] head(res) Which gene has the largest log fold change difference of the top 6 genes shown? FBgn0079420 FBgn0245773 FBgn0075575 7.5.4 Plot the expression differences for the most significant differentially expressed genes We can visually plot these genes by typing par(mfrow=c(2,3)) plotCounts(dds, gene=&quot;FBgn0245773&quot;, intgroup=&quot;sex&quot;) plotCounts(dds, gene=&quot;FBgn0075575&quot;, intgroup=&quot;sex&quot;) plotCounts(dds, gene=&quot;FBgn0071323&quot;, intgroup=&quot;sex&quot;) plotCounts(dds, gene=&quot;FBgn0072657&quot;, intgroup=&quot;sex&quot;) plotCounts(dds, gene=&quot;FBgn0249407&quot;, intgroup=&quot;sex&quot;) plotCounts(dds, gene=&quot;FBgn0079420&quot;, intgroup=&quot;sex&quot;) You can see that of the 6 genes with the lowest adjusted p-values, 5 have negative log fold changes and have higher normalised counts in females compared to males, and 1 has a positive log fold change with higher normalised counts in males than females. 7.6 Visualising the results We will now go through several different methods of visualising the results from our DGE analysis. 7.6.1 MA plot We will first plot an MA plot. This gives us an overview of the experiment and how DESeq2 calls significant DEG. Each gene is represented by a dot. Genes with significant adjusted p-values (default &lt; 0.01) are coloured in blue. This shows that DESeq2 will only call significant DGE in genes with a large average normalised count as only these genes contain sufficient information to be able to do so. par(mfrow=c(1,1)) plotMA(res, ylim = c(-10, 10)) 7.6.2 Volcano plot One nice way to visualise your results is to plot a volcano plot. # Make the basic volcano plot with(res, plot(log2FoldChange, -log10(pvalue), pch=20, main=&quot;Volcano plot&quot;, xlim=c(-10,10), col=&quot;grey&quot;)) # Colour points light blue if padj&lt;0.01 with(subset(res, padj&lt;0.01 ), points(log2FoldChange, -log10(pvalue), pch=20, col=&quot;#a6cee3&quot;)) # Colour points dark blue if log2FC&gt;1 and padj&lt;0.01) with(subset(res, padj&lt;0.01 &amp; abs(log2FoldChange)&gt;1), points(log2FoldChange, -log10(pvalue), pch=20, col=&quot;#1f78b4&quot;)) This allows us to visualise the number of differentially expressed genes which are significant (light blue). We can also visualise how many genes have an expression level which is at least twice as high in males than in females (log2FoldChange&gt;1) and those which are twice as high in females than in males (log2FoldChange&lt;1). In our case, we have a fairly even number of genes both up and down regulated in males compared to females. 7.6.3 Heatmap Usually, the variation between samples within a sample group (within-group variation) is smaller than that between samples from different sample groups (overall variation) because the former consists of technical and biological variation only, while the latter also contains variation due to the effects of factors. When the factor effect is the dominant contributor of variation, the sample groups can be clearly separated. However, if the factor effect is weak compared to the technical and biological variation within sample groups, it will be difficult to discriminate groups from the data. PCA and Correlation Heatmap plots visualise the outcomes of the assessment of the variation within and between sample groups. Before we plot these we will transform the data. For the differential expression analysis we use raw counts but for visualisation and clustering purposes it is common to work with transformed data. There are two main ways suggested for transforming data for visualisation and clustering in DESeq2: VST (variance stabilising transformations) and the rlog (regularised logarithm). For more information see here. Here we will use the rlog transformation before plotting the Heatmap and PCA plots. First use the rlog transformation to normalise the data. rld &lt;- rlog(dds, blind=FALSE) The argument blind, refers to whether the transformation should be blind to the sample information specified by the design formula. This is not appopriate to use as we are expecting many of the genes to have counts which are explained by the experimental design we specified (i.e. sex), so we have set this argument to false. We will use the package pheatmap to plot a heatmap for our samples and see how they cluster. # load pheatmap &amp; ggplot2 library(pheatmap) library(ggplot2) # extract assay of numeric values from the rld object needed by pheatmap rld_mat &lt;- assay(rld) # compute the pairwise correlation values for samples and make a matrix of correlations rld_cor &lt;- cor(rld_mat) # rename the coldata by the sex column in the metadata rownames(rld_cor)&lt;-coldata$sex head(rld_cor) # plot heatmap pheatmap(rld_cor) We can see that in general samples seem to cluster on the heatmap by sex. 7.6.4 Principle Component Analysis We will now plot the PCA and colour the points based on sex. We specify that females will be coloured green and males orange. plotPCA(rld, intgroup=&quot;sex&quot;)+ theme_classic() + theme(legend.title=element_blank())+ scale_color_manual(values = c(&quot;#33a02c&quot;, &quot;#ff7f00&quot;)) The PCA shows us that 32% of the variance can be explained by PC1 and looking at how the points are clustered we can suggest that sex is driving the division based on the x axis. 24% assigned to PC2. We can recolour the plot based on the group variable from our metadata to see if this sheds some more light on what could be driving the differences between samples on the y axis. Plot again and colour based on group. plotPCA(rld, intgroup=&quot;group&quot;)+ theme_classic() + theme(legend.title=element_blank())+ scale_color_manual(values = c(&quot;#a6cee3&quot;, &quot;#1f78b4&quot;, &quot;#fb9a99&quot;, &quot;#e31a1c&quot;, &quot;#b2df8a&quot;, &quot;#33a02c&quot;)) All samples in this dataset are from control samples and head tissue. We specify different colours based on the regime (Base, Multiple mates, Evolved). Darker points are samples from males and lighter colours are from females. We can see that the diversity on the y axis appears to be driven by the regime, so it would be interesting to repeat our analysis adding regime to the formula. That regime seems to have a some affect on gene expression patterns makes sense as mating system variation has been shown to influence sex-biased gene expression in some animal species. For more information on how you would run more complex models please see Chapter 4 of the supplemental bookdown. 7.7 Export the results Export the results as an R data file. save(res, file= &quot;DESeq2_DGE_results_sex.RData&quot;) To save the results to a csv file you can type the following. write.csv(res, &quot;DESeq2_DGE_results_sex.csv&quot;) You can now close and halt your notebook. "],["08-GO.html", "Chapter 8 Gene Ontology enrichment analysis 8.1 Final recap", " Chapter 8 Gene Ontology enrichment analysis Gene Ontology (GO) is a method off classifying gene function in a structured way and is split into three subgroupings: \"biological process (e.g., signal transduction), molecular function (e.g., ATPase activity) and cellular component (e.g., ribosome)\". Genes are associated with particular GO terms via GO annotations and each gene can have multiple annotations associated with it. You can obtain GO annotations from the Gene Ontology website, from species-specific databases, or they can be annotated to a reference gennome using software such as blast2GO. GO enrichment analysis finds which GO terms are over-represented (or under-represented) using annotations for a set of genes (in this case genes which are significantly differentially expressed between males and females). We will perform GO enrichment analysis using the topGO package in R. We strongly recommend reading through the topGO manual when you come to analyse your own data. First create a new notebook called \"Chp08-GO_enrichment\". Load the topGO package and load an example gene dataset, this also loads a function to define a list of differentially expressed genes that we will use in our analysis. We will also re-load our results from the DGE analysis. library(topGO) library(Rgraphviz) data(geneList) load(&quot;DESeq2_DGE_results_sex.RData&quot;) We will now modify the geneList object to contain the results we obtained from our DGE analysis containing the adjusted p-values and the names of the genes. # extract the adjusted p-values from our results object geneList &lt;- res$padj # add the gene names from our results to our list of adjusted p-values names(geneList) &lt;- rownames(res) # remove genes with an adjusted p-value recorded as NA geneList&lt;-na.omit(geneList) We can use the topDiffGenes function to extract genes with a adjusted p-value of less than 0.01. This will be used as our list of genes of interest for our GO enrichment analysis. sum(topDiffGenes(geneList)) We have 666 genes which are significantly differentially expressed when using a cutoff of 0.01. We will now read in a list of genes and their associated biological process GO annotations. geneID2GO &lt;- readMappings(&quot;geneanno_goBio.tsv&quot;) head(geneID2GO) You can see we now have a list of GO annotations associated with each gene ID. We now have all the data we need to make a topGOdata object. This will contain all the information needed to perform the enrichment analysis including the gene lists we've made, the GO annotations and the GO hierarchical structure. sampleGOdata &lt;- new(&quot;topGOdata&quot;, ontology = &quot;BP&quot;, allGenes = geneList, geneSel = topDiffGenes, nodeSize = 10, annot = annFUN.gene2GO, gene2GO = geneID2GO) ontology = specifies which ontology to use (biological processes, cellular components or molecular function) allGenes = a list of all genes which we tested in our DGE analysis with their associated adjusted p-values geneSel = select genes using the topDiffGenes function (genes with a adjusted p-value &lt; 0.01) to use as our set of genes of interest nodeSize = remove any annotated GO terms which have less than X number of genes associated with them (in this case 10) annot = annFUN.gene2GO function is used to extract the gene-to-GO mappings from the geneID2GO object gene2GO = our list of genes and their associated GOs If you check the topGOdata object we can see a summary of the data we added. sampleGOdata Now we have the topGOdata object ready we can start with the enrichment analysis. Here we run the analysis using the Fisherâ€™s exact test statistic using the runTest function and test whether there is an over-representation of GO terms within the group of differentially expressed genes. Each GO category is tested independently with the algorithm classic. resultFisher &lt;- runTest(sampleGOdata, algorithm = &quot;classic&quot;, statistic = &quot;fisher&quot;) resultFisher The enrichment analysis has identified 63 significantly enriched GO categories (p &lt; 0.01). We can then pull out the most significant GO terms from the results and the corresponding p-values using the function GenTable. In this case we will print the top 10 GO categories. allRes &lt;- GenTable(sampleGOdata, classicFisher = resultFisher, orderBy = &quot;classicFisher&quot;, topNodes = 10) allRes Plot a figure of the most significant GO terms. We will plot the top 5 to make it easier to view the plot. showSigOfNodes(sampleGOdata, score(resultFisher), firstSigNodes = 5, useInfo = &#39;all&#39;) This plot is nice but it's quite hard to read. Instead we will write this plot to a png file to view it. png(filename = &quot;GO.png&quot;, res = 300, units = &quot;mm&quot;, height = 200, width = 200) showSigOfNodes(sampleGOdata, score(resultFisher), firstSigNodes = 5, useInfo = &#39;all&#39;) dev.off() You can open the png file you just made by clicking on the Jupyter 'home page' tab and then clicking on the GO.png file you just created. You will then be able to zoom in to see the text of the plot in more details. This plots the top 5 GO terms which have been identified using the Fishers test. The 5 most significant terms are plotted as rectangles. The colour of the rectangles represent significance (dark red most significant, yellow least significant). Within each node, useful information is printed: Line 1: GO identifier Line 2: trimmed GO name Line 3: p-value Line 4: number of significant genes and the total number of genes annotated to the respective GO term Our top 5 enriched GO terms for sex-biased genes were found to be: ribosome biogenesis ribonucleoprotein complex biogenesis cellular amide metabolic process peptide metabolic process translation 8.1 Final recap In this workshop we started with raw reads, which we cleaned (Trimmomatic), aligned to a reference genome (HISAT2) and then produced a set of gene counts per sample (htseq-count). We then performed a differential gene expression analysis (DeSeq2) and GO enrichment analysis (topGO) to find out which genes and pathways were differentially expressed and enriched in response to a variable of interest. We performed this analysis using a small subset of samples and fitted a simple model to examine a single variable. In your own analysis it is extremely important to consider your experimental design, the number of replicates you need, the amount of sequencing per sample and the best model to fit to be able to answer your specific biological question. "]]
