[["01-Metabarcoding_supplemental.html", "Metabarcoding for diet analysis and environmental DNA - supplemental material Chapter 1 Introduction", " Metabarcoding for diet analysis and environmental DNA - supplemental material Katy Maher and Helen Hipperson 2022-09-02 Chapter 1 Introduction This bookdown is supplemental to the main one. It contains some additional code and examples of tools that may prove useful in addition to the core DADA2 pipeline. The sections in this supplement will cover: Normalising sequence data Exporting your ASV matrix and fasta files from R Classifying ASVs with GenBank and BLAST Assigning taxa with MEGAN Summary Ensure you have the metabarcoding environment activated for using all of these materials. As a reminder, the command to do this (if you are not still in the R session) is: . usemetabarcoding This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Normalisation.html", "Chapter 2 Normalising your data 2.1 Relative abundance 2.2 Rarefaction 2.3 Variance stabilising transformation using DESeq2", " Chapter 2 Normalising your data As mentioned in the main tutorial document there are several different methods for normalising your data for downstream analysis. Here we will look at three different methods of normalising your data for downstream analysis. To summarise so you have several methods in one place, we will also include the normalisation method that we used in the main tutorial. Remember these are just a few examples of how to normalise your data and we recommend you read the recent literature and think about the properties of your own dataset when deciding the best way to proceed. 2.1 Relative abundance The transform_sample_counts function transforms the sample counts from a taxa abundance matrix using a user-provided function. The counts of each sample will be transformed individually. In this case we will transform the raw samples into relative abundances by dividing individual ASV counts by the total ASV counts in a sample. phylo.prop &lt;- transform_sample_counts(phylo, function(otu) otu/sum(otu)) 2.2 Rarefaction Rarefaction involves randomly removing reads until you reach a number often equal to or less than the number of reads in the smallest sample. Here we rarefy to an even depth using the minimum number of reads found in a sample as specified by the sample.size=min(sample_sums(phylo)) argument. The argument rngseed = 1 sets a random number seed used for random number generation, which is then used when subsampling a random number of reads from each sample. By setting the random seed you can make this proccess reproducible. We have set the argument replace as replace = F. From the phylo.rarefied R help page “Two implications to consider are that (1) sampling with replacement is faster and more memory efficient as currently implemented; and (2), sampling with replacement means that there is a chance that the number of reads for a given OTU in a given sample could be larger than the original count value, as opposed to sampling without replacement where the original count value is the maximum possible.” phylo.rarefied &lt;- rarefy_even_depth(phylo, rngseed = 1, sample.size=min(sample_sums(phylo)), replace = F) 2.3 Variance stabilising transformation using DESeq2 Variance stabilising transformation borrows methods from transcriptomic research using the DESeq2 package. The workflow below is based on the workflow for variance stabilised data suggested here. First we load the DESeq2 library. library(DESeq2) Now transform the phyloseq object into a format appropriate for DESeq2. ds &lt;- phyloseq_to_deseq2(phylo, ~SITE) The function estimateSizeFactors is used to estimate the size factors for a DESeqDataSet - for more information on the normalisation methods used by DESeq2 please read the DESeq2 paper and manual. ds&lt;-estimateSizeFactors(ds) For our dataset we get the error message “Error in estimateSizeFactorsForMatrix(counts(object), locfunc = locfunc, : every gene contains at least one zero, cannot compute log geometric means” This indicates we have many zeros in our count data (which is common in amplicon studies). There are several ways to deal with this problem. One way is to calculate size factors separately using a zero-tolerant variant of geometric mean. For more details of this method see here. # calculate geometric means prior to estimation of size factors gm_mean &lt;- function(x, na.rm=TRUE){ exp(sum(log(x[x &gt; 0]), na.rm=na.rm) / length(x)) } geoMeans &lt;- apply(counts(ds), 1, gm_mean) We can now proceed and calculate size factors and dispersions of our dataset, before calculating the variance stabilizing transformation and transforming the count data with getVarianceStabilizedData. ds &lt;- estimateSizeFactors(ds, geoMeans = geoMeans) ds &lt;- estimateDispersions(ds) ds_vst&lt;-getVarianceStabilizedData(ds) We then convert the transformed dataset back into a phyloseq object for further analysis. ds_count_phylo &lt;- otu_table(ds_vst, taxa_are_rows=T) sample_info_tab_phy &lt;- sample_data(meta.rmlow) ds_phylo &lt;- phyloseq(ds_count_phylo, sample_info_tab_phy) This is just one way to deal with the problem of zero counts in our dataset. For more discussion on using DESeq2 for metabarcoding data and dealing with zero count data please check out the following links: phyloseq FAQ DESeq2 with phyloseq "],["03-Exporting_data.html", "Chapter 3 Exporting data 3.1 Fasta file 3.2 Sequence count matrix 3.3 Table of taxon names", " Chapter 3 Exporting data It is useful to be able to export our ASV sequences and a matrix table of counts from DADA2/R as we might want to visualise or analyse these using other software. Our ASV sequences and counts per sample are stored in the object seqtab.nochim. The ASVs are not named, so first let’s name them (ASV_1, ASV_2, etc.). # The column names of seqtab.nochim are actually the ASV sequences, # so extract these and assign them to `mifish_seqs` mifish_seqs &lt;- colnames(seqtab.nochim) # Make a new variable for ASV names, `mifish_headers`, #with length equal to the number of ASVs mifish_headers &lt;- vector(dim(seqtab.nochim)[2], mode=&quot;character&quot;) # Fill the vector with names formatted for a fasta header (&gt;ASV_1, &gt;ASV_2, etc.) for (i in 1:dim(seqtab.nochim)[2]) { mifish_headers[i] &lt;- paste(&quot;&gt;ASV&quot;, i, sep=&quot;_&quot;) } 3.1 Fasta file Now we have our sequences and names as variables we can join them and make a fasta file. mifish_fasta &lt;- c(rbind(mifish_headers, mifish_seqs)) write(mifish_fasta, &quot;MiFish_ASVs.fa&quot;) You should now have this fasta file in your working directory on the server. 3.2 Sequence count matrix Next make a table of sequence counts for each sample and ASV. # First transpose the `seqtab.nochim` and assign this to the variable `mifish_tab` mifish_tab &lt;- t(seqtab.nochim) # Name each row with the ASV name, omitting the &#39;&gt;&#39; used in the fasta file row.names(mifish_tab) &lt;- sub(&quot;&gt;&quot;, &quot;&quot;, mifish_headers) write.table(mifish_tab, &quot;MiFish_ASV_counts.tsv&quot;, sep=&quot;\\t&quot;, quote=F, col.names=NA) You should now have an ASV by sample matrix with sequence counts in a tab-separated value (tsv) file in your working directory. 3.3 Table of taxon names Lastly, if we’ve used dada2 to assign taxonomy we can make a table of taxon names for each ASV. # Replace the row names in `taxa` with the ASV names, # omitting the &#39;&gt;&#39; used for the fasta file. rownames(taxa) &lt;- gsub(pattern=&quot;&gt;&quot;, replacement=&quot;&quot;, x=mifish_headers) write.table(taxa, &quot;MiFish_ASV_taxonomy.tsv&quot;, sep = &quot;\\t&quot;, quote=F, col.names=NA) You should now have a tsv file of taxonomic assignments for each ASV in your working directory. "],["04-BLAST.html", "Chapter 4 GenBank and BLAST 4.1 BLAST againt the nt database 4.2 BLAST against a custom database", " Chapter 4 GenBank and BLAST GenBank and BLAST are both hosted by the NCBI (Nationl Center for Biotechnology Information). GenBank is an annotated database of all publicly available DNA sequences, more than 200 million. BLAST is a program that compares sequences to those in databases such as GenBank to find regions of similarity. Therefore we can use BLAST to find sequences similar to our ASVs in GenBank and use that to infer the taxonomy in our dataset. This is not a fool-proof way to know exactly what was in our samples, however, as there are mis-annotated records in GenBank, which can occur if an organism is misidentified before being sequenced, or if the sequence was contaminated or erroneous. Although GenBank holds millions of sequences it is not comprehensive, and it might be the case that an ASV in our sample is simply not represented in the database. It is possible to use BLAST through the web interface either pasting in sequences one by one or uploading a fasta file. However, with a few hundred ASVs from a typical metabarcoding project it is more efficient to use a downloaded copy of the GenBank nucleotide (nt) database and a standalone command line version of the BLAST software. See here for information on downloading BLAST software and databases. Many institutions will have servers with the BLAST software and databases communally available as this saves storage space compared to many users having their own copies, so it is worth asking if this is available where you are based. As the BLAST databases are large and the searches can take a while to run the commands below are not intended to be run on the web VNC, but are provided in case they are useful for you for your own data. BLAST is used on the linux command line, rather than in R as we have been working in all the earlier steps of the workbook. 4.1 BLAST againt the nt database To perform a blastn search of our MiFish ASVs against the nt database the command would be: blastn -query MiFish_ASVs.fa -task blastn -db nt \\ -evalue 0.001 -outfmt 6 -out MiFish_ASVs_blast_out.txt The options specified are: -query filename.fa fasta file of ASV sequences -task blastn perform a blastn search -db nt search against the nucleotide (nt) database -evalue 0.001 threshold E-value for returning BLAST hits -outfmt 6 generate the results in a tabular format The text file produced will be a table of BLAST hits for all ASVs where a match could be found within the threshold E-value. The table will have 12 columns including the ASV name, the database sequence match name, the percent identity of the match, the length of the alignment, the E-value and the bit-score. These last two values are measures of how well our sequences match, with a smaller E-value and a larger bit-score indicating better matches. Here’s what the first few lines of the output file looks like: We have many hits for ASV_1. The first two hits have 100% sequence identity over the whole length (167 bp) of our amplicon. The other hits shown have 1 mismatch giving them a 99.4% sequence identity. How do we decide which match is best given the high similarity to many sequences? We could simply take the top hit for each ASV, but an alternative way is to use a ‘lowest common ancestor’ algorithm to assign taxonomy. This is implemented in the program MEGAN. 4.2 BLAST against a custom database If you have your own fasta file of curated reference sequences you can also use BLAST to match your ASVs to this. First make a BLAST database from the fasta file: makeblastdb -in My_12S_Fish_sequences.fa \\ -parse_seqids \\ -dbtype nucl \\ -out My12S This will generate all of the database files needed to run blastn against the sequences in ‘My_12S_Fish_sequences.fa’. To do this the command would be: blastn -query MiFish_ASVs.fa -task blastn \\ -db My12S -evalue 0.001 -outfmt 6 \\ -out MiFish_ASVs_blast_My12S_out.txt "],["05-MEGAN.html", "Chapter 5 MEGAN 5.1 Filtering BLAST results 5.2 Importing BLAST results into MEGAN 5.3 Exporting taxonomic classifications from MEGAN", " Chapter 5 MEGAN MEGAN stands for MEtaGenome ANalyzer. It has many tools for analysing metabarcoding data, one of which is to parse BLAST results and assign taxonomy to ASVs using a Lowest Common Ancestor (LCA) algorithm. The LCA considers all significant BLAST hits and, if these are to reference sequences from multiple species, assigns the taxonomy of the node that lies above all of those species. For example, if an ASV matched equally well to reference sequences of Neolamprologus longior and Neolamprologus gracilis it would be assigned to the genus level as Neolamprologus sp. Similarly, if an ASV matched equally well to reference sequences of Neolamprologus longior and Ophthalmotilapia ventralis it would be assigned at the family level to Cichlidae as both of these species are within that family. MEGAN is a GUI rather than command line software. It uses the NCBI taxonomy and a mapping file to match NCBI accession numbers (the second column in our blast output table) to taxonomic classes. As these files are large this is not intended to be run on the web VNC, but the workflow is provided in case it is useful for your own data. 5.1 Filtering BLAST results We already restricted the BLAST hits in our output file by specifying a maximum E-value threshold. It is also useful to further filter out sequences with a low percentage identity or a short alignment length as these are likely to be spurious matches to our ASVs. We can do this easily on the linux command line using an awk command (awk is a programming language useful for text and file processing). Let’s filter to keep only hits with a percent identity of at least 90% and an alignment length of at least 100 bp. awk &#39;$3 &gt;= 90&#39; MiFish_ASVs_blast_out.txt | \\ awk &#39;$4 &gt;= 100&#39; &gt; MiFish_ASVs_blast_out_filtered.txt 5.2 Importing BLAST results into MEGAN You will need to download your filtered BLAST results from your server, and also a copy of the file to map the NCBI accession numbers to taxonomic classes (available from the MEGAN download site, the current version is named ‘megan-nucl-Jan2021.db.zip’). In the MEGAN GUI choose ‘File &gt; Import from BLAST’, and the options box will be displayed as shown below. Navigate to where your BLAST results file is and fill in the other options as shown. On the second tab choose ‘Load MeganMapDB mapping file’ and navigate to where you have saved the ‘megan-nucl-Jan2021.db’ file. Click ‘Apply’. The taxonomic assignments for our ASVs, derived using the LCA algorithm, will then be displayed as a tree. We can see that the majority of our MiFish ASVs have been assigned to bony fishes (Clupeocephala), although two have been assigned to bacteria, nine to humans and one to bovids. This helps to explain why some ASVs had no (‘NA’) taxonomic classification from dada2, as for that assignment we used a curated database only of fish sequences. 5.3 Exporting taxonomic classifications from MEGAN You can export the taxonomic classifications from MEGAN. Choose ‘Select &gt; All Nodes’ to highlight all of the nodes in the tree. Choose ‘File &gt; Export &gt; CSVFormat’, then ‘Choose data to export &gt; readName_to_taxonName’. "],["06-Summary.html", "Chapter 6 Summary", " Chapter 6 Summary Do the results you obtained with this pipeline make sense? In a real scenario, you (as the owner of the dataset) are the one with the deepest knowledge of the data you are analysing, so it is upon you to answer this question. This answer needs to be inferred by gathering all the information you can on the samples. If the answer is ‘no,’ you can consider the following points. Are there any missing taxa you know should be there? These taxa may be present but not being detected for a few reasons, first of all, are these represented in the taxonomic database you are using? If no, you should try a different approach. If they are, you can try with different taxonomic assignment methods. If this still does not work, you can change the method to pick up the representative sequence and/or the clustering at the earlier stages of the analysis. The failure could be right at the beginning of the project design. It is worth checking if the PCR primers you are using can amplify these species. Are the primers known to impose bias on the mix of species you are amplifying? Are the primers unable to amplify some taxon? The literature may be able to help you on this topic. We hope that this workflow will prove useful to you when you analyse your own research data. We have covered some of the key methods and considerations for analysing metabarcoding data. However, every project is different and you still need to think about what the most appropriate way might be for analysing your particular data. For a full and complete understanding, you should also read the original publication associated with each program. "]]
