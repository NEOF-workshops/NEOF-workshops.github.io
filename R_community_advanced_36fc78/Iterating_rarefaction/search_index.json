[["01-Iterative_rarefaction_intro.html", "Iterative rarefaction Chapter 1 Introduction Table of contents", " Iterative rarefaction Matthew R. Gemmell 2024-07-22 Chapter 1 Introduction This book explains and demonstrates how to carry out iterative rarefaction for alpha and beta diversity analysis in R with the phyloseq object. This involves running multiple rounds/iterations of rarefaction and producing and averaged table of alpha and beta diversity values. This is a more robust method than only carrying out one round of rarefaction. Table of contents ADD TABLE OF CONTENTS This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["02-Background.html", "Chapter 2 Iterative rarefaction background 2.1 Should you rarefy? 2.2 Using iterations 2.3 Book contents", " Chapter 2 Iterative rarefaction background Rarefaction is the process of randomly subsetting abundances to ensure the total count values are identical across all samples. Rarefaction is intended to correct for bias caused by varying sampling depths across the samples. 2.1 Should you rarefy? Rarefaction can be a hotly debated topic with two main points of view. Some researchers believe it is not appropriate. This is backed up by the 2014 paper \"Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible\" Various R package developers do not recommend it such as the developers of phyloseq &amp; microbiome. Some researchers believe it is appropriate. This is backed up by the 2022 paper \"To rarefy or not to rarefy: robustness and efficiency trade-offs of rarefying microbiome data\" The QIIME2 developers include rarefaction in their tutorials/SOPs for alpha and beta diversity analysis We use rarefaction in our analyses but it is ultimately up to you whether you utilise it or not. 2.2 Using iterations In our initial R community analysis workshop we only carried out one round of rarefaction for each sample. In this book we will rarefy with multiple rounds/iterations to calculate average values for alpha and beta diversity metrics. This is iterative rarefaction analysis. This iterative approach will, in theory, smooth out any extreme results one round of rarefaction may cause. Extreme results are possible due the random nature of rarefaction. These extreme results can include: Leaving important features (ASVs, taxonomic groups, etc.) with no counts Causing a few features to have much higher relative abundances Varying alpha and beta diversity values with different sets of rarefaction 2.3 Book contents In this book you will learn how to: Use random seeds for sampling Carry out iterative rarefaction with sets of random seeds Use iterative rarefaction to carry out alpha diversity analysis Use iterative rarefaction to carry out beta diversity analysis "],["03-Setup.html", "Chapter 3 Setup 3.1 Dataset 3.2 Conda environment 3.3 Directory and files", " Chapter 3 Setup Include info on directory, copying data, and environment setup 3.1 Dataset The data set we will use in this book is the same as that used in the R community analysis workshop. Below are brief bullet points about the data: It is a 16S dataset of ASV counts with taxonomy and phylogeny produced by QIIME2 The samples come from surface water from the Durance River in the south-east of France There are three sampling sites on an anthropisation gradient (low to high agriculture) Upper Durance (UD) Middle Durance (MD) Lower Durance (LD) Four different media approaches were used to produce bacterial lawns that were sequenced Environmental sample (ENV): No media used, frozen at -20째C. TSA 10% incubated at 28째C for 2 days. KBC incubated at 28째C for 2 days. CVP incubated at 28째C for 3 days. There are three replicates for each sampling site and media combination (36 samples total) 3.2 Conda environment 3.3 Directory and files "],["04-Random_seeds.html", "Chapter 4 Random seeds and sampling 4.1 Random seed notebook 4.2 Random sampling 4.3 Sampling with replacement", " Chapter 4 Random seeds and sampling What are random seeds? Random seeds are numbers that computational tasks use to determine how they will carry out a random task. In this section we will demonstrate the use of random seeds. This is to help understand what they are and why they are used. 4.1 Random seed notebook Create a new R jupyter-notebook called \"Random_seeds.ipynb\" for this section. 4.2 Random sampling To demonstrate the use of random seeds we will use the R function sample(). This function randomly samples a set of numbers. Create the below code in a code cell. #Create a vector containing the numbers 0 to 9 num_vec &lt;- 0:9 #Randomly sample 5 of these numbers sample(x = num_vec, size = 5) If you run the code you will get five random single digit numbers. Run this multiple times and you will hopefully see the sampled numbers are different every time. 4.3 Sampling with replacement You may also notice that within each sample there are no repeating numbers. You can change this by adding the option replace = TRUE. Try this out in a new cell. #Randomly sample 5 of these numbers with replacement sample(x = num_vec, size = 5, replace = TRUE) Run this a few times and you will hopefully notice that the five numbers are not always unique. When sampling with replacement you replace each result back into the pool before sampling again. When sampling without replacement you don't replace the results. The famous example is sampling green and yellow balls from a bag. If you had a bag with 1000 balls and you wanted a rough idea of the ratio of yellow and green balls you could count the number of these balls within a sample of only 50. Without replacement you would take out a ball, record its colour and throw it in a separate container. With replacement you would take out a ball, record its colour and put it back into the initial bag, meaning it could possibly be recounted. One advantage of sampling with replacement is that your sampling size can be larger than your actual population size. For example, you could create a random sampling of 50 with a bag containing 10 balls with replacement. This would not work without replacement. The below script will cause R to produce an error saying \"cannot take a sample larger than the population when 'replace = FALSE' \". #Randomly sample 15 of these numbers without replacement sample(x = num_vec, size = 15, replace = FALSE) Importantly for us rarefaction uses sampling without replacement. Any samples with a lower depth than the rarefaction size will be removed and will therefore not be in the resulting rarefied data. "],["05-R_and_random_seeds.html", "Chapter 5 R and random seeds 5.1 Setting the R seed 5.2 Reset seed", " Chapter 5 R and random seeds Sampling is meant to be random but true randomness is pretty much impossible, especially in computing. Therefore, many programs use seeds to determine how random tasks will be carried out. Various programs that use random seeds include: Sampling tools such as sample() and rarefaction Creating bootstrapped phylogenies Creating procedural content such as building Minecraft worlds 5.1 Setting the R seed To carry out random processes R uses a global variable called seed. The seed is normally random and changes every time it is used. This is useful for everyday analysis but what if you want replicable results? In R we can set the seed with the function seet.seed(). Carry this to determien the randomness of sampling. #Set random seed set.seed(1234) #Randomly sample 12 of these numbers without replacement sample(x = num_vec, size = 12, replace = FALSE) #Reset random seed (covered later) set.seed(NULL) You will get a result of \"9, 5, 4, 3, &amp; 0\". You can try to run the code multiple times and you will always get the same results. If you run a tool that uses random sampling you will always get the same results if: You use the same random seed (seed for R) You use the same data You use the same parameters including the replacement method (with or without) In fact, run the below code in a new code cell and you may notice a similarity with your previous output. #Set random seed set.seed(1234) #Create a vector containing the numbers 0 to 10 larger_num_vec &lt;- 10:19 #Randomly sample 5 of these numbers sample(x = num_vec, size = 5) #Reset random seed (covered later) set.seed(NULL) That's right, sample() will always take the 10th (9/19), 6th (5/15), 5th (4/14), 4th (3/13), and 1st (0/10) values if it is given the random seed of 1234, provided with an 10 length vector, and asked to sample 5 values. Setting our randomness is incredibly beneficial for reproducibility in research. When you carry out analysis you may need to redo some work. This could be due to reviewer comments or you may want to incorporate some new methods. As long as you saved the random seeds you used you can get the same results where you need to. It also means others can replicate your results. 5.2 Reset seed We set a random seed at the start of the cell for reproducibility and control, but why do we then run the line set.seed(NULL)? The normal operation of R means that, in effect, its random seed changes every time it is used. This means R normally randomly determines randomness. This is how it should be until we want to determine the randomness. It is therefore good practice to set the seed to NULL after you have utilised your set seeds. This will revert the seed to its normal random operations. One last point to note is R versions. Version 3.6 changed R's sampling methods, therefore if you use Version 3.5 or below you will get different results than we have got. Hopefully the R developers will not change this in a later version again. "],["06-Random_seeds_practice.html", "Chapter 6 Random seed practice 6.1 RSQ1 6.2 RSQ2 6.3 RSQ3 6.4 Random seed recap", " Chapter 6 Random seed practice Brilliant! To reinforce your gained knowledge try out the following challenges. First create the following vector: second_millenium &lt;- 1001:2000 Note: Remember it is best practice to set.seed(NULL) at the end of a code cell. 6.1 RSQ1 Sample the object second_millenium with the following parameters: Extract 10 values Without replacement Use the random seed 489 What is the fourth number in the produced vector? 1120 1369 1744 RSQ1 code solution #RSQ1 #Set random seed set.seed(489) #Randomly sample first_answer &lt;- sample(x = second_millenium, size = 10)[4] first_answer #Reset random seed set.seed(NULL) 6.2 RSQ2 Sample the object second_millenium with the following parameters: Extract 24 values Without replacement Use the answer to the first question as the random seed What is the 16th number in the produced vector? 1120 1369 1744 RSQ2 code solution #RSQ2 #Set random seed set.seed(first_answer) #Randomly sample second_answer &lt;- sample(x = second_millenium, size = 24)[16] second_answer #Reset random seed set.seed(NULL) 6.3 RSQ3 Sample the object second_millenium with the following parameters: Extract a number of values equal to the answer of the second question With replacement Use the answer to the first question as the random seed What is the 999th number in the produced vector? 1120 1369 1744 RSQ3 code solution #RSQ3 #Set random seed set.seed(first_answer) #Randomly sample sample(x = second_millenium, size = second_answer, replace = TRUE)[999] #Reset random seed set.seed(NULL) 6.4 Random seed recap Once you are happy you can save then close and halt your \"Random_seeds.ipynb\" notebook. Through this section you have learnt: The use of random seeds for random processes such as sampling The difference between sampling with and without replacement How to set random seeds in R for reproducible randomness With this you can continue onto iterative rarefaction. "],["07-Iterating_rarefaction_intro.html", "Chapter 7 Iterating rarefaction intro &amp; setup 7.1 Iterating rarefaction setup 7.2 Rarefaction iterations 7.3 RNG vector creation", " Chapter 7 Iterating rarefaction intro &amp; setup In this section we will create code to carry out iterative rarefaction. For this we need to create a vector of random seeds, one for each iteration of rarefaction. We will loop through this vector, using each random seed to carry out one iteration of rarefaction. In the next sections we will utilise this code to produce alpha and beta diversity values that we will analyse. 7.1 Iterating rarefaction setup First, create a new R jupyter-notebook called \"Iterating_rarefaction.ipynb\". At the top of this notebook create a code cell to load in the various packages and data we need. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;IRdisplay&quot;) #Load processed but unrarefied data from R community analysis workshop load(&quot;phyloseq.RData&quot;) 7.2 Rarefaction iterations We need to choose the number of iterations we are going to carry out. For our speed we will use 10 iterations in this practice. In your real analysis I would recommend using 1000 iterations. Let's create a variable for our number of iterations. #Number of rarefaction iterations to be carried out #Using 10 here for speed, real analysis should use 1000 rarefaction_iters &lt;- 10 7.3 RNG vector creation We can now carry out Random Number Generation (RNG) to create a number of random seeds equal to the number of iterations planned. #Create rngseed vector #Set seed for reproducibility #This number was chosen randomly set.seed(2605) #Sample 10 (number of iters) values from the number range 1-100,000 rngseed_vec &lt;- sample(x=1:100000, size = rarefaction_iters, replace = FALSE) #Print out vector rngseed_vec #Save our rngseed vector save(rngseed_vec, file=&quot;rngseeds.RData&quot;) #Reset seed set.seed(NULL) There are a lot of steps above. These are: Setting the random seed: We carry this out so we will always get the same rngseed vector that will be used for the rarefaction iterations. This is important so you will always get the same results if you need to rework some analysis, stats, or plots. Also useful here so you get the same results as the instructor and other attendees. Creating the rngseed vector: We use our old friend sample() to create a random number for each iteration we will carry out. We arbitrarily sample from the numbers 1-100,000. You could change this to a larger range in your future research. We use our previous object rarefaction_iters as size= to produce a random number for each of our iterations. We carry this out without replacement so none of our rarefaction iterations are identical. Save the rngseed vector: We save the vector as a file. We will load this in our alpha and beta diversity notebooks to be used for iterative rarefaction. This is also useful so you have a backup file of the rngseed vectors. Reset seed: Always good to reset the seed at the end of a Jupyter notebook cell or after it has been used in a Rscript. "],["08-Phyla_relative_abundance.html", "Chapter 8 Phyla relative abundance 8.1 Subset and phyla aggregation 8.2 Phyla relative abundance bar chart", " Chapter 8 Phyla relative abundance Prior to iterative rarefaction we will look at the phyla composition of the environmental samples. 8.1 Subset and phyla aggregation For demonstrative purposes we will reduce the amount of samples and features in our data for this section. We will carry this out by: Subsetting the data so it only contains the 9 environmental samples. Aggregate the taxa to phyla whilst aggregating rare taxa to one \"other group\" #Reduce data for demonstrative purposes #Subset phyloseq object to only retain the ENV samples #I.e. remove the media samples physeq_env &lt;- phyloseq::subset_samples(pseq, media == &quot;ENV&quot;) #Aggregate to phyla level whilst aggregating rare phyla pseq_env_phyla &lt;- microbiome::aggregate_rare( pseq_env, level = &quot;Phylum&quot;, detection = 0.1, prevalence = 0.5, #Prevent info on aggregation to be printed out verbose = FALSE) #View count table otu_table(pseq_env_phyla) #Sum count of samples microbiome::readcount(pseq_env_phyla) #Remove unwanted objects rm(pseq, pseq_env) 8.2 Phyla relative abundance bar chart Let's have a quick look at the non rarefied phyla relative abundance through a bar chart. Note: This is how you would normally look at this type of bar chart. #Quick phyla bar chart of relative abundance #Relative abundance transformation pseq_env_phyla_relabund &lt;- microbiome::transform(pseq_env_phyla, &quot;compositional&quot;) #Create, save, and display bar chart phylum_bar &lt;- microbiome::plot_composition(pseq_env_phyla_relabund) ggsave(filename = &quot;./env_phyla_relabund.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 100, width = 100) IRdisplay::display_png(file = &quot;./env_phyla_relabund.png&quot;) "],["09-One_round_of_rarefaction.html", "Chapter 9 One Round of rarefaction 9.1 1R: Rarefaction 9.2 1R: Relative abundance bar chart 9.3 1R: Difference from non-rarefied", " Chapter 9 One Round of rarefaction Building up to multiple iterations of rarefaction we will first carry out one round of rarefaction on our environmental pPhyla relative abundance data. This will also allow us to compare the compare the results of no rarefaction to only one round. 9.1 1R: Rarefaction Carry out one round of rarefaction and view the rarefied counts. We are using the environmental samples subsetted and phyla aggregated data. Additionally, we are using the first of our random seeds in rng_seed_vec and the minimum read count as our rarefaction size. #One round of rarefaction pseq_env_phyla_rarefy_1 &lt;- phyloseq::rarefy_even_depth( pseq_env_phyla, #Minimum read count as rarefaction size sample.size = min(microbiome::readcount(pseq_env_phyla)), #First random seed as the rng seed rngseed = rngseed_vec[1]) #View count table otu_table(pseq_env_phyla_rarefy_1) #Sum count of samples microbiome::readcount(pseq_env_phyla_rarefy_1) You should see that all the samples now have a total count of 11046. 9.2 1R: Relative abundance bar chart Now to create a relative abundance bar chart with our rarefied data to compare to our non-rarefied data. Note: This is not something you would do in real analysis. #Quick phyla bar chart of relative abundance #Relative abundance transformation pseq_env_phyla_rarefy_1_relabund &lt;- microbiome::transform(pseq_env_phyla_rarefy_1, &quot;compositional&quot;) #Create, save, and display bar chart phylum_bar &lt;- microbiome::plot_composition(pseq_env_phyla_rarefy_1_relabund) ggsave(filename = &quot;./env_phyla_rarefy_1_relabund.png&quot;, plot = phylum_bar, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 100, width = 100) IRdisplay::display_png(file = &quot;./env_phyla_rarefy_1_relabund.png&quot;) Viewing the non-rarefied and rarefied based bar charts shows some differences. However, these are quite difficult to discern. 9.3 1R: Difference from non-rarefied To more easily see the differences we will subtract the two relative abundance tables from each other. This will produce a matrix of differences. #Value difference matrix single_rarefaction_diff &lt;- phyloseq::otu_table(pseq_env_phyla_relabund) - phyloseq::otu_table(pseq_env_phyla_rarefy_1_relabund) single_rarefaction_diff We can see there are differences. To make these differences even clearer let's make a histogram. #Histogram of differences hist(single_rarefaction_diff, main = &quot;Single rarefaction&quot;) What is the range of the differences compared to the non rarefied relative abundance values? -0.0003(-3e-04) to 0.0003(3e-04) -0.003 to 0.003 -0.015 to 0.015 Although these values appear quite small keep in mind we are working with relative abundance values. Each sample has a total relative abundance of 1.00 so a relative abundance value of 0.01 is 1%. Let's see if we can get these differences smaller with multiple rounds of rarefaction. "],["10-Multiple_rounds_of_rarefaction.html", "Chapter 10 Multiple Rarefaction iterations 10.1 MR: Rarefaction 10.2 Mathematical operators &amp; data frames 10.3 MR: Difference from non-rarefied", " Chapter 10 Multiple Rarefaction iterations This chapter will demonstrate how to use a loop to carry out multiple rounds of rarefaction. We'll then compare the non-rarefied data to our iteratively rarefied data. 10.1 MR: Rarefaction The below loop creates a relative abundance table created by 10 rounds of iteration. Type the code and read the annotations to understand it. Then run the code. #Iterative rarefaction to produce an average rarefied relative abundance table #Assign rarefaction size rarefaction_size &lt;- min(microbiome::readcount(pseq_env_phyla)) #Load our rng seed vector load(&quot;rngseeds.RData&quot;) #Initalise where we will store the output #In this case we create the first iteration #Carry out first rarefaction pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size #First random seed as the rng seed rngseed = rngseed_vec[1]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Extract relative abundance phyla table as a data frame relabund_phyla_df &lt;- as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) #Loop through the next 9 iterations #Add the relabund rarefied values to phyla_table for (i in 2:length(rngseed_vec)){ #Rarefy pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size rngseed = rngseed_vec[i]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Sum values to phyla_table relabund_phyla_df &lt;- relabund_phyla_df + as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) } #Average the values of the summed relabund phyla_table relabund_phyla_mean_df &lt;- relabund_phyla_df / length(rngseed_vec) The loop produces a data frame (relabund_phyla_df) that has all the values from the ten rarefied data frames summed in each corresponding cell. The final data frame is then divided by the number of iterations . This produces the final data frame relabund_phyla_mean_df. 10.2 Mathematical operators &amp; data frames Two numeric data frames/matrices can be summed together with + if they have the same dimensions. This can be carried out with any mathematical operator (+,-,*,/, etc.) An example of how this works is below. Note: You don't need to run the below code as the output is displayed. #Matrix 1 mat1 &lt;- matrix(1:9, nrow = 3, ncol = 3) mat1 ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 #Matrix 2 mat2 &lt;- matrix((1:9)*10, nrow = 3, ncol = 3) mat2 ## [,1] [,2] [,3] ## [1,] 10 40 70 ## [2,] 20 50 80 ## [3,] 30 60 90 #Summed matrix mat_sum &lt;- mat1 + mat2 mat_sum ## [,1] [,2] [,3] ## [1,] 11 44 77 ## [2,] 22 55 88 ## [3,] 33 66 99 If you only use one number with a data frame/matrix the operation will act upon each cell in the same manner. You could add 1 to each cell, minus 4 from each cell, etc. Continuing the matrix example, we'll get the average of the 2 data frames by dividins by two (/2). #Mean matrix mat_mean &lt;- mat_sum / 2 mat_mean ## [,1] [,2] [,3] ## [1,] 5.5 22.0 38.5 ## [2,] 11.0 27.5 44.0 ## [3,] 16.5 33.0 49.5 10.3 MR: Difference from non-rarefied We'll skip the bar chart this time and only look at the difference of the values. #Value difference matrix iterative_rarefaction_diff &lt;- as.matrix(phyloseq::otu_table(pseq_env_phyla_relabund) - relabund_phyla_mean_df) iterative_rarefaction_diff #Histogram hist(iterative_rarefaction_diff) What is the range of the differences compared to the non rarefied relative abundance values? -0.0003(-3e-04) to 0.0003(3e-04) -0.003 to 0.003 -0.015 to 0.015 You should notice that the differences are much smaller. This indicates that the structure of the iterative rarefied data is much closer to the non-rarefied data compared to the one round rarefied data. This is what we want. "],["11-Iterating_rarefaction_practice.html", "Chapter 11 Iterating rarefaction practice 11.1 One thousand iteration 11.2 Iterating rarefaction recap", " Chapter 11 Iterating rarefaction practice Superlative! Now that you know how to carry out iterative rarefaction I'll ask you to do it once more for the phyla data. 11.1 One thousand iteration Create a rarefaction averaged phyla relative abundance as we have done above but with 1000 rarefaction iterations. For this task use 153478 as the seed when creating your vector of 1000 rng seeds. Save this vector of rngseeds to a file called \"rngseeds_1000.RData\". Note: The iterative rarefaction step may take a few minutes. After creating the relative abundance matrix determine how different the values are compared to the non-rarefied relative abundance with a histogram. What is the range of the differences compared to the non rarefied relative abundance values? -0.0003(-3e-04) to 0.0003(3e-04) -0.003 to 0.003 -0.015 to 0.015 Please attempt the task yourself before looking at the solution code in the below expandable box. Task solution code #Number of rarefaction iterations to be carried out rarefaction_iters &lt;- 1000 #Create rngseed vector #Set seed for reproducibility set.seed(153478) #Create the rngseed vector #Sample 1000 (number of iters) values from the number range 1-100,000 rngseed_vec &lt;- sample(x=1:100000, size = rarefaction_iters, replace = FALSE) #Save our rngseed vector save(rngseed_vec, file=&quot;rngseeds_1000.RData&quot;) #Reset seed set.seed(NULL) #Iterative rarefaction to produce an average rarefied relative abundance table #Assign rarefaction size rarefaction_size &lt;- min(microbiome::readcount(pseq_env_phyla)) #Read in our rng seed vector load(&quot;rngseeds_1000.RData&quot;) #Initalise where we will store the output #In this case we create the first iteration #Carry out first rarefaction pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size rngseed = rngseed_vec[1]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Relabund phyla table object relabund_phyla_table &lt;- as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) #Loop through the next 999 iterations #Add the relabund rarefied values to phyla_table for (i in 2:length(rngseed_vec)){ #Rarefy pseq_rarefy &lt;- phyloseq::rarefy_even_depth(pseq_env_phyla, sample.size = rarefaction_size rngseed = rngseed_vec[i]) #Calculate relative abundance pseq_rarefy_relabund &lt;- microbiome::transform(pseq_rarefy, &quot;compositional&quot;) #Sum values to phyla_table relabund_phyla_table &lt;- relabund_phyla_table + as.data.frame(phyloseq::otu_table(pseq_rarefy_relabund)) } #Average the values of the summed relabund phyla_table relabund_phyla_table &lt;- relabund_phyla_table / length(rngseed_vec) #Value difference matrix iterative_rarefaction_1000_diff &lt;- as.matrix(phyloseq::otu_table(pseq_env_phyla_relabund) - relabund_phyla_table) iterative_rarefaction_diff #Histogram hist(iterative_rarefaction_diff) 11.2 Iterating rarefaction recap With this section you have learnt: How to create a vector of rngseeds How to use rng seeds to carry out iterative rarefaction In you real life analysis you would not use this method to create relative abundance taxonomy bar charts, you would use the non-rarefied relative abundance. However, this hopefully gave you a good idea of how iterative rarefaction works so we can utilise it the next 2 chapters for alpha and beta diversity analysis. Feel free to save then close and halt your \"Iterating_rarefaction.ipynb\" notebook. "],["12-Alpha_diversity_intro.html", "Chapter 12 \\(\\alpha\\) Diversity intro 12.1 \\(\\alpha\\): Setup 12.2 \\(\\alpha\\): Iterative rarefaction values", " Chapter 12 \\(\\alpha\\) Diversity intro In this section we'll carry out alpha diversity analysis using the iterative rarefaction approach. We will carry this out on the ASV counts rather than at a taxonomy level such as phyla. These materials are mostly a combination of the iterative rarefaction in this book and the alpha diversity analysis in the R community workshop. Due to this we won't go into great detail, instead focussing on giving you the code to be able to carry this out. 12.1 \\(\\alpha\\): Setup Create a new R jupyter notebook called \"Alpha_diversity.ipynb\". Load the required data and libraries. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;tidyverse&quot;) library(&quot;IRdisplay&quot;) library(&quot;ggpubr&quot;) #Load processed but unrarefied ASV data from main R community workshop load(&quot;phyloseq.RData&quot;) 12.2 \\(\\alpha\\): Iterative rarefaction values Before carrying out iterative rarefaction we need to decide on a few values Rarefaction size: The sequence depth to normalise samples to We are using the minimum sample depth here The size you choose will be based on your data and what you feel is appropriate More info in the R community workshop RNG seeds: The rng seeds we will use for all the rarefactions We created these in the previous chapter Rarefaction iterations: The number of rarefaction iterations we will use We are using 10 here based on the length of our rng seed vector We recommend you use 1000 in your real analysis #Rarefaction values #Rarefaction size #Minimum sample depth in this case rarefaction_size &lt;- min(microbiome::readcount(pseq)) #Load the vector of 10 rngseeds created in the previous chapter load(&quot;rngseeds.RData&quot;) #Number of rarefaction iterations to be carried out #Based on length of rng seed vector rarefaction_iters &lt;- length(rngseed_vec) "],["13-Alpha_diversity_rarefaction.html", "Chapter 13 \\(\\alpha\\): Iterative rarefaction loop", " Chapter 13 \\(\\alpha\\): Iterative rarefaction loop Now we will create averaged alpha diversity values through iterative rarefaction. We will carry this out by: Calculating initial alpha diversity values from the first iteration Looping through the subsequent rarefaction iterations and adding/summing calculated alpha diversity values to the initial alpha diversity values Dividing each value of the final summed alpha diversity by the number of rarefaction iterations. For this we will use the function microbiome::alpha() to calculate our alpha diversity values. #Loop to create iteration based rarefied alpha diversity values #Create data frame to contain final summed alpha diversity values #In this case we&#39;ll run the first rarefied alpha diversity analysis pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[1], verbose = FALSE) #Alpha diversity alpha_df_sum &lt;- microbiome::alpha(pseq_rarefy, index = &quot;all&quot;) #Loop through 2 to the number of iterations for (i in 2:rarefaction_iters){ pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[i], verbose = FALSE) #Alpha diversity alpha_df &lt;- microbiome::alpha(pseq_rarefy, index = &quot;all&quot;) #Add/sum the new data frame values to the sum data frame alpha_df_sum &lt;- alpha_df_sum + alpha_df } #Divide by number of rarefaction iterations to get average alpha_df_mean &lt;- alpha_df_sum / rarefaction_iters #Save alpha mean data frame save(alpha_df_mean, file = &quot;alpha_df_mean.RData&quot;) #Remove unneeded objects rm(pseq,alpha_df_sum, alpha_df) verbose = FALSE option We include the option verbose = FALSE in the phyloseq::rarefy_even_depth() to prevent a lot of text to be displayed. This text says which rngseed was used in the rarefaction. We don't need this message as we already have a record of the rngseeds we used in rngseed_vec. You can check the structure and contents of our alpha diversity data frame with head(). head(alpha_df_mean) There are a lot of diversity metrics. We are only interested in a few of them here but we will remove the other ones later on. "],["14-Alpha_data_frame_tidy.html", "Chapter 14 \\(\\alpha\\) data frame tidying 14.1 \\(\\alpha\\): Metric and metadata data frame 14.2 \\(\\alpha\\): Long data frame 14.3 \\(\\alpha\\): Subset metrics", " Chapter 14 \\(\\alpha\\) data frame tidying In this section we will tidy up our data frame to make it ready for plotting by: Combining our alpha diversity values and metadata Converting our wide data frame to a long data frame Subsetting our data frame so it only contains the alpha diversity metrics we want to plot 14.1 \\(\\alpha\\): Metric and metadata data frame Now that we have our alpha diversity values we can create a data frame that contains these values and the metadata. In the below code we extract the metadata from the rarefied phyloseq object created in the last rarefaction iteration loop. This ensures we only acquire metadata from samples that are retained after rarefaction. The samples that are retained are always the same across our rarefaction iterations. This is because samples are retained based on the rarefaction size/depth which is kept consistent across our rarefactions iterations. #Combine metadata and alpha diversity mean values into one data frame #Extract metadata from rarefied phyloseq object metadf &lt;- phyloseq::sample_data(pseq) #Ensure row names are identical #if not sort alpha data frame rows by metadata row names if (identical(row.names(metadf), row.names(alpha_df_mean)) == FALSE) { alpha_df_mean &lt;- alpha_df_mean[row.names(metadf),] } #Combine with cbind (column bind) meta_alpha_mean_df &lt;- cbind(metadf,alpha_df_mean) head(meta_alpha_mean_df) #Remove rarefied phyloseq object that we do not need any more in this notebook rm(pseq_rarefy) From the output of head() you should see a table with the first set of columns being the metadata columns. The next set of columns is the alpha diversity metrics. 14.2 \\(\\alpha\\): Long data frame We will plot our alpha diversity values with ggplot2 functions. Before we carry this out we need to convert our wide data frame to a long data frame. We'll carry this out with tidyr::pivot_longer(). We want our metric values to become long. This means that instead of the alpha diversity values being spread across multiple rows and columns, there will only be one value per row. Two columns will represent these values in the long format: metric: The name of the alpha diversity metric value: The value of the alpha diversity metric #Create long version for plotting #alpha_df_mean (no metadata) column names to be used for long conversion alpha_div_colnames &lt;- colnames(alpha_df_mean) #Wide to long meta_alpha_mean_long_df &lt;- tidyr::pivot_longer(data = meta_alpha_mean_df, #Change the alpha diversity names to long format #I.e. keep our metadata columns as separate columns #all_of() used to silence warning message cols = all_of(alpha_div_colnames) #Set metric names to column called metric #Set values to column called value names_to = &quot;metric&quot;, values_to = &quot;value&quot; ) #Change our metric column to a factor #Useful for plotting meta_alpha_mean_long_df$metric &lt;- as.factor(meta_alpha_mean_long_df$metric) #Check head and dimensions of long data frame head(meta_alpha_mean_long_df) dim(meta_alpha_mean_long_df) #Remove unneeded objects rm(alpha_df_mean, metadf) 14.3 \\(\\alpha\\): Subset metrics There are a lot of diversity values created by microbiome::alpha(). For this tutorial we are only interested in: observed: The number of observed features (ASVs, Phlya, Species, etc.) chao1: The estimated real total number of features diversity_shannon: The Shannon diversity metric An estimate of feature diversity based on richness (presence/absence) and abundance The higher the value the higher the diversity We'll subset our long data frame to only retain rows with these metrics. We'll also use the utility of factors to order the metrics so they will be plotted in our preferred order. #Process our long data frame #Subset our long alpha diversity data frame to only contain our metrics of choice metrics &lt;- c(&quot;observed&quot;, &quot;chao1&quot;,&quot;diversity_shannon&quot;) basic_alpha_metrics_long_df &lt;- meta_alpha_mean_long_df[ meta_alpha_mean_long_df$metric %in% metrics, ] #Change instances of diversity_shannon to shannon basic_alpha_metrics_long_df$metric &lt;- gsub(pattern = &quot;diversity_shannon&quot;, replacement = &quot;shannon&quot;, x = basic_alpha_metrics_long_df$metric) #The gsub() function changes our factor to a character vector #Therefore change back to factor #We will also choose our order of the metric names for plotting basic_alpha_metrics_long_df$metric &lt;- factor(x = basic_alpha_metrics_long_df$metric, levels = c(&quot;observed&quot;,&quot;chao1&quot;,&quot;shannon&quot;)) #Check level order of metric factor column levels(basic_alpha_metrics_long_df$metric) #Check head of subsetted long data frame head(basic_alpha_metrics_long_df) With this data frame we can move onto visualisation and statistics. "],["15-Alpha_violin_plot_and_stats.html", "Chapter 15 \\(\\alpha\\): Plot and stats 15.1 \\(\\alpha\\): Violin plot 15.2 \\(\\alpha\\): Stats", " Chapter 15 \\(\\alpha\\): Plot and stats In this chapter we will create a violin plot, similar to a box plot, to visullaise our metrics. To detmeine if differences are significant we will then carry out Kruskal Wallis test and Paired Wilcoxon tests. 15.1 \\(\\alpha\\): Violin plot To visualise the differences of the alpha diversity values between the four different media we'll use violin plots. We can use the function ggplot2::geom_violin() to carry this out. Additionally, we'll add a point for each value and colour it based on the site it canme from (UD, MD, or LD). The function ggforce::geom_sina() can be used for this. We'll use its parameter alpha() to make the points 50% (0.5) transparent. As we are plotting values from three different metrics we will split the plot into three separate plots. ggplot2::facet_wrap() can be used for this tasked with ~metric used to split the plot by the metrics. We also specify scales = \"free\" so each of the three plots has their own x and y scales. This is important when the values are drastically different such is the case between the observed and chao1 (&gt;100) compared to the shannon values (&lt;10). scales options The four scales are: \"fixed\" (default): All the scales are the same (fixed), based on the largest and smallest x and y values across all the plots. Useful where you want direct comparisons such as looking at teh overall pattern in ordination plots. \"free\": All the scales are free. Each plot's x and y values limits are based on the data within it. \"free_x\": The x axis is free and the y axis is fixed. \"free_y\": The y axis is free and the x axis is fixed. Which you want to use depends on your data and how you are facetting it. #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(basic_alpha_metrics_long_df, aes(x = media, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Site&quot;, x = &quot;Media&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_media_violinplot.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_media_violinplot.png&quot;) 15.2 \\(\\alpha\\): Stats We can carry out statistics to compare the alpha diversity values between sample groups. 15.2.1 Kruskal Wallis test To determine if there is an overall difference in our data we'll use the Kruskal Wallis test. We'll carry this out using the media grouping for our three alpha diversity values. #Kruskal Wallis test #Observed ASVs kruskal.test(observed ~ media, data = meta_alpha_mean_df) #Chao1 estimator kruskal.test(chao1 ~ media, data = meta_alpha_mean_df) #Shannon diversity kruskal.test(shannon ~ media, data = meta_alpha_mean_df) All the p-values are less than 0.05 indicating statistical significance. That means we can move onto pairwise comparisons. 15.2.2 Paired Wilcoxon test To determine what groups are significantly different from each other we can carry out paired Wilcoxon test. This tests #Paired wilcoxon test #Observed ASVs pairwise.wilcox.test(meta_alpha_mean_df$observed, meta_alpha_mean_df, p.adjust.method = &quot;holm&quot;) #Chao1 estimator pairwise.wilcox.test(meta_alpha_mean_df$chao1, meta_alpha_mean_df, p.adjust.method = &quot;holm&quot;) #Shannon diversity pairwise.wilcox.test(meta_alpha_mean_df$shannon, meta_alpha_mean_df, p.adjust.method = &quot;holm&quot;) You'll see three p-value adjusted tables with all the values (except Shannon: ENV against TSA) being significant (&lt;0.05). "],["16-Alpha_plot_with_stats.html", "Chapter 16 \\(\\alpha\\): Plot with stats 16.1 List of comparisons 16.2 Violin plot with stats 16.3 Reorder x-axis and stats", " Chapter 16 \\(\\alpha\\): Plot with stats Rather than having the plot and stats separate, we can add stats onto our plot. This can be carried out with the function stat_compare_means() from the `ggpubr package. 16.1 List of comparisons To produce pairwise comparisons with ggpubr::stat_compare_means() we need a list of the comparisons we want to carry out. We can create this with the function combn(), short for combination. We provide it with three parameters: Input data: This is a vector of the unique metadata categories to create the combinations from We are using our created uniq_media_values_chr_vec in this case We ensure that this is a vector of characters so the created combination list contains character vectors A list of character vectors is required for ggpubr::stat_compare_means() m =: The number of elements to choose when creating combinations. We choose 2 so we get all pair combinations simplify =: Indicates if the result should be simple (TRUE) or not (FALSE) TRUE returns a simplified array such as a matrix or a data frame FALSE returns a list. This is what we want as ggpubr::stat_compare_means() requires a list #To compare mean we need to create a list of comparisons #Create character vector of unique metadata values (media in this case) uniq_media_values_chr_vec &lt;- unique(as.character(basic_alpha_metrics_long_df$media)) uniq_media_values_chr_vec #Can use combn() to get comparisons my_comparisons &lt;- combn(uniq_media_values_chr_vec, m = 2, simplify = FALSE)) #Check contents and structure my_comparisons str(my_comparisons) 16.2 Violin plot with stats With our list of comparisons we can add ggpubr::stat_compare_means() to our ggplot2 code. This function will both calculate the Wilcoxon tests and add them to the plot. #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(basic_alpha_metrics_long_df, aes(x = media, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Site&quot;, x = &quot;Media&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) + #Add comparisons ggpubr::stat_compare_means(comparisons = my_comparisons) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;) 16.3 Reorder x-axis and stats ggplot orders the x-axis by alphabetical order. This is not normally wanted so we will convert our media column to a factor and order the levels how we want them. As the environmental samples can be seen as the baseline we will have them first. #Set order of media basic_alpha_metrics_long_df$media &lt;- factor(basic_alpha_metrics_long_df$media, #Set order of levels levels = c(&quot;ENV&quot;, &quot;CVP&quot;, &quot;KBC&quot;, &quot;TSA&quot;)) The stats in our previous plot were also not in a good order. We'll therefore reorder them. When doing this it is important to note that the first comparison in the lists is the bottom most stat in the plot. #Order comparisons my_ordered_comparisons &lt;- my_comparisons[c(1,2,6,4,3,5)] my_ordered_comparisons You'll notice this can be quite manual. It can be made easier when doing this yourself to roughly reorder, run the below code for your plot, then fix the stats reorder. With our media categories and comparisons reordered we can create the final plot. #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(basic_alpha_metrics_long_df, aes(x = media, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Site&quot;, x = &quot;Media&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) + #Add comparisons ggpubr::stat_compare_means(comparisons = my_ordered_comparisons) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_media_violinplot_pairwise_wilcox.png&quot;) "],["17-Alpha_diversity_practice.html", "Chapter 17 \\(\\alpha\\): Practice 17.1 \\(\\alpha\\): Task 17.2 \\(\\alpha\\): Recap", " Chapter 17 \\(\\alpha\\): Practice 17.1 \\(\\alpha\\): Task As an optional task create a new violin plot that includes the following: Plots the metrics: \"chao1\" \"evenness_pielou\" renaming it as \"pielou\" \"diversity_fisher\" renaming it as \"fisher\" Ensure they are in the order \"chao1\", \"pielou\", then \"fisher\" The x-axis is separated by Site (UD, MD, LD) rather than media. Ensure the order is UD, MD, then LD Points are coloured by Media (ENV, CVP, KBC, and TSA) Ensure the order is ENV, CVP, KBC, then TSA Include Wilcoxon paired stats comparing the Sites Solution code Subset long alpha diversity table created earlier in this chapter to contain metrics of choice. #Process our long data frame #Subset our long alpha diversity data frame to only contain our metrics of choice metrics &lt;- c(&quot;chao1&quot;, &quot;evenness_pielou&quot;,&quot;diversity_fisher&quot;) subset_alpha_metrics_long_df &lt;- meta_alpha_mean_long_df[ meta_alpha_mean_long_df$metric %in% metrics, ] #Change instances of evenness_pielou to pielou subset_alpha_metrics_long_df$metric &lt;- gsub(pattern = &quot;evenness_pieloue&quot;, replacement = &quot;pielou&quot;, x = subset_alpha_metrics_long_df$metric) #Change instances of diversity_fisher to fisher subset_alpha_metrics_long_df$metric &lt;- gsub(pattern = &quot;diversity_fisher&quot;, replacement = &quot;fisher&quot;, x = subset_alpha_metrics_long_df$metric) #The gsub() function changes our factor to a character vector #Therefore change back to factor #We will also choose our order of the metric names for plotting subset_alpha_metrics_long_df$metric &lt;- factor(x = subset_alpha_metrics_long_df$metric, levels = c(&quot;chao1&quot;,&quot;pielou&quot;,&quot;fisher&quot;)) #Check level order of metric factor column levels(subset_alpha_metrics_long_df$metric) #Check head of subsetted long data frame head(subset_alpha_metrics_long_df) Create metadata combination list for plot stats #To compare mean we need to create a list of comparisons #Create character vector of unique metadata values (site in this case) uniq_site_values_chr_vec &lt;- unique(as.character(subset_alpha_metrics_long_df$site)) uniq_site_values_chr_vec #Can use combn() to get comparisons my_comparisons &lt;- combn(uniq_site_values_chr_vec, m = 2, simplify = FALSE)) #Check contents and structure my_comparisons str(my_comparisons) Reorder factors and comparisons #Reorder sites, media and comparisons #Set order of sites subset_alpha_metrics_long_df$site &lt;- factor(subset_alpha_metrics_long_df$site, #Set order of levels levels = c(&quot;UD&quot;, &quot;MD&quot;, &quot;LD&quot;)) #Set order of media subset_alpha_metrics_long_df$media &lt;- factor(subset_alpha_metrics_long_df$media, #Set order of levels levels = c(&quot;ENV&quot;, &quot;CVP&quot;, &quot;KBC&quot;, &quot;TSA&quot;)) #Order comparisons my_ordered_comparisons &lt;- my_comparisons[c(1,3,2)] my_ordered_comparisons Plot with stats #Produce ggplot object of violin plot alpha_violinplot &lt;- ggplot(subset_alpha_metrics_long_df, aes(x = site, y = value)) + ggplot2::geom_violin() + ggforce::geom_sina(alpha=0.5, aes(color=site)) + ggplot2::labs(color = &quot;Media&quot;, x = &quot;Site&quot;, y = &quot;Value&quot;) + ggplot2::facet_wrap(~metric, scales = &quot;free&quot;) + #Add comparisons ggpubr::stat_compare_means(comparisons = my_ordered_comparisons) #Save ggplot2 object with ggsave() ggsave(filename = &quot;./Alpha_diversity_rarefy_iters_site_violinplot_pairwise_wilcox.png&quot;, plot = alpha_violinplot, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 150, width = 250) #Display plot IRdisplay::display_png(file = &quot;./Alpha_diversity_rarefy_iters_site_violinplot_pairwise_wilcox.png&quot;) 17.2 \\(\\alpha\\): Recap In this chapter you have: Produced alpha diversity values through iterative rarefaction Created a long data frame containing metadata and specified alpha diversity metrics Visualised the group differences of alpha diversity metrics with violin plots Embedded paired Wilcoxon p-values in our violin plots With these skills and knowledge you will be able to carry out thorough investigations of alpha diversity in your future research. "],["18-Beta_intro.html", "Chapter 18 \\(\\beta\\) Diversity intro 18.1 \\(\\beta\\): Setup", " Chapter 18 \\(\\beta\\) Diversity intro This section will teach you how to carry out beta diversity analysis. The steps will include: Calculating beta diversity distances Using iterative rarefaction to create averaged distance values Carrying various ordination techniques to visualise the distances between samples 18.1 \\(\\beta\\): Setup Create a new R jupyter notebook called \"Beta_diversity.ipynb\". Load the required data and libraries. #Libraries library(&quot;phyloseq&quot;) library(&quot;microbiome&quot;) library(&quot;IRdisplay&quot;) library(&quot;vegan&quot;) library(&quot;rbiom&quot;) library(&quot;ape&quot;) #Load processed but unrarefied ASV data from main R community workshop load(&quot;phyloseq.RData&quot;) "],["19-Beta_distances_metrics.html", "Chapter 19 \\(\\beta\\): Distance matrices 19.1 Unifrac distances 19.2 Vegan distances", " Chapter 19 \\(\\beta\\): Distance matrices Here we'll find out how to produce a paired distance matrix with our beta diversity metric of choice. Unfortunately there is not one function that can calculate all the metrics we may want. 19.1 Unifrac distances Unifrac distances are preferred by many when a phylogenetic tree is available for your data. We are working with 16S data so a phylogenetic tree was created. Other barcodes or types of data may not have a phylogenetic such as ITS data or complex shotgun metagenomic data. To produce a Unifrac distance matrix we will use the function unifrac() from the package rbiom. The function rbiom::unifrac() was created to work with biom files and not phyloseq objects. Thankfully we don't need to convert our objects to a biom object, instead only needing to extract our count/abundance data and phylogenetic tree. We can carry this out with the following 2 functions: phyloseq::otu_table(): Extracts the feature count/abundances table phyloseq::phy_tree(): Extract the phylogenetic tree There are 2 types of Unifrac distances: Weighted: Incorporate relative abundances Unweighted: Does not incorporate relative abundances We'll calculate weighted Unifrac distances by specifying the parameter weighted = TRUE. So our output works with subsequent ordination step we'll convert the output of rbiom::unifrac() into a matrix with as.matrix(). Carry out the matrix production with the below script: #Calculate weighted unifrac values unifrac_rbiom_microbiome &lt;- as.matrix( rbiom::unifrac(biom = phyloseq::otu_table(pseq), tree = phyloseq::phy_tree(pseq), weighted = TRUE)) #Check the first 6 rows and columns of the resulting distance matrix head(unifrac_rbiom_microbiome) 19.2 Vegan distances To calculate non-unifrac beta diversity distances we can use the vegan package and its function vegdist(). The function rbiom::unifrac() calculates paired distances, this is the samples in the otu_table of a phyloseq object. Unfortunately, vegan::vegdist() calculates paired distances by rows (features), this being the features in the otu_table of a phyloseq object. We do not want this but thankfully all we need to add is the function t() to our abundance object to transpose the data. Create a Bray-Curtis distance matrix with the below code: #Calculate Bray-Curtis distance matrix bray_curtis_mat &lt;- as.matrix( vegan::vegdist(x = t(phyloseq::otu_table(pseq)), method = &quot;bray&quot;)) #Check first 6 rows and columns of matrix bray_curtis_mat[1:6,1:6] The function can calculate a plethora of metrics with the full list available at the following webpage. "],["20-Beta_rarefaction.html", "Chapter 20 \\(\\beta\\): Iterative rarefaction 20.1 Iterative rarefaction values 20.2 Iterative beta diversity calculation", " Chapter 20 \\(\\beta\\): Iterative rarefaction Now that we know how to create a beta diveristy paired distance matrix, we can create one with averaged values created by iterative rarefaction. 20.1 Iterative rarefaction values We need to set our rarefaction values and rngseeds. We can use the same code as we used in the alpha_diversity analysis. #Rarefaction values #Rarefaction size #Minimum sample depth in this case rarefaction_size &lt;- min(microbiome::readcount(pseq)) #Load the vector of 10 rngseeds created in the previous chapter load(&quot;rngseeds.RData&quot;) #Number of rarefaction iterations to be carried out #Based on length of rng seed vector rarefaction_iters &lt;- length(rngseed_vec) 20.2 Iterative beta diversity calculation The below code carries out itertaive rarefaction and produces an averaged weighted unifrac paired distance matrix. #Loop to create iteration based rarefied weighted unifrac values #Create matrix to contain summed wunifrac beta diversity values #In this case we&#39;ll run the first rarefied beta diversity analysis pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[1], verbose = FALSE) #wunifrac beta diversity beta_df_sum &lt;- as.matrix( rbiom::unifrac( biom = phyloseq::otu_table(pseq_rarefy), tree = phyloseq::phy_tree(pseq_rarefy), weighted = TRUE)) #Loop through 2 to the number of iterations for (i in 2:rarefaction_iters){ #Rarefaction pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[i], verbose = FALSE) #Beta diversity beta_df &lt;- as.matrix( rbiom::unifrac( biom = phyloseq::otu_table(pseq_rarefy), tree = phyloseq::phy_tree(pseq_rarefy), weighted = TRUE)) #Add/sum the new data frame values to the sum data frame beta_df_sum &lt;- beta_df_sum + beta_df } #Divide by number of rarefaction iterations to get average beta_df_mean &lt;- beta_df_sum / rarefaction_iters #Save alpha mean data frame save(beta_df_mean, file = &quot;wunifrac_df_mean.RData&quot;) #View first 6 rows and columns of matrix beta_df_mean[1:6,1:6] #Remove unneeded objects rm(beta_df_sum, beta_df_mean, pseq_rarefy) verbose = FALSE option We include the option verbose = FALSE in the phyloseq::rarefy_even_depth() to prevent a lot of text to be displayed. This text says which rngseed was used in the rarefaction. We don't need this message as we already have a record of the rngseeds we used in rngseed_vec. You'll notice that each value is duplicated, once in the bottom left triangle and once in the top right triangle. This is fine as the subsequent functions in this chapter will work with this in the same manner as if the matrix was de-duplicated. In the above case we saved our final distance matrix and removed it. We will then load the object in the next section. This is convenient as it means we only need to run this code cell once. With higher numbers of rarefaction iterations it can take a while. "],["21-Beta_ordination.html", "Chapter 21 \\(\\beta\\): Ordination 21.1 Load weighted unifrac matrix 21.2 NMDS 21.3 PCoA 21.4 Ordination recap", " Chapter 21 \\(\\beta\\): Ordination There are various ways to ordinate paired dissimilarity distances. We are going to use two of the most popular for community based data: NMDS and PCoA. 21.1 Load weighted unifrac matrix Prior to ordination we need to load the weighted unifrac matrix. This is a useful cell to have as we don't need to rerun the iterative rarefaction to reacquire this object if we save, close + halt, and then reopen this notebook. #Load wunifrac matrix load(&quot;wunifrac_df_mean.RData&quot;) 21.2 NMDS The first ordination technique we will use is NMDS (Non-metric MultiDimensional Scaling). To carry this out we can use the function vegan::monoMDS(). 21.2.1 NMDS ordinate We provide the function with our beta diversity dissimilarity matrix and the parameter k = 2. The parameterk specifies the number of dimensions to calculate, we want 2 as we will only be plotting an x and y axis i.e. 2 dimensions. #NMDS ordinate nmds_res &lt;- vegan::monoMDS(beta_df_mean, k = 2) #Structure of nmds_res str(nmds_res) 21.2.2 NMDS points The function produces a list containing 28 different objects. Here we are only interested in the points data frame. This contains the points we will be plotting in our NMDS plot. Lets extract this data frame. #Extract plot points nmds_points &lt;- nmds_res$points #Check head head(nmds_points) 21.2.3 NMDS data frame with metadata Before plotting with ggplot2 we need to combine the metadata and points into a long data frame. There is no need to \"longify\" our data frame as it will start in the long format we require. #Create long data frame with metadata and points #Extract metadata and ensure row names order matches metadf &lt;- phyloseq::sample_data(pseq) if (identicial(row.names(metadf), row.names(nmds_points)) == FALSE) { metadf &lt;- metadf[row.names(nmds_points),] } #Make points with metadata data frame nmds_points_metadata &lt;- cbind(nmds_points, metadf) #Check head of data frame head(nmds_points_metadata) #Save object we want, remove ones we don&#39;t save(nmds_points_metadata, file = &quot;wunifrac_NMDS.RData&quot;) rm(metadf, nmds_res, nmds_points) 21.2.4 NMDS scatter plot Now we can produce a NMDS scatter plot. We will colour the points by site and the point shapes will be determined by the media. #Produce NMDS scatter plot #Plot ordination nmds.wunifrac &lt;- ggplot(data = nmds_points_metadata, aes(x = NMDS1, y = NMDS2, color = site, shape = media)) + ggplot2::geom_point() #Save ggplot2 object with ggsave ggsave(filename = &quot;./Beta_diversity_NMDS_wunifrac_media_site.png&quot;, plot = nmds.wunifrac, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 125, width = 150) #Display plot IRdisplay::display_png(file = &quot;./Beta_diversity_NMDS_wunifrac_media_site.png&quot;) Super! You should see that the plot is mainly separated by NMDS1 splitting the ENV samples compared to the media samples. The next major difference is in NMDS2 which separates the TSA samples compared to the CVP and KBC samples. The CVP and KBC samples also appear to form distinct clusters. 21.3 PCoA The second, and last, ordination method we will look at is PCoA (Principal Correspondence Analysis). 21.3.1 PCoA ordinate The vegan package cannot carry out PCoA ordination. Therefore, we will use the function pcoa() from the ape package. #PCoA ordinate pcoa_res &lt;- ape::pcoa(beta_df_mean) #Structure of pcoa_res str(pcoa_res) The function creates a list containing 5 objects. We are interested in 2 of these objects, vectors and values. 21.3.2 PCoA points Whereas we can specify the number of dimensions we want for NMDS, PCoA will create a certain number of dimensions based on the provided data. The vectors object contains the axes points for all these dimensions. We will only plot the first 2 axes. Extract these points: #Extract first 2 axes pcoa_points &lt;- pcoa_res$vectors[,1:2] head(pcoa_points) 21.3.3 PCoA variance As there are multiple axes created we need to know the strength of each axis. This is known as the \"Percentage/proportion of variance explained\", this tells us how much of the total variance is explained by each axis. The axes are always ordered from highest to lowest % variance explained. Therefore axis one explains the most variance, followed by axis 2. The higher the % variance explained of axis 1 and axis 2, the better our subsequent plot represents our data. General guidelines to how good our plot are based on the sum of these 2 values: &lt;50%: Poor 50-69%: Decent 70-89%: Good 90-100%: Great The % variance explained is contained in the values data frame within the Relative_eig column. These are proportion values (0-1) so we will times them by 100 to make them percentages and round these digits to 2 decimal places (round(,digits=2). Let's extract the % variance explained values. #Variation explained values pcoa_axis_var_explained &lt;- round(x=pcoa_res$values[,&quot;Relative_eig&quot;] * 100, digits=2) 21.3.4 PCoA data frame with metadata As with the NMDS data we will create a long data frame containing our points and metadata. #Create point long data frame with metadata #Extract metadata and ensure row names order matches metadf &lt;- phyloseq::sample_data(pseq) if (identicial(row.names(metadf), row.names(pcoa_points)) == FALSE) { metadf &lt;- metadf[row.names(pcoa_points),] } #Make points with metadata data frame pcoa_points_metadata &lt;- cbind(pcoa_points, metadf) head(pcoa_points_metadata) #Save object we want, remove ones we don&#39;t save(pcoa_points_metadata, file = &quot;wunifrac_PCoA.RData&quot;) rm(metadf, pcoa_res, pcoa_points) 21.3.5 PCoA scatter plot When plotting a PCoA scatter plot it is important to include the % variance on the axes labels. We will carry this out using the pcoa_axis_var_explained vector we created earlier. #Produce PCoA scatter plot #Plot ordination pcoa.wunifrac &lt;- ggplot(data = pcoa_points_metadata, aes(x = Axis.1, y = Axis.2, color = site, shape = media)) + ggplot2::geom_point() + #Add x and y labels to include % variance explained labs(x = paste0(&quot;Axis.1 [&quot;, pcoa_axis_var_explained[1], &quot;%]&quot;), y = paste0(&quot;Axis.2 [&quot;, pcoa_axis_var_explained[2], &quot;%]&quot;)) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Beta_diversity_pcoa_wunifrac_media_site.png&quot;, plot = pcoa.wunifrac device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 125, width = 150) #Display plot IRdisplay::display_png(file = &quot;./Beta_diversity_pcoa_wunifrac_media_site.png&quot;) We have a PCoA plot which represents 82.1% (67.46+14.64) of the variance of our data. It is quite similar to our NMDS plot. 21.4 Ordination recap In this chapter you have created ordination values (NMDS &amp; PCOA) with iterative rarefaction and created scatter plots with these. In the next chapter we will use the ordination values to carry out statistics. "],["22-Beta_stats.html", "Chapter 22 \\(\\beta\\): Stats 22.1 Stats setup 22.2 PERMANOVA 22.3 Pairwise PERMANOVA", " Chapter 22 \\(\\beta\\): Stats Now to carry out some statistics on our ordinations. These are the same methods as covered in the R community analysis workshop. However, the code is slightly different. 22.1 Stats setup Load the required data. #Load wunifrac load(&quot;wunifrac_df_mean.RData&quot;) #Extract metadata #need data.frame() for vegan::adonis2() used later metadf &lt;- data.frame(phyloseq::sample_data(pseq)) 22.2 PERMANOVA To determine if their is a significant overall difference between the media &amp; site groups we can carry out a PERMANOVA. We'll use the package vegan with its function adonis2(). Note: The original vegan::adonis() function is deprecated and should not be used. #PERMANOVA of media+site wunifrac_adonis &lt;- vegan::adonis2(beta_df_mean ~ media+site, data = metadf, by = &quot;margin&quot;) 22.3 Pairwise PERMANOVA We can use a pairwise PERMANOVA to determine if their are significant differences between groups in a metadata category. The below code carries this out for the media groupings. #Pairwise PERMANOVA for media #Get combinations of unique media values cbn &lt;- combn(x = unique(metadf$media), m = 2) #Create empty final data frame with 4 columns # and a number of rows equal to the the number of combinations pairwise_permanova_df &lt;- as.data.frame(matrix(data = NA, nrow = ncol(cbn), ncol = 4)) #Add column names colnames(pairwise_permanova_df) &lt;- c(&quot;1&quot;,&quot;2&quot;,&quot;p&quot;,&quot;p.adj&quot;) #Loop through the combinations for(i in 1:ncol(cbn)){ #Subset metadata metadata_subset &lt;- metadf[metadf$media %in% cbn[,i],] #Extract sample names samples_subset &lt;- row.names(metadf_subset) #Subset distance matrix wunifrac_dist_mat_subset &lt;- beta_df_mean[samples_subset,samples_subset] #PERMANOVA/ADONIS of media #Ensure to change group name if using different group (media) pairwise_adonis &lt;- vegan::adonis2( wunifrac_dist_mat_subset ~ media, data = metadf_subset, by = &quot;margin&quot;) #Add the group names and p-value to the main data frame pairwise_permanova_df[i,1:2] &lt;- cbn[,i] pairwise_permanova_df[i,3] &lt;- wunifrac_pairwise_adonis[1,&quot;Pr(&gt;F)&quot;] } #Add adjusted P-values pairwise_permanova_df$p.adj &lt;- p.adjust(pairwise_permanova_df$p, method = &quot;BH&quot;) #View data frame pairwise_permanova_df #Write to a file write.table(x = pairwise_permanova_df, file = &quot;pairwise_permanova_media_wunifrac.tsv&quot;, quote = FALSE, row.names = FALSE) "],["23-Beta_subset_ordination.html", "Chapter 23 \\(\\beta\\): Subset ordinations 23.1 Subset distance matrix 23.2 Points long data frame 23.3 Media PCoA scatter plot 23.4 Stats?", " Chapter 23 \\(\\beta\\): Subset ordinations When you ordinate data the distances within groups may be hard to see. This can be caused by one group causing a larger difference and therefore most of the displayed variation is explaining that. This can be seen with our previous ordination plots where the majority of the variation explained is caused by the difference of the environmental samples against the media samples. We will therefore subset our ordination in this chapter to only look at the media samples. 23.1 Subset distance matrix The ordination values (PCoA, NMDS) will change when you remove or add samples. This means we cannot simply subset our ordination points. However, paired distance values never change between samples. We can therefore subset our distance matrix and then ordinate it. This is much better than having to carry out the iterative rarefaction again. Subset out previously produced distance matrix to only removes the environmental samples: #Load wunifrac load(&quot;wunifrac_df_mean.RData&quot;) #Load metadata metadf &lt;- phyloseq::sample_data(pseq) #Subset data frame so it excludes env samples metadf_noenv &lt;- metadf[metadf$media != ENV,] #Subset distance matrix so it only contains non env samples beta_df_mean_noenv &lt;- beta_df_mean[row.names(metadf_noenv), row.names(metadf_noenv)] beta_df_mean_no_env 23.2 Points long data frame We can now ordinate (PCoA) our subset distance matrix: #Ordinate subset distance matrix with PCoA #PCoA ordinate pcoa_res &lt;- ape::pcoa(beta_df_mean_noenv) #Variation explained values pcoa_axis_var_explained &lt;- round(pcoa_res$values[,&quot;Relative_eig&quot;] * 100, digits = 2) pcoa_axis_var_explained #Extract 1st 2 axes pcoa_res_points &lt;- pcoa_res$vectros[,1:2] head(pcoa_res_points) Followed by producing a long data frame for plotting: #Create point long data frame with metadata #Ennsure row names order matches if (identicial(row.names(metadf), row.names(pcoa_points)) == FALSE) { metadf &lt;- metadf[row.names(pcoa_points),] } #Make points with metadata data frame pcoa_points_metadata &lt;- cbind(pcoa_points, metadf_noenv) head(nmds_points_metadata) #Save object we want, remove ones we don&#39;t save(pcoa_points_metadata, file = &quot;noenv_wunifrac_PCoA.RData&quot;) rm(metadf, nmds_res, pcoa_points) 23.3 Media PCoA scatter plot Finally you can produce the PCoA scatter plot for just the media samples: #Produce PCoA scatter plot #Plot ordination pcoa.wunifrac &lt;- ggplot(data = pcoa_points_metadata, aes(x = Axis.1, y = Axis.2, color = site, shape = media)) + ggplot2::geom_points() + labs(x = paste0(&quot;Axis.1 [&quot;, pcoa_axis_var_explained[1], &quot;%]&quot;), y = paste0(&quot;Axis.2 [&quot;, pcoa_axis_var_explained[2], &quot;%]&quot;)) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Beta_diversity_pcoa_wunifrac_noenv_media_site.png&quot;, plot = pcoa.wunifrac, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 125, width = 150) #Display plot IRdisplay::display_png(file = &quot;./Beta_diversity_pcoa_wunifrac_noenv_media_site.png&quot;) Now we can see some much clearer clustering of the media and site groupings: The different media produce distinct separate clusters. CVP has the tightest clustering. Within the KBC and TSA groups the three different sites seems to produce distinct clusters. 23.4 Stats? As the statistics are based on the paired distances and not the ordination you don't need to repeat the statistical tests if you have already compared the media group pairs as we did. "],["24-Beta_considerations.html", "Chapter 24 \\(\\beta\\): Considerations 24.1 Which distance measure to use? 24.2 Which ordination method to use? 24.3 More dimensions", " Chapter 24 \\(\\beta\\): Considerations There are many considerations to take in mind when carrying out beta diversity analysis. 24.1 Which distance measure to use? There are many beta diversity distances that you can use. Ultimately the choice is yours but our recommendations would be: Weighted and unweighted unifrac distances if you have a phylogenetic tree Bray-Curtis and Jaccard distances if you do not have a phylogenetic tree These 2 sets of distances are very popular and commonly used as the default choices. There are two distances in each set as one is based on: Richness (presence/absence): Unweighted unifrac &amp; Jaccard Richness and abundance values: Weighted unifrac &amp; Bray-Curtis Normally the measure using abundance values will be more infomrative. However, it is good to attempt the richness only approach too as it may show something hidden by tthe inclusion of the abundance data. 24.2 Which ordination method to use? A common question is \"Which ordination method should I use?\" There are many ordination methods with NMDS and PCoA being popular for ordination distance based values (dissimilarity matrices). A general guide to which to use for your data is by choosing the most informative one. Choose the one that shows the best picture and that explains the data the best. In this case the PCoA plot looks better than the NMDS plot as the PCoA plot has a high _% variance explained__ and it shows more separation of the samples. If the PCoA plot had a low % variance explained it may be better to choose the NMDS plot. NMDS attempts to explain the data in the number of dimensions chosen by the user. We chose 2 as we want to plot the data in 2 dimensions. 24.3 More dimensions Your data may be very complex and two dimensions would not be sufficient to plot the data. There are two main ways to plot multiple dimensions. Produce multiple plots Create multiple 2D plots to compare pairs of axes. If you wanted to plot the first three axes this way you would produce the following scatter plots: Axis 1 against Axis 2 Axis 1 against Axis 3 Axis 2 against Axis 3 You can use this method to easily visualise as many axes as possible. The drawback is that you can only directly compare two axes in each plot. 3D scatterplot You can create an interactive 3D scatter plot with the package plotly using the plot_ly() function (guide). This allows you to directly compare 3 axes at once. It is interactive, allowing you to change the perspective of the plot. This allows you to choose the best angle to save the image to use in publication. However, you would generally not use this method to compare more than 3 axes. "],["25-Beta_practice.html", "Chapter 25 \\(\\beta\\): Practice 25.1 \\(\\beta\\): Task 25.2 \\(\\beta\\): Recap", " Chapter 25 \\(\\beta\\): Practice 25.1 \\(\\beta\\): Task As an optional task create a NMDS and PCoA scatter plot using Bray-Curtis. To do this carry out the following steps: Generate a Bray-Curtis distance matrix using the 10 rng seeds previosuly created. Carry out ordination using NMDS and PCoA Create long data frames with metadata and points Plot the points using the media groupings as the shape and the site groupings as the colour Solution code Rarefaction values and rng seeds. #Rarefaction values #Rarefaction size #Minimum sample depth in this case rarefaction_size &lt;- min(microbiome::readcount(pseq)) #Load the vector of 10 rngseeds created in the previous chapter load(&quot;rngseeds.RData&quot;) #Number of rarefaction iterations to be carried out #Based on length of rng seed vector rarefaction_iters &lt;- length(rngseed_vec) Calculate rarefied Bray-Curtis distance matrix by iterative rarefaction. #Calculate rarefied bray-curtis through iterations #We can use a loop to carry this out for us #First create a matrix to contain the final summed bray-curtis beta diversity values #In this case we&#39;ll run the first rarefied beta diversity analysis pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[1], verbose = FALSE) #bray-curtis beta diversity beta_df_sum &lt;- as.matrix( vegan::vegdist(x = t(phyloseq::otu_table(pseq_rarefy)), method = &quot;bray&quot;)) #Loop through 2 to the number of iterations for (i in 2:rarefaction_iters){ #Rarefaction pseq_rarefy &lt;- phyloseq::rarefy_even_depth( pseq, sample.size = rarefaction_size, rngseed = rngseed_vec[i], verbose = FALSE) #Beta diversity beta_df &lt;- as.matrix( rbiom::unifrac( vegan::vegdist(x = t(phyloseq::otu_table(pseq_rarefy)), method = &quot;bray&quot;)) #Add/sum the new data frame values to the sum data frame beta_df_sum &lt;- beta_df_sum + beta_df } #Divide by number of rarefaction iterations to get average beta_df_mean &lt;- beta_df_sum / rarefaction_iters #Save alpha mean data frame save(beta_df_mean, file = &quot;bray_curtis_df_mean.RData&quot;) #View first 6 rows and columns of matrix beta_df_mean[1:6,1:6] #Remove unneeded objects rm(beta_df_sum, beta_df_mean, pseq_rarefy) NMDS ordinate &amp; long data frame #NMDS ordinate nmds_res &lt;- vegan::metaMDS(beta_df_mean, k = 2) #Plot points nmds_res$points #Create long data frame with metadata and points #Extract metadata and ensure row names order matches metadf &lt;- phyloseq::sample_data(pseq) if (identicial(row.names(metadf), row.names(nmds_points)) == FALSE) { metadf &lt;- metadf[row.names(nmds_points),] } #Make points with metadata data frame nmds_points_metadata &lt;- cbind(nmds_points, metadf) #Check head of data frame head(nmds_points_metadata) #Save object we want, remove ones we don&#39;t save(nmds_points_metadata, file = &quot;bray_NMDS.RData&quot;) rm(metadf, nmds_res, nmds_points) NMDS scatterplot #Produce NMDS scatter plot #Plot ordination nmds.bray &lt;- ggplot(data = nmds_points_metadata, aes(x = NMDS1, y = NMDS2, color = site, shape = media)) + ggplot2::geom_point() #Save ggplot2 object with ggsave ggsave(filename = &quot;./Beta_diversity_NMDS_bray_media_site.png&quot;, plot = nmds.bray, device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 125, width = 150) #Display plot IRdisplay::display_png(file = &quot;./Beta_diversity_NMDS_bray_media_site.png&quot;) PCoA ordinate &amp; long data frame #PCoA ordinate pcoa_res &lt;- ape::pcoa(beta_df_mean) #Extract first 2 axes pcoa_points &lt;- pcoa_res$vectors[,1:2] head(pcoa_points) #Variation explained values pcoa_axis_var_explained &lt;- round(x=pcoa_res$values[,&quot;Relative_eig&quot;] * 100, digits=2) pcoa_axis_var_explained #Create point long data frame with metadata #Extract metadata and ensure row names order matches metadf &lt;- phyloseq::sample_data(pseq) if (identicial(row.names(metadf), row.names(pcoa_points)) == FALSE) { metadf &lt;- metadf[row.names(pcoa_points),] } #Make points with metadata data frame pcoa_points_metadata &lt;- cbind(pcoa_points, metadf) head(pcoa_points_metadata) #Save object we want, remove ones we don&#39;t save(pcoa_points_metadata, file = &quot;wunifrac_PCoA.RData&quot;) rm(metadf, pcoa_res, pcoa_points) PCoA scatterplot #Produce PCoA scatter plot #Plot ordination pcoa.bray &lt;- ggplot(data = pcoa_points_metadata, aes(x = Axis.1, y = Axis.2, color = site, shape = media)) + ggplot2::geom_point() + #Add x and y labels to include % variance explained labs(x = paste0(&quot;Axis.1 [&quot;, pcoa_axis_var_explained[1], &quot;%]&quot;), y = paste0(&quot;Axis.2 [&quot;, pcoa_axis_var_explained[2], &quot;%]&quot;)) #Save ggplot2 object with ggsave ggsave(filename = &quot;./Beta_diversity_pcoa_bray_media_site.png&quot;, plot = pcoa.bray device = &quot;png&quot;, dpi = 300, units = &quot;mm&quot;, height = 125, width = 150) #Display plot IRdisplay::display_png(file = &quot;./Beta_diversity_pcoa_bray_media_site.png&quot;) 25.2 \\(\\beta\\): Recap "]]
